<!DOCTYPE html>

<html lang="en">

    <head>
        <title>Ruogu Fang 方若谷</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="ruogu fang">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta name="description" content="Ruogu Fang Homepage" />
        <meta name="keywords" content="Ruogu Fang, medical image, machine learning, deep learning, computer vision, health analysis, SMILE group, big data" />
        <link rel="shortcut icon" href="img/misc/ufl.png">

        <!--CSS styles-->
        <link rel="stylesheet" href="css/bootstrap.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">
        <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
        <link rel="stylesheet" href="css/magnific-popup.css">
        <link rel="stylesheet" href="css/style.css">
        <link id="theme-style" rel="stylesheet" href="css/styles/default.css">

        <!--/CSS styles-->

        <!--Javascript files-->
        <script type="text/javascript" src="js/jquery-3.5.0.min.js"></script>
        <script type="text/javascript" src="js/TweenMax.min.js"></script>
        <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
        <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>
        <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
        <script type="text/javascript" src="js/jquery.dropdownit.js"></script>
        <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>
        <script type="text/javascript" src="js/bootstrap.min.js"></script>
        <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>
        <script type="text/javascript" src="js/masonry.min.js"></script>
        <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>
        <script type="text/javascript" src="js/jquery.nicescroll.min.js"></script>
        <script type="text/javascript" src="js/magnific-popup.js"></script>
        <script type="text/javascript" src="js/custom.js"></script>
        <!--/Javascript files-->
    </head>

    <body>
        <div id="wrapper">

            <!--Sidebar-->
            <a href="#sidebar" class="mobilemenu"><i class="fa fa-reorder"></i></a>
            <div id="sidebar">
                <div id="sidebar-wrapper">
                    <div id="sidebar-inner">

                        <!-- Profile/logo section-->
                        <div id="profile" class="clearfix">
                            <div class="portrate hidden-xs"></div>
                            <div class="title">
                                <h2>Ruogu Fang Reanna 方若谷</h2>
                                <h3>Associate Professor</h3>
                                <h3>Pruitt Family Endowed Fellow</h3>
                                <h3>University of Florida</h3>
                            </div>
                        </div>
                        <!-- /Profile/logo section-->

                        <!-- Main navigation-->
                        <div id="main-nav">
                            <ul id="navigation">
                                <li>
                                  <a href="#biography">
                                    <i class="fa fa-user"></i>
                                    <div class="text">About Me</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#team">
                                    <i class="fa fa-home"></i>
                                    <div class="text">Team</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#research">
                                    <i class="fa fa-book"></i>
                                    <div class="text">Research</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#publications">
                                    <i class="fa fa-edit"></i>
                                    <div class="text">Publications</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#teaching">
                                    <i class="fa fa-clock-o"></i>
                                    <div class="text">Teaching</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#software">
                                    <i class="fa fa-tv"></i>
                                    <div class="text">Software</div>
                                  </a>
                                </li>

                                <li>
                                    <a href="#video">
                                      <i class="fa fa-film"></i>
                                      <div class="text">Video</div>
                                    </a>
                                  </li>

                                <li>
                                  <a href="#media">
                                    <i class="fa fa-rss"></i>
                                    <div class="text">Media</div>
                                  </a>
                                </li>
                                
                                <li>
                                  <a href="#gallery">
                                    <i class="fa fa-picture-o"></i>
                                    <div class="text">Gallery</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#join">
                                      <i class="fa fa-user-plus"></i>
                                      <div class="text">Join</div>
                                  </a>
                                </li>

                                <li>
                                  <a href="#contact">
                                    <i class="fa fa-envelope"></i>
                                      <div class="text">Contact Me</div>
                                  </a>
                                </li>

                                <li class="external">
                                  <a href="CV_Fang.pdf" target="_blank">
                                    <i class="fa fa-download"></i>
                                      <div class="text">Download CV</div>
                                  </a>
                                </li>
                            </ul>
                        </div>
                        <!-- /Main navigation-->

                        <!-- Sidebar footer -->
                        <div id="sidebar-footer">
                            <div class="social-icons">
                                <ul>
                                    <li><a href="https://scholar.google.com/citations?user=LVb46zEAAAAJ&hl=en" target="_blank"><i class="fa fa-google"></i></a></li>
                                    <li><a href="https://github.com/lab-smile"  target="_blank"><i class="fa fa-github"></i></a></li>
                                    <li><a href="https://twitter.com/RuoguFang" target="_blank"><i class="fa fa-twitter"></i></a></li>
                                    <li><a href="https://www.linkedin.com/in/ruogu-fang-a015bb15" target="_blank"><i class="fa fa-linkedin"></i></a></li>
                                </ul>
                            </div>
                          <div id="copyright">Copyright @2021 Ruogu Fang</div>
                        </div>
                        <!-- /Sidebar footer -->
                    </div>
                </div>
            </div>
            <!--/Sidebar-->

            <!--Main-->
            <div id="main">

                <!--About me-->
                <div id="biography" class="page home" data-pos="home">

                    <!--Front Page Header-->
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-sm-2 visible-sm"></div>
                                    <div class="col-sm-8 col-md-5">
                                        <div class="biothumb">
                                            <img alt="image" src="img/personal/personal-ufl.jpg" class="img-responsive">

                                            <!--
                                            <div class="overlay">
                                                <h1 class="">Ruogu (Reanna) Fang 方若谷</h1>
                                                <ul class="list-unstyled">
                                                    <li>J. Crayton Pruitt Family<br>Department of Biomedical Engineering</li>
                                                    <li>University of Florida</li>
                                                </ul>
                                            </div>
                                            -->
                                        </div>
                                        <div class="biothumb">
                                            <img alt="image" src="img/misc/smilebanner.png" class="img-responsive" style="padding-top:30px;padding-bottom:30px">
                                        </div>
                                                                                
                                        <p style="color:red"><b>Postdoc Position Open</b>: Multiple fully funded <a href="https://explore.jobs.ufl.edu/cw/en-us/job/519971/postdoctoral-associate">Post-doc</a> positions are open on research in Medical Artificial Intelligence (MAI), brain-inspired AI, and AI for precision brain health.</p>
                                        <p style="color:red"><b>Ph.D. Position Open</b>: Multiple fully-funded Ph.D. positions are open on research in generative AI, foundation models, LLM, and digital twins.</p>
                                        <p><b>Please check out the "Join" tab to see more information.</b></p>

                                       <!-- <p style="color:red"><b>OPS/RA Position Open</b>: Multiple <a href="https://explore.jobs.ufl.edu/cw/en-us/job/530597/ops-research-assistant">part/full-time OPS positions </a> are open on research in Foundation Model, Text-Image Generative AI.</p> -->

                                    </div>
                                    <div class="clearfix visible-sm visible-xs"></div>

                                    <div class="clearfix visible-sm visible-xs"></div>
                                    <div class="col-sm-12 col-md-7">
                                        <h3 class="title">Bio</h3>
                                        <p>An AI researcher in medicine and healthcare, <b>Dr. Ruogu Fang</b> is a tenured Associate Professor and Pruitt Family Endowed Faculty Fellow in the J. Crayton Pruitt Family Department of Biomedical Engineering at the University of Florida. <!--Her research revolves around the integration of artificial intelligence (AI) and deep learning with the intricacies of the human brain.--> Her research encompasses two principal themes: <b>AI-empowered precision brain health</b> and <b>brain/bio-inspired AI</b>. Her work involves addressing compelling questions, such as using machine learning techniques to quantify brain dynamics, facilitating early Alzheimer's disease diagnosis through novel imagery, predicting personalized treatment outcomes, designing precision interventions, and leveraging principles from neuroscience to develop the next-generation of AI. 
                                        
                                        Fang's current research is also rooted in the confluence of AI and multimodal medical image analysis. She is the PI of NIH NIA RF1 (R01-equivalent), <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1564892">NSF Research Initiation Initiative (CRII) Award</a>, <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1908299&HistoricalAwards=false">NSF CISE IIS Award</a>, Ralph Lowe Junior Faculty Enhancement Award from <a href="https://www.orau.org/">Oak Ridge Associated Universities (ORAU)</a>. She has also received numerous recognitions. She was selected as the Rising Stars (Engineering) by the Academy of Science, Engineering, and Medicine of Florida (ASEMFL), inaugural recipient of the Robin Sidhu Memorial Young Scientist Award from the <a href="https://www.worldbrainmapping.org/">Society of Brain Mapping and Therapeutics</a>, <a href="http://chenlab.ece.cornell.edu/people/ruogu/kin_verify">Best Paper Award from the IEEE International Conference on Image Processing</a>, University of Florida Herbert Wertheim College of Engineering <a href="https://www.bme.ufl.edu/fang-receives-hwcoe-2022-faculty-award-for-excellence-in-innovation/">Faculty Award for Excellence in Innovation</a>, UF BME <a href="https://www.bme.ufl.edu/2021-bme-departmental-excellence-award-winners-announced/">Faculty Research Excellence Award</a>, among others. Fang's research has been featured by <a href="https://www.forbes.com/sites/jackierocheleau/2020/11/25/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/">Forbes Magazine</a>, <a href="https://www.washingtonpost.com/health/retiina-changes-in-early-alzheimers/2021/02/26/24c57bfa-6bba-11eb-9ead-673168d5b874_story.html?fbclid=IwAR1MbVBJwITjz5D5GwpFZ-xyzZcr6d-4VwlXPOqf3Htou3WhUq-Oto91MXM">The Washington Post</a>, <a href="https://www.abcactionnews.com/news/local-news/supercomputer-at-the-university-of-florida-is-harnessing-the-awesome-power-of-ai">ABC</a>, <a href="https://press.rsna.org/timssnet/media/pressreleases/14_pr_target.cfm?ID=2229">RSNA</a>, and published in Lancet Digital Health. She is an Associate Editor of the Journal Medical Image Analysis, a Topic Editor of Frontiers in Human Neuroscience, and a Guest Editor of CMGI. She is a reviewer for The Lancet, Nature Machine Intelligence, Science Advances, etc. Her research has been supported by NSF, NIH, Oak Ridge Laboratory, DHS, DoD, NVIDIA, and the  University of Florida. She is President of Women in <a href="https://miccai.org/">MICCAI</a> (WiM) and Associate Editor of the <a href="https://www.sciencedirect.com/journal/medical-image-analysis">Medical Image Analysis</a> journal. 
                                        
                                        At the heart of her work is the Smart Medical Informatics Learning and Evaluation (SMILE) lab, where she is tirelessly dedicated to creating groundbreaking brain and neuroscience-inspired medical AI and deep learning models. The primary objective of these models is to comprehend, diagnose, and treat brain disorders, all while navigating the complexities of extensive and intricate datasets. </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/Front Page Header-->

                    <!--Front Page Content-->
                    <div class="pagecontents">

                    <!--Recent News-->
                    <div class="section color-1">
                        <div class="section-container">
                            <div class="row">
                                <div class="col-md-10 col-md-offset-1">
                                    <div class="title text-center">
                                        <h3>Recent News</h3>
                                    </div>
                                    
                                    <div class="accordion">
                                        <ul>
                                            <li>
                                            <div> 
                                                <a href="#">
                                                <h3>11/30/2023</h3>
                                                <p>Dr. Fang is recognized as a "Rising Star" in the Academy of Science, Engineering and Medicine of </br>
                                                Florida (ASEMFL) for her contributions in medical AI and deep learning models. </p>
                                                </a>
                                            </div>
                                            </li>

                                          <li>
                                            <div>
                                                <a href="#">
                                                <h3>12/09/2022</h3>
                                                <p>Dr. Fang recieves Pruitt Family Endowed Faculty Fellow for 2023-2026!</p>
                                                </a>
                                            </div>
                                          </li>
                                          <li>
                                            <div>
                                                <a href="#">
                                                <h3>12/02/2022</h3>
                                                <p>Dr. Fang delivered a keynote speech entitled "A Tale of Two Frontiers - When Brain Meets AI" </br>
                                                at the Neural Information Processing (NeurIPS) 2022 workshop on "Medical Imaging Meets NeurIPS" </br>
                                                in New Orleans, Louisiana.</p>
                                                </a>
                                            </div>
                                          </li>

                                        </ul>
                                    </div>
                                    
                                </div>
                            </div>
                        </div>
                    </div>            
                    <!--/Recent News-->

                    <!--News-->
                    <div class="section color-2">
                            <div class="section-container">
                                <div class="row">

                                    <div class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>News</h3>
                                        </div>
                                    <tr>
                                        <td>
                                            <div style="height: 350px; overflow: auto;">
                                                <ul>
                                                    <!--2024-->
                                                    <li style="margin-bottom:10px">07/26/2024: Congrats to SMILE Lab Ph.D. student Skylar Stolte on receiving the prestigous NIH F31 Ruth L. Kirschstein Predoctoral Individual National Research Service Award! </li>
                                                    <!--<li style="margin-bottom:10px">07/11/2024: Dr. Fang and SMILE Lab PhD student have been awarded the Pioneering Research HiPerGator Award for their innovative use of AI in high-fidelity whole-head segmentation of MRIs, aiming to prevent dementia. [<a href="https://bme.ufl.edu/dr-ruogu-fang-and-ph-d-student-skylar-stolte-win-pioneering-research-hipergator-award/">News</a>]</li> -->
                                                    <li style="margin-bottom:10px">06/17/2024: Dr. Fang has been selected to participate in the 2024-2025 class of the University of Florida Leadership Academy. </li>
                                                    <li style="margin-bottom:10px">06/08/2024: Congratulations to SMILE Lab Alumni Gianna Sweeting getting accepted in Meharry Medical College's MD program! </li>
                                                    <li style="margin-bottom:10px">05/14/2024: Dr. Fang gave an invited talk at the University of Tokyo and RIKEN, Japan on neuroscience-inspired AI and AI for brain health, hosted by Dr. Tatsuya Harada and Dr. Lin Gu.</li>
                                                    <li style="margin-bottom:10px">04/29/2024: Kudos to SMILE Lab PhD candidate Seowung Leem on his paper being accepted by IEEE EMBC as an oral presentation!</li>
                                                    <li style="margin-bottom:10px">04/18/2024: Congratulations to SMILE Lab PhD student Seowung Leem on receiving the IEEE EMBC NextGen Scholar Award from IEEE Engineering in Medicine and Biology Society (EMBS), 2024!</li>
                                                    <li style="margin-bottom:10px">04/08/2024: Congratulations to Skylar Stolte on being selected as 2023-2024 Attributes of a Gator Engineer Award Winners in Creativity!</li>
                                                    <li style="margin-bottom:10px">04/03/2024: Congratulations to SMILE Lab PhD student Joseph Cox on being selected as NIAAA T32 Fellow! [<a href="https://www.bme.ufl.edu/predoctoral-student-awarded-nih-niaaa-fellowship/">News</a>]</li>
                                                    <li style="margin-bottom:10px">04/03/2024: Dr. Fang has been awarded Inaugural "AI Course Award". This award was created by the AI2 Center, the Center for Teaching Excellence (CTE), and the Center for Instructional Technology & Training (CITT) to honor UF instructors who have developed high-quality AI courses. She will be recognized at the Interface Conference on April 17, 2024. [<a href="https://bme.ufl.edu/fang-receives-inaugural-ai-course-award/">News</a>]</li>
                                                    <li style="margin-bottom:10px">04/02/2024: New paper entitled "DeepDynaForecast: Phylogenetic-informed graph deep learning for epidemic transmission dynamic prediction" has been accepted by Plos Computational Biology! Congrats to Chaoyue! [<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011351">Paper</a>]</li>
                                                    <li style="margin-bottom:10px">03/27/2024: Congratulations to SMILE Lab PhD student Skylar Stolte on winning the Cluff Aging Research Award!</li>
                                                    <li style="margin-bottom:10px">03/26/2024: New paper entitled "Neuron-Level Explainable AI for Alzheimer’s Disease Assessment from Fundus Images" is accepted by Nature Scientific Reports! [<a href="https://www.nature.com/articles/s41598-024-58121-8">Link</a>]</li>
                                                    <li style="margin-bottom:10px">03/21/2024: Congratulations to SMILE Lab undergraduates Amy Lazarte and Jason Chen on being selected as AI Scholars at the University Scholar Program (USP)!</li>
                                                    <li style="margin-bottom:10px">03/04/2024: Dr. Fang is invited to give a talk at the National Academy of Science (NAS)'s workshop titled Exploring the Bidirectional Relationship between Artificial Intelligence and Neuroscience, March 25-26, 2024 in Washington DC. [<a  href="https://www.bme.ufl.edu/fang-invited-to-present-at-the-national-academies-workshop-on-bidirectionality-between-ai-neuroscience/">News</a>]</li>
                                                    <li style="margin-bottom:10px">02/28/2024: Dr. Fang is named to the Class of 2024 Senior Members by National Academy of Inventors (NAI)! [<a href="https://www.bme.ufl.edu/fang-announced-as-nai-senior-member/">News</a>]</li>
                                                    <li style="margin-bottom:10px">02/27/2024: Congrats to SMILE Lab PhD student Chaoyue Sun on winning the Best Paper Award at <a href="https://healthinf.scitevents.org/">HEALTHINF 2024 Conference</a>!</li>
                                                    <li style="margin-bottom:10px">02/24/2024: SMILE Lab has a third paper accepted in 2024 in just two months entitled "Emergence of Emotion Selectivity in Deep Neural Networks Trained to Recognize Visual Objects" by PLOS Computational Biology! Kudo to SMILE Lab postdoc associate Dr. Peng Liu! [<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011943" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">02/10/2024: SMILE Lab has a new paper entitled "Deep Learning Predicts Prevalent and Incident Parkinson’s Disease From UK Biobank Fundus Imaging" accepted by Nature Scientific Reports! </li>
                                                    <li style="margin-bottom:10px">01/08/2024: Congrats to Skylar Stolte on her first author journal paper entitled "Precise and Rapid Whole-Head Segmentation from Magnetic Resonance Images of Older Adults using Deep Learning" being accepted by Imaging Neuroscience!</li>
                                                    
                                                    <!--2023-->                                                    
                                                    <li style="margin-bottom:10px">12/20/2023: A new paper is accepted by Journal of Visual Communication and Image Representation! </li>
                                                    <li style="margin-bottom:10px">12/01/2023: Welcome Diandra Ojo to join SMILE Lab as a Postdoc Associate!</li>
                                                    <li style="margin-bottom:10px">11/17/2023: A new published in Nature Portfolio Journal npj Digital Medicine on bias and diaparity of AI in diagosing women's health issue. [<a href="https://www.nature.com/articles/s41746-023-00953-1?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20231117&utm_content=10.1038/s41746-023-00953-1" target="_blank">Paper</a>] [<a href="https://news.ufl.edu/2023/11/bias-in-ai-womens-health/" target="_blank">News</a>]
                                                    <li style="margin-bottom:10px">10/24/2023: Dr. Fang gave an invited talk at the 3rd Annual AI Symposium at UF Health Cancer Center: Insights in Cancer Imaging on "AI for Medical Image Analysis 101". [<a href="https://cancer.ufl.edu/2023/10/27/uf-health-cancer-center-ai-cancer-research/">Link</a>]</a></li>
                                                    <li style="margin-bottom:10px">10/12/2023: Dr. Fang co-host with Dr. Parisa Rashidi a Special Session on "AI in Biomedical Engineering" at BMES 2023. Department chairs from University of Washington, Cornell, University of Florida, Boston University, Clemson University were invited to share thoughts on this panel discussion. </li>
                                                    <li style="margin-bottom:10px">10/11/2023: Congratulations to SMILE Lab PhD Candidate Skylar Stolte on placing 2nd in the Women in MICCAI (WiM) Inspirational Leadership Legacy (WILL) Initiative competition! [<a href="https://www.youtube.com/watch?v=XMF6f3RHmP0" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">10/09/2023: Dr. Fang is selected as Rising Stars (Engineering) to be recognized at the Academy of Science, Engineering, and Medicine of Florida (ASEMFL) Annual Meeting of November 3 & 4, 2023. [<a href="https://www.bme.ufl.edu/fang-receives-distinguished-recognition-as-rising-stars-engineering-from-the-academy-of-science-engineering-and-medicine-of-florida/" target="_blank">News</a>][<a href="https://www.eng.ufl.edu/newengineer/honors-awards/saluting-the-trailblazers-academy-of-science-engineering-and-medicine-of-florida-names-honorees-from-uf/?utm_source=Newsletter+&utm_medium=Email+&utm_campaign=FAS+&utm_id=DEC+2023+" target="_blank">College News</a>]</li>
                                                    <li style="margin-bottom:10px">10/09/2023: Dr. Fang becomes a MICCAI 2023 Mentor!</li>
                                                    <li style="margin-bottom:10px">10/08/2023: Dr. Fang presented at the Pre-MICCAI conference as Keynote Speaker in the University of British Columbia (UBC), Vancouver, Canada.</li>
                                                    <li style="margin-bottom:10px">09/01/2023: Welcome Peng Liu to join SMILE Lab as a Postdoc Associate!</li>
                                                    <li style="margin-bottom:10px">09/01/2023: Congratulations to our SMILE Lab Ph.D. student Daniel Rodriguez being selected  to receive NIH T1D&BME T32 Fellowship! [<a href="https://www.bme.ufl.edu/bme-ph-d-student-awarded-nih-t1d-t32-fellowship/">News</a>]</a></li>
                                                    <li style="margin-bottom:10px">08/23/2023: Welcome two new PhD students Pankaj Chand and Daniel Rodriguez joining SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/18/2023: A new collaborative grant (DRPD-ROF2023) entitled "Learning optimal treatment strategies for hypotension in critical care patients with acute kidney injury using artificial intelligence" has been funded by the University of Florida!</li>
                                                    <li style="margin-bottom:10px">08/09/2023: Dr. Fang receives a new NSF award on brain-inspired AI entitled "NCS-FO: Brain-Informed Goal-Oriented and Bidirectional Deep Emotion Inference" as the PI, with Co-PI Dr. Mingzhou and Andreas Keil. [<a href="https://www.bme.ufl.edu/bridging-neuroscience-and-ai-brain-inspired-ai-to-make-machine-perceive-emotion-like-humans/" target="_blank">News</a>] [<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2318984" target="_blank">NSF Link</a>]</li>
                                                    <li style="margin-bottom:10px">08/07/2023: Dr. Fang gave a talk at the MRI Research Institute (MRIRI), Weill Cornell Medical College, Cornell University on "Generative, Trustworthy, and Precision AI in Radiology".</li>
                                                    <li style="margin-bottom:10px">08/01/2023: Dr. Fang will serve as the President of Women in MICCAI, International Society of Medical Image Computing and Computer Assisted Intervention (MICCAI). [<a href="https://www.bme.ufl.edu/34619-2/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">07/31/2023: Two papers from SMILE Lab PhD students Joseph Cox and Seowung Leem will be presented at <a href="https://www.bmes.org/meetings/2023-bmes-annual-meeting" target="_blank">BMES 2023</a> in Seattle, WA!</li>
                                                    <li style="margin-bottom:10px">06/26/2023: One paper entitled "DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability" is accepted by MICCAI 2023 in Vancouver, Canada. Kudos to Skylar!</li>
                                                    <li style="margin-bottom:10px">05/23/2023: New paper entitled "Machine-Learning Defined Precision tDCS for Improving Cognitive Function" is accepted by Brain Stimulation! </li>
                                                    <li style="margin-bottom:10px">05/17/2023: Editorial on "Frontiers of Women in Brain Imaging and Brain Stimulation" authored by Dr. Fang is published in the Frontiers of Human Neuroscience.</li>
                                                    <li style="margin-bottom:10px">05/16/2023: Dr. Fang gave an invited talk at the <a href="https://informatics.research.ufl.edu/event/nvaitc-uf-virtual-ai-symposium/" target="_blank">Nvidia Artificial Intelligence Technology Center (NVAITC)</a> on "Trustworthy AI and Large Vision Models for Neuroimages".</li>
                                                    <li style="margin-bottom:10px">04/25/2023: Dr. Fang will serve as a mentor for Dr. Joseph Gullett who is awarded an NIH/NIA K23 on "Using Artificial Intelligence to Predict Cognitive Training Response in Amnestic Mild Cognitive Impairment".</li>
                                                    <li style="margin-bottom:10px">04/25/2023: A new collaborative R01 award entitled "Cognitively engaging walking exercise and neuromodulation to enhance brain function in older adults" is funded by NIH/NIA!</li>
                                                    <li style="margin-bottom:10px">04/19/2023: SMILE Lab PhD student Joseph Cox taught the AI Bootcamp of <a href="https://ai.cme.ufl.edu/" target="_blank">AI4Health Conference</a> in Orlando. </li>
                                                    <li style="margin-bottom:10px">04/10/2023: Congratulations to SMILE Lab PhD Student Hong Huang on his work "Distributed Pruning Towards Tiny Neural Networks in Federated Learning" getting accepted by the 43rd IEEE International Conference on Distributed Computing Systems (ICDCS 2023) (rate=18.9%)!</li>
                                                    <li style="margin-bottom:10px">04/08/2023: Congrats to SMILE Lab alumna and Dream Engineering Team vice president Neeva Sethi on being one of the five inductees to the <a href="https://classc.clas.ufl.edu/hall-of-fame/" target="_blank">UF CLAS Hall of Fame</a>!</li>
                                                    <li style="margin-bottom:10px">04/07/2023: Congrats to SMILE Lab PhD student Tianqi Liu on passing his PhD Proposal Defense!</li>
                                                    <li style="margin-bottom:10px">04/06/2023: Dr. Fang appears in the National Geographic story, "Your eyes may be a window into early Alzheimer's detection"! [<a href="https://www.nationalgeographic.com/premium/article/eyes-early-stage-alzheimers-retina" target="_blank">News</a>]</li>                                                
                                                    <li style="margin-bottom:10px">04/06/2023: SMILE Lab received an Oracle for Research Cloud Starter Award!</li>
                                                    <li style="margin-bottom:10px">04/05/2023: SMILE Lab undergraduate researchers Grace Cheng and Akshay Ashok have been selected to receive UF AI Scholarship on its first offering! Congrats to Grace and Akshay! [<a href="https://www.bme.ufl.edu/bme-students-selected-for-ai-scholars-program/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">03/31/2023: SMILE Lab is featured on the Forward & Up video by the College of Engineering. [<a href="https://www.youtube.com/watch?v=PlJhBRqmWeI" target="_blank">Video</a>]</li>
                                                    <li style="margin-bottom:10px">03/31/2023: Congratulations to SMILE Lab Alumnus Garrett Fullerton on receiving the prestigious National Science Foundation Graduate Research Fellowship Program (NSF-GRFP) grant!</li>
                                                    <li style="margin-bottom:10px">03/23/2023: Congratulations to SMILE Lab Alumna Neeva Sethi on receiving the prestigious Presidential Service Award at the University of Florida! [<a href="https://twitter.com/LabFang/status/1638921022023028736?s=20" target="_blank">News</a>] </li>
                                                    <li style="margin-bottom:10px">03/06/2023: Dr. Fang gave a talk at the Intelligence Critical Care Center (IC3) on "Artificial Intelligence for Cognitive Aging: Novel Diagnosis and Personalized Intervention". 
                                                    <li style="margin-bottom:10px">02/14/2023: Dr. Fang and SMILE Lab's research using HiperGator supercomputer for healthcare and humanity is featured by ABC Action News in the story "Supercomputer at the University of Florida is harnessing the awesome power of AI". [<a href="https://www.abcactionnews.com/news/local-news/supercomputer-at-the-university-of-florida-is-harnessing-the-awesome-power-of-ai" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">02/11/2023: Our journal paper entitled "DOMINO: Domain-aware loss for deep learning calibration" has been accepted by Software Impact. Kudos to Skylar! Code and pretrained models are available on <a href="https://github.com/lab-smile/DOMINO" target="_blank">GitHub</a> and <a href="https://codeocean.com/capsule/6022409/tree/v2" target="_blank">CodeOcean</a> [<a href="https://www.sciencedirect.com/science/article/pii/S2665963823000155" target="_blank">Paper</a>] </li>
                                                    <li style="margin-bottom:10px">01/10/2023: Dr. Fang and SMILE Lab Ph.D. student Skylar Stolte are featured by the Medical Imaging section of Computer Vision News on medical AI research. [<a href="https://www.rsipvision.com/ComputerVisionNews-2023January/32/" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">01/06/2023: Welcome two new Ph.D. students Zhuobiao Qiao and Yu Feng to join SMILE Lab!</li>

                                                    <!--2022-->
                                                    <li style="margin-bottom:10px">12/09/2022: Dr. Fang recieves Pruitt Family Endowed Faculty Fellow for 2023-2026! [<a href="https://www.bme.ufl.edu/new-pruitt-family-endowed-faculty-fellowships-awardees-3/" target="_blank">News</a>] </li>
                                                    <li style="margin-bottom:10px">12/02/2022: Dr. Fang delivered a keynote speech entitled "A Tale of Two Frontiers - When Brain Meets AI" at the <a href="https://nips.cc/" target="_blank">Neural Information Processing System (NeurIPS) 2022</a> workshop on "Medical Imaging Meets NeurIPS" in New Orleans, Louisiana. </li>
                                                    <li style="margin-bottom:10px">11/11/2022: Dr. Fang gave an invited talk at College of Medicine, Stanford University on "Artificial Intelligence in Cognitive Aging and Brain-Inspired AI". </li>
                                                    <li style="margin-bottom:10px">11/01/2022: SMILE Lab PhD Candidate Skylar Stolte presented her work, DOMINO: Domain-aware Calibration in Medical Image Segmentation, at the [<a href="https://www.rc.ufl.edu/highlight-articles/fall-2022-hipergator-symposium.html" target="_blank">Fall 2022 HiPerGator Symposium</a>] [<a href="https://www.bme.ufl.edu/bme-students-selected-for-lightening-talk-presentations-at-2022-hipergator-symposium/" target="_blank">News</a>].</li>
                                                    <li style="margin-bottom:10px">10/25/2022: New collaborative paper entitled "Association of Longitudinal Cognitive Decline with Diffusion MRI in Gray Matter, Amyloid, and Tau Deposition" is accepted by <a href="https://www.sciencedirect.com/journal/neurobiology-of-aging" target="_blank">Neurobiology of Aging</a>! </li>
                                                    <li style="margin-bottom:10px">09/20/2022: Kudos to SMILE Lab PhD student Skylar Stolte for her Women in MICCAI's Best Paper Presentation Award Runner up! [<a href="https://www.bme.ufl.edu/bme-student-awarded-best-paper-presentation-runner-up-at-miccai-wim/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">08/24/2022: Congrats to SMILE Lab PhD Candidate Skylar Stolte on passing her dissertation qualification!</li>
                                                    <li style="margin-bottom:10px">08/20/2022: Welcome two new Masters students Everett Schwieg and Fan Yang to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">01/06/2023: Welcome two new Ph.D. students Chaoyue Sun and Hong Huang to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/10/2022: Congrats to SMILE Lab PhD student Skylar Stolte on her paper selected to be <a href="https://conferences.miccai.org/2022/files/downloads/MICCAI2022-Program-for-authors.pdf">oral presentation</a> (Oral rate=2.3%) at MICCAI 2022!</li>
                                                    <li style="margin-bottom:10px">08/09/2022: Kudos to SMILE Lab PhD student Seowung Leem's paper being accepted by the <a href="https://www.sfn.org/meetings/neuroscience-2022">Annual Meeting of Society for Neuroscience (SfN)</a> 2022!</li>
                                                    <!--<li style="margin-bottom:10px">07/27/2022: Congrats to Garrett Fullerton and Simon Kato on their paper entitled "MAGIC: Multitask synthesis of contrast-free CT perfusion maps via generative adversarial network" being accepted by the <a href="https://www.rsna.org/">Annual Meeting of Radiology Society of North America (RSNA) 2022!</li>-->
                                                    <li style="margin-bottom:10px">06/28/2022: <b>Dr. Fang is awarded Tenure and Promotion to Associate Professor! [<a href="https://www.bme.ufl.edu/fang-awarded-tenure-and-promoted-to-associate-professor/">News</a>]</b> </li>
                                                    <li style="margin-bottom:10px">06/20/2022: Congratulations to SMILE Lab PhD student Skylar Stolte on receiving MICCAI Student Travel Award!</li>
                                                    <li style="margin-bottom:10px">06/07/2022: Dr. Fang gave an invited talk at the <a href="https://www.grc.org/image-science-conference/2022/">Gordan Research Conference (GRC) Image Science, Emerging Imaging Techniques at the Intersection of Physics and Data Science</a> on the topic "From Zero to One: Physiology-Informed Deep Learning for Contrast-Free CT Perfusion in Stroke Care" in Newry, ME, United States. </li>
                                                    <li style="margin-bottom:10px">06/01/2022: Dr. Fang gave an invited talk at the <a href="https://www.grc.org/systems-aging-conference/2022/">Gordan Research Conference (GRC) System Aging, Systemic Processes, Omics Approaches and Biomarkers in Aging</a> on the topic "Artificial Intelligence and Machine Learning for Cognitive Aging: Novel Diagnosis and Precision Intervention" in Newry, ME, United States. </li>
                                                    <li style="margin-bottom:10px">05/25/2022: New paper published in Frontiers in Radiology entitled "PIMA-CT: Physical Model-Aware Cyclic Simulation and Denoising for Ultra-Low-Dose CT Restoration". Congrats to recent SMILE Lab PhD graduate Peng Liu and undergraduate graduate Garrett Fullerton! [<a href="https://www.frontiersin.org/articles/10.3389/fradi.2022.904601/full" target="_blank">Link</a>] </li>
                                                    <li style="margin-bottom:10px">05/23/2022: Welcome new Masters student Ayesha Naikodi to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">05/12/2022: Welcome new Ph.D. student Joseph Cox to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">05/05/2022: Our paper entitiled "DOMINO: Domain-aware Model Calibration in Medical Image Segmentation" is early accepted by <a href="https://conferences.miccai.org/2022/en/">MICCAI</a> in Singapore Sep. 18-22, 2022 (early acceptance rate=13%)! Congrats to Skylar Stolte!</li>
                                                    <li style="margin-bottom:10px">05/03/2022: Dr. Fang was interview by ABC WCJB TV Tech Tuesday on her research using artificial intelligence (AI) to detect Alzheimer's Disesase. [<a href="https://www.wcjb.com/2022/05/04/tech-tuesday-modular-ad/?utm_source=newsfore&utm_medium=email&utm_campaign=16933&pnespid=t7s2B3tWKPwe3.vE.DeoApKGo0.1CINmM7Gg3utzvBdm3JEFixSQW_4oqGfEyyA8RU2FZT94NA" target="_blank">Interview</a>]</li>
                                                    <li style="margin-bottom:10px">04/14/2022: Congratulations to SMILE Lab member Garrett Fullerton on winning the Outstanding Research Award at the BME Undergraduate Research Day! [<a href="https://www.bme.ufl.edu/bme-undergraduate-research-day-3/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">03/20/2022: Welcome new Ph.D. student Ziqian Huang to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">03/11/2022: A new collaborative $10.7M P01 entitled "Multi-Scale Evaluation and Mitigation of Toxicities Following Internal Radionuclide Contamination" (PI: Gayle E. Woloschak) is funded by NIH NIAID!</li>
                                                    <li style="margin-bottom:10px">03/04/2022: Dr. Fang is selected to receive the Herbert Wertheim College of Engineering 2022 Faculty Award for Excellence in Innovation! [<a href="https://www.bme.ufl.edu/fang-receives-hwcoe-2022-faculty-award-for-excellence-in-innovation/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">03/01/2022: Dr. Fang is appointed as the Associate Director in the UF <a href="https://ufhealth.org/news/2021/artificial-intelligence-intensive-care-unit-uf-researchers-developing-novel-solutions" target="_blank">Intelligent Critical Care Center (IC3)</a>.</li>
                                                    <li style="margin-bottom:10px">02/16/2022: Dr. Fang will serve as Topic Editor on "<a href="https://www.frontiersin.org/research-topics/32902/women-in-brain-imaging-and-stimulation" target="_blank">Women In Brain Imaging and Stimulation</a>" with <a href="https://www.frontiersin.org/journals/human-neuroscience" target="_blank">Frontiers in Human Neuroscience Journal</a>. Welcome to submit to this exciting topic!</li>
                                                    <li style="margin-bottom:10px">02/12/2022: Dr. Fang will serve as Area Chair of the 25th <a href="https://conferences.miccai.org/2022" target="_blank">International Conference of Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022</a> in Singapore. Call for papers for this top conference in MIA!</li>
                                                    <li style="margin-bottom:10px">02/02/2022: Dr. Fang and collaborators joined forces with Nvidia scientists and OpenACCorg to accelerate brain science at the Georgia Tech GPU Hackathon. The StimulatedBrain AI@UF team drastically improved their processing time for evaluating datapoints collected from an individual brain. [<a href="https://phhp.ufl.edu/2022/02/02/uf-nvidia-partner-to-speed-brain-research-using-ai/" target="_blank">News</a>] [<a href="https://twitter.com/UF_CAMcenter/status/1488925678686720001" target="_blank">Twitter</a>]</li>
                                                    <li style="margin-bottom:10px">01/18/2022: Dr. Fang delivers an invited talk entitled "Modular machine learning for Alzheimer's disease classification from retinal vasculature" at University of Oxford "Artificial Intelligence for Mental Health" seminar series. </li>
                                                    <li style="margin-bottom:10px">01/09/2022: Welcome new Ph.D. student Tianqi Liu to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">01/07/2022: Dr. Fang is interviewed by Ivanhoe on her collaborative work on Aritifial Intelligence to prevent dementia. [<a href="https://www.ivanhoe.com/medical-breakthroughs/artificial-intelligence-prevents-dementia/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">01/04/2022: Dr. Fang gives an invited talk entitled "Artificial Intelligence for Cognitive Aging - Novel Diagnosis and Precision Intervention" at the University of Florida Institute of Aging. </li>
                                                    
                                                    <!--2021-->
                                                    <li style="margin-bottom:10px">12/15/2021: Congrats to SMILE Lab PhD Dr. Peng Liu graduated!</li>
                                                    <li style="margin-bottom:10px">12/14/2021: Dr. Fang receives the BME Departmental Faculty Research Excellence Award! [<a href="https://www.bme.ufl.edu/2021-bme-departmental-excellence-award-winners-announced/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">12/07/2021: A new paper on Artificial Intelligence to predict dementia entitled "Baseline neuroimaging predicts decline to dementia from amnestic mild cognitive impairment" is published in Frontiers in Aging Neuroscience! [<a href="https://www.frontiersin.org/articles/10.3389/fnagi.2021.758298/full">Paper</a>] [<a href="https://ufhealth.org/news/2021/uf-study-shows-artificial-intelligence-s-potential-predict-dementia" target="_blank">News</a>] </li>
                                                    <li style="margin-bottom:10px">11/30/2021: Kudos to SMILE PhD Peng Liu on winning the UNIQUE-IVADO Award for Best Abstract (Undergraduate and Graduate Level) at <a href="https://www.main2021.org/home">Montreal AI& Neuroscience (MAIN) Conference</a>! [<a href="https://youtu.be/VAU0MfQtLOk?t=530">Video</a>] [<a href="https://www.bme.ufl.edu/bme-ph-d-student-receives-the-best-abstract-award-at-the-montreal-ai-neuroscience-main-conference/" target="_blank">News</a>] </li>
                                                    <li style="margin-bottom:10px">11/03/2021: Our lab's new AI paper entitled "Unraveling Somatotopic Organization in the Human Brain using Machine Learning and Adaptive Supervoxel-based Parcellations" is accepted by NeuroImage today! Kudos to Kyle See as a leading first author! [<a href="https://www.sciencedirect.com/science/article/pii/S1053811921009824" target="_blank">Link</a>] </li>
                                                    <li style="margin-bottom:10px">10/29/2021: Our lab's new paper on AI in domain adaptation entitled "CADA: Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation" is published in NeuroComputing today! Kudos to Peng and Charlie! [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221015642" target="_blank">Link</a>] </li>                                
                                                    <li style="margin-bottom:10px">10/28/2021: Congratulations to SMILE Lab member Peng Liu on successfully defending his Ph.D. dissertation entitled "Biology and Neuroscience-Inspired Deep Learning"! Congrats, Dr. Liu!</li>
                                                    <li style="margin-bottom:10px">10/28/2021: New collaborative paper on "Machine Learning for Physics-Informed Generation of Dispersed Multiphase Flow Using Generative Adversarial Networks" published in Theoretical and Computational Fluid Dynamics! [<a href='https://link.springer.com/article/10.1007/s00162-021-00593-9' target="_blank">Link</a>] </li>
                                                    <li style="margin-bottom:10px">10/22/2021: New publication on AI in computational fluid dynamics entitled "Rotational and Reflectional Equivariant Convolutional Neural Network for data-limited applications: Multiphase Flow demonstration" in the Journal of Physics of Fluids is now online! [<a href="https://aip.scitation.org/doi/10.1063/5.0066049" target="_blank">Link</a>] </li>                                                 
                                                    <li style="margin-bottom:10px">10/09/2021: Dr. Fang will serve as session chair for Optical Imaging Session of the <a href="https://www.bmes.org/annualmeeting" target="_blank">Annual Meeting of Biomedical Engineering Society (BMES)</a> on Oct. 6-9, 2021 at Orlando, FL. </li>                                            
                                                    <li style="margin-bottom:10px">09/30/2021: A new collaborative grant entitled "Creation of an intelligent alert to improve efficacy & patient safety in real time during fluoroscopic guided lumbar transforaminal epidural steroid injection" is funded by the I. Heermann Anesthesia Foundation. </li>             
                                                    <li style="margin-bottom:10px">09/30/2021: Dr. Fang has received an Oracle Research Project Award on "Explainable artificial intelligence for Alzheimer’s Disease Assessment from Retinal Imaging". </li>
                                                    <li style="margin-bottom:10px">09/29/2021: Dr. Fang serves as the session chair of Image Reconstruction Session at <a href="https://miccai2021.org/en/" target="_blank">MICCAI 2021</a>. </li>
                                                    <li style="margin-bottom:10px">09/21/2021: A new 5-year U24 grant ($2.5M) entitled "Southern HIV and Alcohol Research Consortium Biomedical Data Repository" is funded by NIH NIAAA!</li>
                                                    <li style="margin-bottom:10px">09/10/2021: A new 5-year P01 grant ($6.6M) entitled "Interventions to improve alcohol-related comorbidities along the gut-brain axis in persons with HIV infection" is funded by NIH NIAAA! [<a href="https://ufhealth.org/news/2022/uf-health-team-receives-66-million-study-treatments-boost-cognition-those-hiv" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">09/09/2021: A new 4-year SCH grant ($1.2M) entitled "Collaborative Research: SCH: Trustworthy and Explainable AI for Neurodegenerative Diseases" is funded by National Science Foundation! Dr. Fang is Co-PI on this Trustworthy and Explanable Artificial Intelligence (AI) award. [<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2123809" target="_blank">NSF</a>] [<a href="https://www.eng.ufl.edu/newengineer/research-innovation/ai-university/researchers-seek-to-build-confidence-into-ai-for-healthcare-under-nsf-grant/" target="_blank">News</a>]</li>                                                   
                                                    <li style="margin-bottom:10px">09/09/2021: A new 5-year P01 grant ($1.5M to UF) entitled "SHARE Program: Innovations in Translational Behavioral Science to Improve Self-management of HIV and Alcohol Reaching Emerging adults" is funded by NIH NIAAA!</li>                                                    
                                                    <li style="margin-bottom:10px">08/27/2021: Welcome two new Ph.D. students Charlie Tran and Seowung Leem to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/26/2021: Three abstracts are accepted by <a href="https://www.sfn.org/meetings/neuroscience-2021" target="_blank">Society of Neuroscience (SfN) Annual Meeting</a> to be held November 8-11 virtual and November 13-16, 2021 in Chicago:
                                                        <ul>
                                                            <li>Emergence of emotion selectivity in deep neural networks trained to recognize visual objects</li>
                                                            <li>A deep neural network model for emotion perception</li>
                                                            <li>Machine learning defined precision tES for improving cognitive function in older adults</li>
                                                        </ul>
                                                        Congrats to Peng and Alejandro!</li>
                                                    <li style="margin-bottom:10px">08/24/2021: A new paper entitled "Machine Learning for Physics-Informed Generation of Dispersed Multiphase Flow Using Generative Adversarial Networks" is accepted by Theoretical and Computational Fluid Dynamics!</li>
                                                    <li style="margin-bottom:10px">08/23/2021: Welcome two new Ph.D. students Charlie Tran and Seowung Leem to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/17/2021: Kudos to SMILE Lab PhD student Charlie Tran who has been selected into the highly competitive <a href="https://nextprofpathfinder.engin.umich.edu/" target="_blank">NextProf Pathfinder</a> 2021 to be held during October 17-19, 2021 on the campus of University of Michigan, Ann Arbor, co-sponsored by the University of California, San Diego. Congrats Charlie! [<a href="https://www.bme.ufl.edu/ph-d-student-selected-for-2021-nextprof-pathfinder-workshop/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">08/11/2021: Congratulations to SMILE lab undergraduate student Gianna Sweeting on being selected to receive the <a href="https://www.eng.ufl.edu/students/students/awards-and-scholarships/undergraduate-scholarship-application/" target="_blank">John & Mittie Collins Engineering Scholarship</a> from Herbert Wertheim College of Engineering (HWCOE)! [<a href="https://www.bme.ufl.edu/undergraduate-student-receives-hwcoe-scholarship/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">07/30/2021: A new collaborative 5-Year R01 grant ($2.3M) entitled "Acquisition, extinction, and recall of attention biases to threat: Computational modeling and multimodal brain imaging" has been funded by NIH NIMH! </li>
                                                    <li style="margin-bottom:10px">07/15/2021: Our AI research on precision dosing for preventing dementia has been reported by <a href="https://ufhealth.org/news/2021/uf-researchers-use-ai-develop-precision-dosing-treatment-aimed-preventing-dementia" target="_blank">UF News</a>, <a href="https://www.local10.com/health/2021/07/16/staving-off-dementia-is-focus-of-univ-of-florida-study/" target="_blank">WPLG Local 10 News (ABC-affiliated local TV)</a>, <a href="https://www.wcjb.com/2021/07/14/uf-researchers-using-artificial-intelligence-develop-treatment-prevent-dementia/" target="_blank">WCJB TV (ABC/CW+ affiliated local)</a>, and <a href="https://www.alligator.org/article/2021/07/ai-dementia" target="_blank">The Alligator</a>. </li>
                                                    <li style="margin-bottom:10px">06/14/2021: Dr. Fang presented as an invited speaker at the Cleveland Clinic-National Science Foundation Workshop "The Present and the Future of Artificial Intelligence in Biomedical Research".</li>
                                                    <li style="margin-bottom:10px">06/04/2021: NeuroAI T32 Machine Learning Workshop taught by Dr. Fang has successfully completed! [<a href="http://hhp.ufl.edu/articles/2021/neuroai-workshops.html" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">05/14/2021: New 4-Year MPI (Fang & Woods) RF1 grant ($2.9M) on Artificial Intelligence for transcranial direct current stimulation (tDCS) in remediating cognitive aging has been funded by NIH! [<a href="https://www.bme.ufl.edu/fang-and-uf-researchers-awarded-nih-nia-ro1-grant/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">05/02/2021: Congrats to SMILE PhD student Skylar Stolte on passing her Doctoral Comprehensive Exam!</li>
                                                    <li style="margin-bottom:10px">04/07/2021: Congratulations to SMILE undergraduate student and incoming Ph.D. student Charlie Tran on receiving the McNaire Graduate Assistantship!</li>
                                                    <li style="margin-bottom:10px">03/18/2021: New 5-year ($5M) NIH U01 grant on New AI tool to improve diagnosis of Parkinson’s and related disorders. [<a href="https://ufhealth.org/news/2021/new-ai-tool-be-tested-nih-funded-study-improve-diagnosis-parkinson-s-and-related-disorders" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">03/01/2021: Congratulations to SMILer undergraduate Gianna Sweeting for being selected by the Univerity Scholar Program!</li>
                                                    <li style="margin-bottom:10px">02/26/2021: Dr. Fang's work AI in Parkinson's Disease dignosis via eye scans has been reported by <a href="https://www.washingtonpost.com/health/retiina-changes-in-early-alzheimers/2021/02/26/24c57bfa-6bba-11eb-9ead-673168d5b874_story.html?fbclid=IwAR1MbVBJwITjz5D5GwpFZ-xyzZcr6d-4VwlXPOqf3Htou3WhUq-Oto91MXM" target="_blank">The Washington Post</a>.</li>
                                                    <li style="margin-bottom:10px">02/25/2021: Congratulations to SMILer undergraduate Gianna Sweeting for being selected as a Fernandez Family Scholar by the Herbert Wertheim College of Engineering for her excellent progress and interest in research and graduate studies. [<a href="https://www.bme.ufl.edu/undergraduate-student-selected-as-fernandez-family-scholar/" target="_blank">News</a>][<a href="https://twitter.com/eabrown18/status/1365719503062073345?s=20" target="_blank">Twitter</a>]</li>
                                                    <li style="margin-bottom:10px">02/18/2021: Dr. Fang has been selected as Aspiring PI to attend <a href="https://www.cefns.nau.edu/~fa334/Links.html" target="_blank">2021 NSF SCH PI Workshop: Smart Health in the AI and COVID Era</a>.</li>
                                                    <li style="margin-bottom:10px">02/18/2021: SMILE lab PhD student Peng Liu has been selected by NSF to attend the <a href="https://www.cefns.nau.edu/~fa334/Links.html" target="_blank">2021 NSF SCH PI Workshop: Smart Health in the AI and COVID Era.</a></li>
                                                    <li style="margin-bottom:10px">02/2021: Dr. Fang will serve as Track Chair for <a href="https://www.bmes.org/annualmeeting" target="_blank">BMES 2021</a></li>
                                                    <li style="margin-bottom:10px">02/2021: Dr. Fang will serve as Program Committee for <a href="https://miccai2021.org/en/" target="_blank">MICCAI 2021</a>.</li>
                                                    <li style="margin-bottom:10px">01/25/2021: Congrats to Kyle See and Rachel Ho whose joint paper on "TL1 Team Approach to Predicting Response to Spinal Cord Stimulation for Chronic Low Back Pain" has been accepted by <a href="https://www.actscience.org/Translational-Science">Translational Science 2021!</a></li>

                                                    <!--2020-->
                                                    <li style="margin-bottom:10px">12/2020: Dr. Fang, together with <a href="https://www.bme.ufl.edu/dept-member/ding_mingzhou/" target="_blank">Dr. Mingzhou Ding</a> and <a href="https://people.clas.ufl.edu/akeil/">Dr. Andreas Keil</a> have been awarded <a href="https://news.ufl.edu/2020/12/artificial-intelligence-research-catalyst-fund-/">UF Research Artificial Intelligence Research Catalyst Fund</a> on the project "VCA-DNN: Neuroscience-Inspired Artificial Intelligence for Visual Emotion Recognition"! [<a href="https://www.bme.ufl.edu/fang-and-ding-selected-for-uf-catalyst-fund/" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">12/15/2020: Our paper on "Modular machine learning for Alzheimer's disease classification from retinal vasculature" has been accepted by Nature Scientific Reports! [<a href="https://www.nature.com/articles/s41598-020-80312-2">Link</a>]</li>
                                                    <li style="margin-bottom:10px">12/2020: Dr. Fang has been interviewed by <a href="https://www.forbes.com/sites/jackierocheleau/2020/11/25/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/?sh=557314f52faa">Forbes</a>, <a href="https://press.rsna.org/timssnet/media/pressreleases/14_pr_target.cfm?ID=2229">RSNA</a>, <a href="https://www.diagnosticimaging.com/view/eye-exam-plus-ai-could-replace-advanced-imaging-in-parkinson-s-detection">Diagnostic Imaging</a> on her research about <a href="https://www.eng.ufl.edu/newengineer/in-the-headlines/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/">AI for Parkinson's Disease Diagnosis via Eye Exam.</a></li>
                                                    <li style="margin-bottom:10px">11/2020: Dr. Fang is interviewed by UFII on AI for brain functions. [<a href="https://informatics.research.ufl.edu/engineering-professor-uses-ai-to-study-the-brain/">Link</a>]</li>
                                                    <li style="margin-bottom:10px">10/30/2020: Paper published in Brain Simulation on <a href="https://www.sciencedirect.com/science/article/pii/S1935861X20302680">Machine learning and individual variability in electric field characteristics predict tDCS treatment response</a>". [<a href="https://www.brainstimjrnl.com/article/S1935-861X(20)30268-0/pdf">PDF</a>]</li>
                                                    <li style="margin-bottom:10px">10/14/2020: Congratulations to SMILer Gianna Sweeting on receving the Engineering College Scholarship from the Herbert Wertheim College of Engineering (HWCOE)! [<a href="https://www.bme.ufl.edu/bme-student-selected-as-a-hwcoe-scholarship-recipient/">News</a>]</li>
                                                    <li style="margin-bottom:10px">09/04/2020: Congratulations to BME Alumna Yao Xiao Ph.D on receiving the prestigious 2020 BMES Career Development Award! [<a href="https://www.bme.ufl.edu/bme-alumna-awarded-bmes-2020-career-development-award/">News</a>]</li>
                                                    <li style="margin-bottom:10px">08/20/2020: Welcome new Ph.D. student Skylar Stolte to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/05/2020: Congrats on Skylar Stolte on her abstract entitled "Artificial Intelligence For Characterizing Heart Failure In Cardiac Magnetic Resonance Images" being accepted by <a href="https://professional.heart.org/professional/EducationMeetings/MeetingsLiveCME/ScientificSessions/UCM_316900_Scientific-Sessions.jsp">American Heart Association Scientific Sessions</a> 2020! </li>
                                                    <li style="margin-bottom:10px">07/16/2020: Our paper on "Physiological wound assessment from coregistered and segmented tissue hemoglobin maps" is published at Journal of the Optical Society of America A. It is a collaborative work with Dr. Anuradha Godavarty at Florida International University. [<a href="https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-37-8-1249">Paper</a>]</li>
                                                    <li style="margin-bottom:10px">07/06/2020: Congratulaions to SMILE Member PhD student <a href="https://rocmind.com/">Peng Liu</a> on receving <a href="https://research.ufl.edu/informatics-institute.html">UFII</a> Graduate Student Fellowship on his project on Neuroscience-Inspired Artificial Intelligence![<a href="https://www.bme.ufl.edu/bme-student-receives-ufii-graduate-student-fellowship/">News</a>]</li></li>
                                                    <li style="margin-bottom:10px">06/25/2020: Yao Xiao presented at the 2020 Annual Meeting of the Society for Imaging Informatics in Medicine (SIIM) on 'Multi-Series CT Image Super-Resolution by using Transfer Generative Adversarial Network'! [<a href="https://cdn.ymaws.com/siim.org/resource/resmgr/siim20/abstracts-research/xiao-fang_multi-series_ct_im.pdf" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">06/12/2020: SMILer Kyle B. See is highlighted in BME Student Spotlight! [<a href="https://www.bme.ufl.edu/student-spotlight-kyle-see/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">05/30/2020: Congratulations to Skylar Stolte for her paper, 'A Survey on Medical Image Analysis in Diabetic Retinopathy', being accepted for publication in Medical Image Analysis! [<a href="https://www.sciencedirect.com/science/article/pii/S1361841520301067">Link</a>]</li>
                                                    <li style="margin-bottom:10px">05/21/2020: Congratulations to Kyle See for passing the PhD Departmental Comprehensive Exam!</li>
                                                    <li style="margin-bottom:10px">05/04/2020: Garrett Fullerton and Simon Kato have been selected for NSF REU.</li>
                                                    <li style="margin-bottom:10px">04/05/2020: Yao Xiao presented at the IEEE International Symposium on Biomedical Imaging (ISBI'20) on 'Transfer-GAN: Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Networks'! [<a href="https://ieeexplore.ieee.org/document/9098322" target="_blank">Paper</a>]</li>
                                                    <li style="margin-bottom:10px">04/30/2020: Yao Xiao has been selected as a Graduate Student Commencement Speaker at the College of Engineering Graduation Ceremony. [<a href="https://www.bme.ufl.edu/hwcoe-commencement-graduation-student-speaker-yao-xiao/" target="_blank">News</a>] [<a href="http://virtualgrad.marchingorder.com/ufl/">Speech beings at 16:28</a>]</li>
                                                    <li style="margin-bottom:10px">04/07/2020: SMILer Charlie Tran has been selected to participate in the University of Florida's Ronald E. McNair Post-Baccalaureate Achievement Program. [<a href="http://mcnair.aa.ufl.edu/about/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">04/01/2020: SMILE Lab Alumnus Daniel El Basha has been awarded the NSF Graduate Research Fellowship! [<a href="https://www.research.gov/grfp/AwardeeList.do?method=loadAwardeeList" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">03/25/2020: Yao Xiao on successfully defending her PhD dissertation!</li>
                                                    <li style="margin-bottom:10px">02/25/2020: SMILer Garret Fullerton has been accepted into UF University Scholars Program to work on machine learning for medical image optimization. [<a href="https://www.bme.ufl.edu/nine-bme-students-selected-as-university-scholars/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">02/17/2020: Yao Xiao presented at the SPIE Medical Imaging (SPIE MI'20) on 'Transfer generative adversarial network for multimodal CT image super-resolution'! [<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11313/2549533/Transfer-generative-adversarial-network-for-multimodal-CT-image-super-resolution/10.1117/12.2549533.full?SSO=1" target="_blank">Talk</a>]</li>
                                                    <li style="margin-bottom:10px">02/07/2020: Congrats to Yao Xiao for her abstract, 'Multi-Series CT Image Super-Resolution by using Transfer Generative Adversarial Network', being accepted for presenting at the 2020 Annual Meeting of the Society for Imaging Informatics in Medicine (SIIM)! [<a href="https://cdn.ymaws.com/siim.org/resource/resmgr/siim20/abstracts-research/xiao-fang_multi-series_ct_im.pdf" target="_blank">Paper</a>]</li>
                                                    <li style="margin-bottom:10px">01/06/2020: Congrats to Yao Xiao for her paper, 'Transfer-GAN: Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Networks', being accepted for publication in the IEEE International Symposium on Biomedical Imaging (ISBI'20), and awarded the ISBI (NIH, NIBIB, NCI-funded) Student Travel Award, UF GSC Student Travel Award! [<a href="https://ieeexplore.ieee.org/document/9098322" target="_blank">Paper</a>]</li>
                                                    
                                                    <!--2019-->
                                                    <li style="margin-bottom:10px">12/04/2019: Dr. Fang presented at the Annual Conference of Radiological Society of North America (RSNA) on “Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Network” with Ph.D. student Yao Xiao as the leading author. [<a href="https://rsna2019.rsna.org/" target="_blank">Link</a>]</li>
                                                    <li style="margin-bottom:10px">10/16/2019: Congrats to Yao Xiao for her abstract, 'Transfer generative adversarial network for multimodal CT image super-resolution', being accepted for presenting at the SPIE Medical Imaging (SPIE MI'20)! [<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11313/2549533/Transfer-generative-adversarial-network-for-multimodal-CT-image-super-resolution/10.1117/12.2549533.full?SSO=1" target="_blank">Paper</a>]</li>
                                                    <li style="margin-bottom:10px">09/09/2019: Dr. Fang receives an NSF award entitled "III:Small: Modeling Multi-Level Connectivity of Brain Dynamics". [<a href="https://www.bme.ufl.edu/fang-and-ding-awarded-nih-grant-to-study-brain-dynamics/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">08/30/2019: Congrats to Peng Liu on passing his dissertation qualification!</li>
												    <li style="margin-bottom:10px">08/26/2019: Kudos to Peng Liu and Dr. Fang for their first patent at UF. A Software Using a Genetic Algorithm to Automatically Build Convolutional Neural Networks for Medical Image Denoising! [<a href="https://ufinnovate.technologypublisher.com/tech/Software_Using_a_Genetic_Algorithm_to_Automatically_Build_Convolutional_Neural_Networks_for_Medical_Image_Denoising" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">08/20/2019: Welcome new Ph.D. student Kyle See to join SMILE Lab!</li>
                                                    <li style="margin-bottom:10px">08/20/2019: Congrats to our STTP students on their fantastic project presentations!</li>
												    <li style="margin-bottom:10px">07/26/2019: 'Development and Validation of Automated Imaging Differentiation in Parkinsonism: A Multi-Site Machine Learning Study' accepted for publication in The Lancet Digital Health. Congrats to SMiLE Lab and Dr. David Vaillancourt!</li>
												    <li style="margin-bottom:10px">08/20/2019: Two SSTP high school students Imaan Randhawa and Aarushi Walia successfully completed their summer research in SMiLE Lab under the supervision of Dr. Fang and PhD student Yao Xiao.</li>
												    <li style="margin-bottom:10px">06/28/2019: Dr. Fang recieves UF Informatics Institute Seed Fund Grant for research in smartphone based Diabetic Retinopath detection. [<a href="https://www.bme.ufl.edu/fang-receives-uf-informatics-institute-seed-fund-grant/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">06/13/2019: Kyle See is awarded an NIH CTSI TL1 Predoctoral Fellowship to study methods and mechanisms of cognition and motor control through data science. [<a href="https://www.bme.ufl.edu/bme-doctoral-students-awarded-nih-ctsi-tl1-predoctoral-fellowship/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">05/10/2019: Dr. Fang receives collaborative CTSI Pilot Award to study cancer therapy-induced cardiotoxicity. [<a href="https://www.bme.ufl.edu/fang-receives-collaborative-ctsi-pilot-award-for-precision-medicine/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">05/07/2019: Congrats to Yao Xiao for successfully defending her proposal</li>
												    <li style="margin-bottom:10px">04/16/2019: Congrats to Peng Liu for his paper ,'Deep Evolutionary Networks with Expedited Genetic Algorithms for Medical Image Denoising', being accepted for publication in Medical Image Analysis! [<a href="https://www.bme.ufl.edu/fang-and-researchers-manuscript-recently-published-in-medical-image-analysis/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">04/16/2019: Kudo to Yao Xiao for her paper, 'STIR-Net: Spatial-Temporal Image Restoration Net for CTPerfusion Radiation Reduction', being accepted for publication in Frontiers in Neurology, section Stroke. [<a href="https://www.bme.ufl.edu/fang-and-researchers-manuscript-recently-published-in-frontiers-in-neurology/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">04/16/2019: SMiLE Lab's Senior Design group presents their final project for Smartphone Based Diabetic Retinopathy Diagnosis.</li>
												    <li style="margin-bottom:10px">03/07/2019: Maximillian Diaz accepted to UF University Scholars Program to work on retina based Parkinson's diagnosis. [<a href="https://www.bme.ufl.edu/nine-bme-students-selected-as-university-scholars-for-2019-2020/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">01/10/2019: Dr. Fang named a senior member of IEEE. [<a href="https://www.bme.ufl.edu/fang-elevated-to-ieee-senior-member/" target="_blank">News</a>]</li>
												    
                                                    <!--2018-->
                                                    <li style="margin-bottom:10px">05/17/2018: Dr. Fang awarded University of Florida Informatics Institute and the Clinical and Translational Science Institute (CTSI) pilot funding for precision medicine. [<a href="https://www.bme.ufl.edu/fang-awarded-ctsi-pilot-program-funding/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">04/24/2018: SMiLE Lab recieves two first place awards at the Diabetic Retinopathy Segmentation and Grading Challenge. [<a href="https://www.bme.ufl.edu/smile-lab-wins-first-place-in-international-competition-on-retinal-image-analysis/" target="_blank">News</a>]</li>
												    <li style="margin-bottom:10px">03/26/2018: Akash and Akshay Mathavan accepted to UF University Scholars Program to work on environmental risk factors for ALS. [<a href="https://www.bme.ufl.edu/thirteen-uf-bme-students-selected-as-university-scholars-for-2018-2019/" target="_blank">News</a>]</li>
                                                    
                                                    <!--2017-->
                                                    <li style="margin-bottom:10px">10/30/2017: Two master students, Yangjunyi Li and Yun Liang, join SMILE Group. Welcome!</li>
                                                    <li style="margin-bottom:10px">10/01/2017: Two UF BME senior students Kyle See and Daniel El Basha join SMILE lab to work on big biomedical data anlytics research supported by NSF REU. Welcome! [<a href="https://www.bme.ufl.edu/fangs-students-awarded-reu-supplement-from-nsf/" target="_blank">News</a>]</li>
                                                    <!--<li>09/01/2017: One paper is accepted by the journal IET Image Processing on <a href="http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2017.0273">``Automatic Choroid Layer Segmentation: A Slicing Approach''</a>. Congrats to Saleha!</li>-->
                                                    <li style="margin-bottom:10px">08/2017: Yao is awarded <a href="http://www.miccai2017.org/">MICCAI 2017</a> Student Travel Award. Congrats to Yao! [<a href="https://www.bme.ufl.edu/bme-student-receives-two-prestigious-travel-awards/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">08/2017: Four papers from SMILE Lab will be presented at <a href="http://www.bmes.org/">BMES 2017</a> in Phoenix, Arizona.</li>
                                                    <li style="margin-bottom:10px">08/2017: SMILE Lab will move to J. Crayton Pruitt Family Department of Biomedical Engineering at University of Florida.</li>
                                                    <li style="margin-bottom:10px">07/2017: One paper is accepted by <a href="http://mlmi2017.web.unc.edu/" target="_blank">Machine Learning and Medical Imaging (MLMI) Workshop</a> at <a href="http://www.miccai2017.org/" target="_blank">MICCAI 2017</a>. Congrats to Yao! </li>
                                                    <li style="margin-bottom:10px">07/16/2017: Dr. Fang is invited to give a talk at the <a href="http://mic.sjtu.edu.cn/mics-2017/home" target="_blank">4th Medical Image Computing Seminar (MICS)</a> held at Shanghai Jiaotong University, Shanghai, China.</li>
                                                    <li style="margin-bottom:10px">06/2017: Yao won the NSF Travel Award to attend <a href="http://conferences.computer.org/chase2017/" target="_blank">CHASE 2017</a> in Philadelphia, PA. Congrats to Yao! [<a href="https://www.bme.ufl.edu/bme-student-receives-two-prestigious-travel-awards/" target="_blank">News</a>]</li>
                                                    <li style="margin-bottom:10px">05/2017: Dr. Fang is invited by NSF as a panelist of Smart and Connect Health.</li>
                                                    <li style="margin-bottom:10px">05/2017: One paper is accepted by <a href="http://conferences.computer.org/chase2017/" target="_blank">CHASE 2017</a>. Congrats to Yao! </li>
                                                    <li style="margin-bottom:10px">04/2017: One paper is accepted by <a href="http://www.miccai2017.org/" target="_blank">MICCAI 2017</a>. Congrats to Ling! </li>
                                                    <li style="margin-bottom:10px">04/2017: Dr. Fang is invited to give a talk at the <a href="http://www.worldbrainmapping.org/" target="_blank">Society for Brain Mapping and Therapeutics</a> Annual Meeting in Los Angeles, CA. </li>
                                                    <li style="margin-bottom:10px">03/2017: Dr. Fang attended NSF Smart and Connected Health PI Meeting held in Boston, MA. </li>
                                                    
                                                    <!--2016-->
                                                    <li style="margin-bottom:10px">10/2016: PhD student Maryamossadat Aghili has been awarded travel grants from NIPS WiML 2016 Program Committee and FIU GPSC to attend WiML of NIPS 2016 in Barcelona. </li>
                                                    <li style="margin-bottom:10px">09/2016: Dr. Fang is invited by NIH to review in BDMA study section.</li>
                                                    <li style="margin-bottom:10px">09/2016: One paper is accepted by Pattern Recognition!</li>
                                                    <li style="margin-bottom:10px">08/2016: Dr. Fang is selected as an Early Career Grant Reviewer by NIH.</li>
                                                    <li style="margin-bottom:10px">08/2016: SMILE REU and RET students and teachers won the 2016 Best REU and RET Poster Awards at SCIS of FIU.</li>
                                                    <li style="margin-bottom:10px">07/2016: Our paper "Abdominal Adipose Tissues Extraction Using Multi-Scale Deep Neural Network" is accepted by NeuroComputing!</li>
                                                    <li style="margin-bottom:10px">04/2016: PhD student Maryamossadat Aghili has been awarded travel grants to attend Grad Cohort Conference (CRAW).</li>
                                                    <li style="margin-bottom:10px">05/2016: Dr. Fang's research appeared on FIU News: <a href="http://news.fiu.edu/2016/05/professor-uses-computer-science-to-reduce-patients-exposure-to-radiation-from-ct-scans/101015" target="_blank">Professor uses computer science to reduce patients' exposure to radiation from CT scans</a>!</li>
                                                    <li style="margin-bottom:10px">05/2016: <b>Dr. Fang has been selected to receive the <a href="http://www.orau.org/university-partnerships/faculty-student-programs/powe/powe-winners.aspx" target="_blank">2016 Ralph E. Powe Junior Faculty Enhancement Award</a> from Oak Ridge Associated Universities!</b></li>
                                                    <li style="margin-bottom:10px">05/2016: <b>Dr. Fang received funding from NSF on CRII (Pre-CAREER) Award on "<a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1564892" target="_blank">Characterizing, Modeling and Evaluating Brain Dynamics</a>"!</b></li>
                                                    <li style="margin-bottom:10px">04/2016: Our paper "TENDER: TEnsor Non-local Deconvolution Enabled Radiation Reduction in CT Perfusion" is accepted by NeuroComputing!</li>
                                                    <li style="margin-bottom:10px">04/09/2016: <b>Dr. Fang is awarded the first <a href="http://research.fiu.edu/research-faculty-honors-highlights/" target="_blank">Robin Sidhi Memorial Young Scientist Award</a> from the Annual Congress of <a href="http://www.worldbrainmapping.org/" target="_blank">Society of Brain Mapping and Therapeutics</a> for recognizing her continuous devotion to bridge information technology and health informatics. </b></li>
                                                    <li style="margin-bottom:10px">03/2016: Our paper "<a href=http://users.cis.fiu.edu/~rfang/publications/ACM16_Survey.pdf" target="_blank">"Computational Health Informatics in the Big Data Age: A Survey</a>" is accepted by the prestigous ACM Computing Survey!</li>
                                                    <li style="margin-bottom:10px">01/2016: Dr. Fang is invited by NSF as a panel reviewer of Smart and Connect Health.</li>
                                                    
                                                    <!--2015-->
                                                    <li style="margin-bottom:10px">12/2015: Dr. Fang serves as the Publicity Chair of the <a href="http://www.icmla-conference.org/icmla15/#">14th IEEE International Conference on Machine Learning and Applications 2015</a>.</li>
                                                    <li style="margin-bottom:10px">04/2015: Dr. Fang is invited by NSF as a panel reviewer of Smart and Connect Health.</li>
                                                </ul>
                                            </div>
                                        </td>
                                    </tr>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/News-->

                    <!--Honors & Distinctions-->
                    <div class="section color-1">
                        <div class="section-container">
                            <div class="row">
                                <div class="col-md-10 col-md-offset-1">
                                    <div class="title text-center">
                                        <h3>Honors & Distinctions</h3>
                                    </div>
                                    <div style="height: 350px; overflow: auto;">
                                    <ul class="timeline">
                                        <li class="open">
                                            <div class="date">2024</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://bme.ufl.edu/dr-ruogu-fang-and-ph-d-student-skylar-stolte-win-pioneering-research-hipergator-award/" class="tooltips" title="News" target="_blank">Pioneering Research HiPerGator Award</a></div>
                                                <div><h5>University of Florida Research Computing</h5></div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2024</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://bme.ufl.edu/fang-receives-inaugural-ai-course-award/" class="tooltips" title="News" target="_blank">Inaugural AI Course Award</a></div>
                                                <div><h5>University of Florida</h5></div>
                                            </div>
                                        </li>                                        
                                        
                                        <li class="open">
                                            <div class="date">2024</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="" class="tooltips" title="News" target="_blank">Senior Member Grade</a></div>
                                                <div><h5>National Academy of Inventors (NAI)</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2024</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://bme.ufl.edu/fang-receives-distinguished-recognition-as-rising-stars-engineering-from-the-academy-of-science-engineering-and-medicine-of-florida/" class="tooltips" title="News" target="_blank">Best Paper Award</a></div>
                                                <div><h5>The 17th International Conference on Health Informatics (HEALTHINF/BIOSTEC), Italy, Rome</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2023</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="" class="tooltips" title="News" target="_blank">Rising Star Award</a></div>
                                                <div><h5>Academy of Science, Engineering and Medicine of FL (ASEMFL)</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2022</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="" class="tooltips" title="News" target="_blank">Pruitt Family Endowed Faculty Fellowship</a></div>
                                                <div><h5>University of Florida</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2022</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://www.bme.ufl.edu/2021-bme-departmental-excellence-award-winners-announced" class="tooltips" title="News" target="_blank">Tenure and Promotion to Associate Professor</a></div>
                                                <div><h5>University of Florida</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2022</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://www.bme.ufl.edu/2021-bme-departmental-excellence-award-winners-announced" class="tooltips" title="News" target="_blank">Faculty Award for Excellence in Innovation</a></div>
                                                <div><h5>Herbert Wertheim College of Engineering, University of Florida</h5></div>
                                            </div>
                                        </li>
                                         
                                    
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://www.bme.ufl.edu/2021-bme-departmental-excellence-award-winners-announced/" class="tooltips" title="News" target="_blank">Faculty Research Excellence Award</a></div>
                                                <div><h5>J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida</h5></div>
                                            </div>
                                        </li>
                                        
                                        
                                        <li class="open">
                                            <div class="date">2020</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://news.ufl.edu/2020/12/artificial-intelligence-research-catalyst-fund-/" class="tooltips" title="News" target="_blank">Artificial Intelligence Catalyst Award</a></div>
                                                <div><h5>NVIDIA-University of Florida</h5></div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2020</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://news.ufl.edu/2020/12/artificial-intelligence-research-catalyst-fund-/" class="tooltips" title="News" target="_blank">Great Teaching Certificate</a></div>
                                                <div><h5>University of Florida Center for Teaching Excellence</h5></div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2020</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://pharmacy.ufl.edu/2018/03/27/uf-leads-all-pharmacy-colleges-with-four-ascpt-presidential-trainee-awards/" class="tooltips" title="News" target="_blank">David Goldstein M.D., Ph.D., Presidential Trainee Award</a></div>
                                                <div>
                                                    <h5>For the highest-scoring abstract, Co-Authored Paper</h5>
                                                    <h5>American Society for Clinical Pharmacology and Therapeutics Annual Meeting in Houston, TX, March 18-21, 2020.</h5></div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2018</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://www.bme.ufl.edu/fang-elevated-to-ieee-senior-member/">IEEE Senior Member Grade</a></div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2018</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Top-ranked (#1) in “Fovea Detection” System, First International Diabetic Retinopathy Grading and Segmentation Challenge</div>
                                                <div><h5>IEEE International Symposium of Biomedical Imaging</h5></div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2018</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Top-ranked (#1) in “Optical Disc Segmentation” System, First International Diabetic Retinopathy Grading and Segmentation Challenge</div>
                                                <div><h5>IEEE International Symposium of Biomedical Imaging</h5></div>
                                            </div>
                                        </li>


                                       <li class="open">
                                            <div class="date">2017</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject"><a href="https://www.bme.ufl.edu/fang-selected-to-acms-future-of-computer-academy/">Future Academy of Computing</a></div>
                                                <div><h5>Association for Computing Machinery (ACM)</h5></div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2017</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Robin Sidhu Memorial Young Scientist Award</div>
                                                <div>
                                                    <h5>Society of Brain Mapping and Theurapeutics</h5>
                                                    <h5>Covered by PR Newswire, Yahoo,  <a href="http://news.fiu.edu/2016/05/professor-uses-computer-science-to-reduce-patients-exposure-to-radiation-from-ct-scans/101015" target="_blank" >NEWS</a></h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2016</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">NSF Best REU and RET Poster Awards</div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/reu.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                        Dr. Fang's mentee, Paul Naghshineh from George Washington University, won the Best REU Poster Award at the annual REU Symposium at FIU. Christian McDonald with Edda I. Rivera, teachers from Miami Jackson Senior High School and John A. Ferguson Senior High School, under Dr. Fang's mentorship, won the Best RET Poster Award. Congratulations to Paul, Christian and Edda!
                                                    </div>
                                                </div>
                                            </div>
                                        </li>


                                        <li class="open">
                                            <div class="date">2016</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Ralph E. Powe Junior Faculty Enhancement Award</div>
                                                <div>
                                                    <h5>Oak Ridge Associated Universities</h5>
                                                </div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/ORAU.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                        Dr. Fang has been selected to receive the 2016 Ralph E. Powe Junior Faculty Enhancement Award from Oak Ridge Associated Universities (two nominations from each institute, 35 awardees out of 132 applicants).
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2016</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">NSF IIS CRII Award on "Characterizing, Modeling and Evaluating Brain Dynamics" <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1564892" class="tooltips" title="News" target="_blank"><i class="fa fa-external-link"></i></a></div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/nsf.jpg" >
                                                    </div>
                                                </div>
                                            </div>
                                        </li>


                                        <li>
                                            <div class="date">2015</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">CISE CAREER Workshop Travel Award </div>
                                                <div>
                                                    <h5>National Science Foundation</h5>
                                                </div>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="date">2014</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Hsien Wu and Daisy	Yen	Wu Memorial	Award</div>
                                                <div><h5>Cornell University</h5></div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/cu.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                    In recognition	of the	excellent progress in the academic program and high potential for a successful academic career (5 awardees out	of all graduate students at Cornell University).
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        <!---
                                        <li>
                                        <div class="date">2014</div>
                                        <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Student Travel	Award at MICCAI</div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/miccai.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                        Student	Travel Award at the	International Conference on	Medical	Image Computing	and Computer Assisted Intervention (MICCAI)	2014.
                                                    </div>
                                                </div>
                                            </div>
                                        </li>
                                        --->

                                        <li>
                                            <div class="date">2012</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">ECE Women's Conference	Travel Grant</div>
                                                <div><h5>IBM-Cornell University</h5></div>
                                            </div>
                                        </li>

                                        <li>
                                        <div class="date">2010</div>
                                        <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Best Paper Award</div>
                                                <div><h5>IEEE International Conference on Image Processing (ICIP)</h5></div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/icip.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                        Best Paper Award at	the	17th International Conference on Image Processing, 2010. (Top 1 out	of 1190 accepted papers, first author publication)
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2010</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Best PhD Poster Award, Cornell Engineering </div>
                                                <div><h5>Cornell Engineering Research Conference</h5></div>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="date">2009</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Irwin and Joan	Jacobs Fellowship</div>
                                                <div><h5>Cornell University</h5></div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/cu.jpg" >
                                                    </div>
                                                <div class="col-md-10">
                                                    Awarded	to students	who	exemplify strength and potential in academics, service,	and	leadership,	2009-2010
                                                </div>
                                                </div>
                                            </div>
                                        </li>


                                    </ul>

                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/Honors & Distinctions-->

                    <!--Grants & Awards-->
                    <div class="section color-2">
                        <div class="section-container">
                            <div class="row">
                                <div class="col-md-10 col-md-offset-1">
                                    <div class="title text-center">
                                        <h3>Grants & Awards</h3>
                                    </div>
                                    <div style="height: 350px; overflow: auto;">
                                    <ul class="timeline">
                                        <li class="open">
                                            <div class="date">2023</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">DRPD-ROF2023: Learning optimal treatment strategies for hypotension in critical care patients with acute kidney injury using artificial intelligence</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Amount: $86,500</h5>
                                                    <h5>Role: Co-I (PI: Tezcan Ozrazgat Baslanti, Co-I: Jessica Ray)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2023</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">NCS-FO-2318984: Brain-Informed Goal-Oriented and Bidirectional Deep Emotion Inference</div>
                                                <div>
                                                    <h5>Funding: National Science Foundation, Integrative Strategies for Understanding Neural and Cognitive Systems (NCS)</h5>
                                                    <h5>Amount: $920,000</h5>
                                                    <h5>Role: Principal Investigator</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2023</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">R01: Cognitively engaging walking exercise and neuromodulation to enhance brain function in older adults</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute of Aging (NIA)</h5>
                                                    <h5>Amount: $4.8M</h5>
                                                    <h5>Role: Co-I (PI: David Clark, University of Florida)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2022</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">P01AI165380: Multi-Scale Evaluation and Mitigation of Toxicities Following Internal Radionuclide Contamination</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute of Allergy and Infectious Diseases (NIAID)</h5>
                                                    <h5>Amount: $10.7M ($1.95M to UF)</h5>
                                                    <h5>Role: Co-I (PI: Gayle E. Woloschak, Northwestern University)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">RF1: Mechanisms, response heterogeneity and dosing from MRI-derived electric field models in tDCS augmented cognitive training: a secondary data analysis of the ACT study (R01-equivalent)</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute of Aging (NIA)</h5>
                                                    <h5>Amount: $2.9M</h5>
                                                    <h5>Role: Principal Investigator (MPI: Ruogu Fang & Adam Woods)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Collaborative Research: SCH: Trustworthy and Explainable AI for Neurodegenerative Diseases</div>
                                                <div>
                                                    <h5>Funding: National Science Foundation, Smart and Connected Health [<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2123809" target="_blank">Link</a>]</h5>
                                                    <h5>Amount: $1.2M ($840K to UF)</h5>
                                                    <h5>Duration: 2021-2025</h5>
                                                    <h5>Role: Co-Principal Investigator (PI: My Thai)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">U24AA029959: Southern HIV and Alcohol Research Consortium Biomedical Data Repository</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute on Alcohol Abuse and Alcoholism (NIAAA)</h5>
                                                    <h5>Amount: $2.5M</h5>
                                                    <h5>Role: Co-Investigator (PI: Samuel Wu, Robert Cook)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">P01AA029547: SHARE Program: Innovations in Translational Behavioral Science to Improve Self- management of HIV and Alcohol Reaching Emerging adults</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute on Alcohol Abuse and Alcoholism (NIAAA)</h5>
                                                    <h5>Amount: $3M</h5>
                                                    <h5>Role: Co-Investigator (PI: Samuel Wu)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">P01AA029543: Interventions to improve alcohol-related comorbidities along the gut-brain axis in persons with HIV infection</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute on Alcohol Abuse and Alcoholism (NIAAA)</h5>
                                                    <h5>Amount: $6.6M</h5>
                                                    <h5>Role: Co-Investigator (PI: Robert Cook)</h5>
                                                </div>
                                            </div>
                                        </li>
                                        
                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">R01: Acquisition, extinction, and recall of attention biases to threat: Computational modeling and multimodal brain imaging</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute of Mental Health (NIMH)</h5>
                                                    <h5>Amount: $2.3M</h5>
                                                    <h5>Role: Co-Investigator (MPI: Mingzhou Ding & Andreas Keil)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2021</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">U01: Web-based Automated Imaging Differentiation of Parkinsonism</div>
                                                <div>
                                                    <h5>Funding: National Institute of Health, National Institute of Neurological Disorders and Stroke (NINDS)</h5>
                                                    <h5>Amount: $5.2M</h5>
                                                    <h5>Role: Co-investigator (PI: David Vaillancourt)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2020</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Artificial Intelligence Catalyst Award: VCA-DNN: Neuroscience-Inspired Artificial Intelligence for Visual Emotion Recognition</div>
                                                <div>
                                                    <h5>Funding: NVIDIA - Universit of Florida</h5>
                                                    <h5>Amount: $50,000</h5>
                                                    <h5>Role: Principal Investigator (Co-PI: Mingzhou Ding)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2020</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">UFII: Biology and Cognition Inspired Deep Learning</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Role: Mentor (Mentee: Peng Liu)</h5>
                                                </div>
                                            </div>
                                        </li>


                                        <li class="open">
                                            <div class="date">2019</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">III: Small: Modeling Multi-Level Connectivity of Brain Dynamics</div>
                                                <div>
                                                    <h5>Funding: National Science Foundation <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1908299&HistoricalAwards=false"><i class="fa fa-external-link"></i></a></h5>
                                                    <h5>Amount: $823,000</h5>
                                                    <h5>Role: Principal Investigator (Co-PI: Mingzhou Ding)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2019</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">UFII Junior SEED Award: Multimodal Visual-Text Learning from Clinical Narrative and Image for Early Detection of Diabetic Retinopathy</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Amount: $40,000</h5>
                                                    <h5>Role: Co-Principal Investigator (PI: Yonghui Wu)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2019</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">UFII-CTSI Pilot Award: Toward prevention of cardiotoxicity in cancer: a multimodal approach leveraging genomics, images and clinical data</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Amount: $60,000</h5>
                                                    <h5>Role: Co-Principal Investigator (PI: Yan Gong)</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2019</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">NIH CTSI TL1: Predicting short-term and long-term effects of spinal cord stimulation: implications for clinical practice</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Role: Mentor (Mentee: Kyle B. See)</h5>
                                                </div>
                                            </div>
                                        </li>

                                         <li class="open">
                                            <div class="date">2018</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">UFII-CTSI Pilot Award: PrecisionDose:Personalized Radiation Dose Optimization for Multimodal Imaging</div>
                                                <div>
                                                    <h5>Funding: University of Florida</h5>
                                                    <h5>Amount: $75,000</h5>
                                                    <h5>Role: Principal Investigator</h5>
                                                </div>
                                            </div>
                                        </li>

                                        <li class="open">
                                            <div class="date">2018</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Phase I IUCRC University of Florida: Center for Big Learning</div>
                                                <div>
                                                    <h5>Funding: National Science Foundation (<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747783" target="_blank">NSF Abstract</a>)</h5>                     
                                                    <h5>Amount: $1,050,478</h5>
                                                    <h5>Role: Senior Personnel (PI: Dapeng Wu)</h5>
                                                </div>
                                            </div>
                                        </li>


                                        <li class="open">
                                            <div class="date">2016</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">Ralph E. Powe Junior Faculty Enhancement Award</div>
                                                <div>
                                                    <h5>Funding: Oak Ridge Associated Universities (ORAU)</h5>
                                                    <h5>Amoung: $10,000</h5>
                                                    <h5>Role: Principal Investigator</h5>
                                                </div>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="date">2016</div>
                                            <div class="circle"></div>
                                            <div class="data">
                                                <div class="subject">CRII: Characterizing, Modeling and Evaluating Brain Dynamics<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1564892"></a></div>
                                                <div>
                                                    <h5>Funding: National Science Foundation</h5>
                                                    <h5>Amount: $190,991</h5>
                                                    <h5>Role: Principal Investigator</h5>
                                                </div>
                                                <div class="text row">
                                                    <div class="col-md-2">
                                                        <img alt="image" class="thumbnail img-responsive" src="img/personal/nsf.jpg" >
                                                    </div>
                                                    <div class="col-md-10">
                                                    <p>Brain dynamics, which reflects the healthy or pathological states of the brain with quantifiable, reproducible, and indicative dynamics values, remains the least understood and studied area of brain science despite its intrinsic and critical importance to the brain. Unlike other brain information such as the structural and sequential dimensions that have all been extensively studied with models and methods successfully developed, the 5th dimension, dynamics, has only very recently started receiving systematic analysis from the research community. The state-of-the-art models suffer from several fundamental limitations that have critically inhibited the accuracy and reliability of the dynamic parameters' computation. First, dynamic parameters are derived from each voxel of the brain spatially independently, and thus miss the fundamental spatial information since the brain is connected? Second, current models rely solely on single-patient data to estimate the dynamic parameters without exploiting the big medical data consisting of billions of patients with similar diseases.</p>
                                                    <p>This project aims to develop a framework for data-driven brain dynamics characterization, modeling and evaluation that includes the new concept of a 5th dimension – brain dynamics – to complement the structural 4-D brain for a complete picture. The project studies how dynamic computing of the brain as a distinct problem from the image reconstruction and de-noising of convention models, and analyzes the impact of different models for the dynamics analysis. A data-driven, scalable framework will be developed to depict the functionality and dynamics of the brain. This framework enables full utilization of 4-D brain spatio-temporal data and big medical data, resulting in accurate estimations of the dynamics of the brain that are not reflected in the voxel-independent models and the single patient models. The model and framework will be evaluated on both simulated and real dual-dose computed tomography perfusion image data and then compared with the state-of-the-art methods for brain dynamics computation by leveraging collaborations with Florida International University Herbert Wertheim College of Medicine, NewYork-Presbyterian Hospital / Weill Cornell Medical College (WCMC) and Northwell School of Medicine at Hofstra University. The proposed research will significantly advance the state-of-the-art in quantifying and analyzing brain structure and dynamics, and the interplay between the two for brain disease diagnosis, including both the acute and chronic diseases. This unified approach brings together fields of Computer Science, Bioengineering, Cognitive Neuroscience and Neuroradiology to create a framework for precisely measuring and analyzing the 5th dimension – brain dynamics – integrated with the 4-D brain with three dimensions from spatial data and one dimension from temporal data. Results from the project will be incorporated into graduate-level multi-disciplinary courses in machine learning, computational neuroscience and medical image analysis. This project will open up several new research directions in the domain of brain analysis, and will educate and nurture young researchers, advance the involvement of underrepresented minorities in computer science research, and equip them with new insights, models and tools for developing future research in brain dynamics in a minority serving university.</p>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>
                                        <li>

                                    </ul>

                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/Grants & Awards-->

                    <!--Academic Positions-->
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">

                                    <!--First Column Part 1-->
                                    <div class="col-md-5">

                                        <div class="title text-center">
                                            <h3>Education</h3>
                                        </div>

                                        <ul class="ul-card">
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Ph.D.</span>
<!--                                                    <span class="year">2014</span>-->
                                                </div>
                                                <div class="description">
                                                    <p class="what">Ph.D. in Electrical	and Computer Engineering</p>
                                                    <p class="where">Cornell University, Ithaca, NY.</p>
                                                </div>
                                            </li>

                                            <!--<li>
                                                <div class="dy">
                                                    <span class="degree">B.A.</span><span class="year">2007</span>
                                                </div>
                                                <div class="description">
                                                    <p class="what">Full-time Exchange in Electrical and	Communication Engineering</p>
                                                    <p class="where">University	of Hong	Kong,Hong Kong</p>
                                                </div>
                                            </li>-->

                                            <li>
                                                <div class="dy">
                                                    <span class="degree">B.E.</span>
<!--                                                    <span class="year">2009</span>-->
                                                </div>
                                                <div class="description">
                                                    <p class="what">B.E. in Information Engineering</p>
                                                    <p class="where">Zhejiang University, Hangzhou, China</p>
                                                </div>
                                            </li>
                                        </ul>

                                        <!--First Column Part 2-->
                                        <div class="title text-center">
                                            <h3>Professional Service (Selected)</h3>
                                        </div>

                                        <ul class="ul-card">
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">President</span>
                                                    <span class="year">2023-Present</span>
                                                </div>
                                                <div class="description">
                                                    <p class="what">Women in MICCAI (WiM)</p>
                                                    <p class="where">Medical Image Computing and Computer Assisted Intervention (MICCAI) Society</p>
                                                </div>
                                            </li>

                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Associate Editor</span>
                                                    <!--<span class="year">2023-Present</span> -->
                                                </div>
                                                <div class="description">
                                                    <p class="what">Medical Image Analysis</p>
                                                </div>
                                            </li>

                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Area Chair</span>
                                                    <span class="year">2022-Present</span>
                                                </div>
                                                <div class="description">
                                                    <p class="what">MICCAI Conference</p>
                                                    <p class="where">The International Conference on Medical Image Computing and Computer Assited Intervention (MICCAI)</p>
                                                </div>
                                            </li>

                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Reviewer</span>
                                                    <!--<span class="year">2022-Present</span>-->
                                                </div>
                                                <div class="description">
                                                    <p class="where">The Lancet, Nature Machine Intelligence, Science Advances, IEEE TPAMI, IEEE TNNLS, MIA, IEEE TMI, IEEE TIP</p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>



                                    <!--Second Column-->
                                   <div class="col-md-5 col-md-offset-1">

                                        <div class="title text-center">
                                            <h3>Academic Positions</h3>
                                        </div>

                                        <!--1st Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
                                                    <span>BME</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Tenured Associate Professor</h4>
                                                    <p><em>University of Florida</em> J. Crayton Pruitt Family Department of Biomedical Engineering</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/1st Position-->
                                        
                                       <!--2nd Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2017</span>-->
                                                    <span>IC3</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Associate Director</h4>
                                                    <p><em>University of Florida</em> UF Intelligent Critical Care Center (IC3)</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/2nd Position-->
                                       
                                       
                                        <!--3rd Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2017</span>-->
                                                    <span>ECE</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affliated Faculty</h4>
                                                    <p><em>University of Florida</em> Department of Electrical and Computer Engineering</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/3rd Position-->

                                        <!--4th Position-->
                                         <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2018</span>-->
                                                    <span>COM</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> Department of Radiology, College of Medicine</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/4th Position-->

                                        <!--/5th Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2019</span>-->
                                                    <span>CISE</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> Department of Computer & Information Science & Engineering</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/5th Position-->

                                        <!--6th Position-->
                                         <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2020</span>-->
                                                    <span>CAM</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> The Center for Cognitive Aging and Memory Clinical Translational Research (CAM)</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/6th Position-->

                                        <!--7th Position-->
                                         <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2020</span>-->
                                                    <span>UFGI</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> Genetics Institute (UFGI) </p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/7th Position-->

                                        <!--8th Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2020</span>-->
                                                    <span>UFCC</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> UF Health Cancer Center</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/8th Position-->
                                       
                                        <!--9th Position-->
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
<!--                                                    <span>Present</span>-->
<!--                                                    <span>2020</span>-->
                                                    <span>EPI</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Affiliated Faculty</h4>
                                                    <p><em>University of Florida</em> Emerging Pathogens Institute</p>
                                                </div>
                                            </li>
                                        </ul>
                                        <!--/9th Position-->

                                        <!--
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
                                                    <span>2017</span>
                                                    <span>2014</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Tenure-Track Assistant Professor</h4>
                                                    <p><em>Florida International University</em> School of Computing and Information Sciences</p>
                                                </div>
                                            </li>
                                        </ul>
                                        -->
                                    </div>
                                    <!--/Second Column-->

                                </div>
                            </div>
                        </div>
                        <!--/Academic Positions-->

                       

                    <!--Acknowledgements-->
                    <div class="section color-2">
                        <div class="section-container">
                            <div class="row">
                                <div class="col-md-10 col-md-offset-1">
                                    <div class="title text-center">
                                        <h3>Acknowledgements</h3>
                                    </div>
                                    <ul>
                                        <li class="open">
                                            <div class="data">
                                                <div class="">Our work is supported by:</div><br>
                                                <img alt="image" src="img/acknowlegements/nsf_logo.gif" >
                                                <img alt="image" height="166" src="img/acknowlegements/nih.jpg" >
                                                <img alt="image" height="166" src="img/acknowlegements/DHS.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/DoD.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/orau.jpg" >
                                                <img alt="image" height="166" src="img/acknowlegements/nvidia.jpg" >
                                                <img alt="image" height="166" src="img/acknowlegements/Oracle.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/sbmt.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/uf.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/UFII.png" >
                                                <img alt="image" height="166" src="img/acknowlegements/CTSI.png" >
                                                <img alt="image" height="140" src="img/acknowlegements/MBRF.png" >
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/About me-->

                <!--Team-->
                <div id="team" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Team</h2>
                                <div class="row">
                                    <div class="col-md-24">
                                        <p></p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">

                                <!--Current Members-->
                                <div class="title text-center">
                                    <h1>Current Members</h1>
                                </div>

<!--####################-->
<!-- Postdoc Researchers-->     <h3>Postdoc Researchers</h3>
<!--####################-->  

<!--Peng-->                     <a href="https://rocmind.com/" target="_blank">
                                    <div class="member">
                                        <img src="img/lab/pengliu.jpg" width="200" height="200" class="img-circle lab-img">
                                        <div class="bio">
                                            <h3><b>Peng Liu</b></h3>
                                            <h4><i>Postdoc, 2023-Now</i></h4>
                                            <h5>Ph.D. in Biomedical Engineering, University of Florida, 2021</h5>
                                            <h5>Postdoc, Psychology and Brain Science, Dartmouth College, 2022-2023</h5>
                                        </div>
                                    </div>
                                </a>


<!--Diandra-->                     <a href="" target="_blank">
                                <div class="member">
                                    <img src="img/lab/Diandra_Ojo.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Diandra Ojo</b></h3>
                                        <h4><i>Postdoc, 2023-Now</i></h4>
                                        <h4>Co-mentor with Dr. Ivana Parker</h4>
                                        <h5>Ph.D. in Computer Science, University of Florida, 2023</h5>
                                    </div>
                                </div>
                            </a>

<!--#############-->
<!-- PhD Students-->            <h3>Ph.D. Students</h3>
<!--#############-->            
<!-- JQ
                                <div class="member">
                                    <img src="img/lab/jq.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jianqiao Tian</b></h3>
                                        <h4><i>PhD Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
-->

<!-- Kyle-->                    <a href="https://kyuros.github.io/kylesee/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/kylesee.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Kyle See</b></h3>
                                        <h4><i>Ph.D. Candidate, 2019-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                        <h5>UF Graduate Student Preeminence Award</h5>
                                        <h5>NIH CTSI TL1 Predoctoral Fellowship</h5>
                                        <!--<div class="bmail">sample@ufl.edu</div>-->
                                        <!-- <div class="btags2 btw">Machine Learning in Somatotopy</div>
                                        <div class="btags2 btw">Autoimmune Disease Analytics</div> -->
                                    </div>
                                </div>
                                </a>

<!-- Skylar-->	                <a href="https://skylarstolte.github.io/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/skylarstolte.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Skylar Stolte</b></h3>
                                        <h4><i>Ph.D. Candidate, 2020-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                        <h5>UF Graduate Student Preeminence Award, Attributes of a Gator Engineer Award</h5>
                                        <!-- <div class="btags2 btw">Cardiotoxicity Prediction</div>
                                        <div class="btags2 btw">Longitudinal Glaucoma Study</div> -->
                                    </div>
                                </div>
                                </a>

<!--Charlie                  <a href="https://www.linkedin.com/in/charlie-tran-7808a0178/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/charlietran.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Charlie Tran</b></h3>
                                        <h4><i>Ph.D. Student, 2021-Now</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                        <h5>McNair Scholars Program</h5>
                                    </div>
                                </div>
                                </a>
-->

<!--Seowung Leem-->             <a href="https://www.linkedin.com/in/seowung-leem-1254951ba/?originalSubdomain=kr" target="_blank">
                                <div class="member">
                                    <img src="img/lab/seowung.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Seowung Leem</b></h3>
                                        <h4><i>Ph.D. Student, 2021-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
                                </a>
 
<!--Joseph Cox-->               <div class="member">
                                    <img src="img/lab/JosephCox.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Joseph Cox</b></h3>
                                        <h4><i>Ph.D. Student, 2022-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                        <h5>NIH NIAAA T32 Fellow</h5>
                                    </div>
                                </div>
                                
<!--Chaoyue Sun-->              <div class="member">
                                    <img src="img/lab/ChaoyueSun.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Chaoyue Sun</b></h3>
                                        <h4><i>Ph.D. Student, 2020-Now</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                    </div>
                                </div>
                                

<!--Tianqi-->                   <div class="member">
                                    <img src="img/lab/tianqiliu.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Tianqi Liu</b></h3>
                                        <h4><i>Ph.D. Student, 2019-Now</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                    </div>
                                </div>

<!--Zhuobiao-->                 <div class="member">
                                    <img src="img/lab/zhuobiaoqiao.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Zhuobiao Qiao</b></h3>
                                        <h4><i>Ph.D. Student, 2021-Now</i></h4>
                                        <h4>Electrical Engineering</h4>
                                    </div>
                                </div>

<!--Pankaj                  <div class="member">
                                    <img src="img/lab/pankajchand.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Pankaj Chand</b></h3>
                                        <h4><i>Ph.D. Student, 2021-Now</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>
--> 

<!--Daniel-->                   <div class="member">
                                    <img src="img/lab/danielrodriguez.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Daniel Rodriguez</b></h3>
                                        <h4><i>Ph.D. Student, 2022-Now</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                        <h5>NIH T1D T32 Fellow</h5>
                                    </div>
                                </div>
                                
<!-- Rachel Ho	                <div class="member">
                                    <img src="img/lab/rachelho.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Rachel Ho</b></h3>
                                        <h4><i>APK Ph.D. Student</i></h4>
                                        <h4>Applied Physiology and Kinesiology</h4>
                                        <h5>NIH CTSI TL1 Predoctoral Fellowship</h5>
                                        <h5>Co-advised with Dr. Steven Coombes via TL1 Program</h5>
                                    </div>
                                </div>
-->
   
<!--#############-->            <br>
<!-- Co-advise PhD -->            <h3>Co-advise or Collaborating PhD Students</h3>
<!--#############-->            <br>

<!--Boxiao Yu-->             <div class="member">
                                <img src="img/lab/BoxiaoYu.jpeg" width="200" height="200" class="img-circle lab-img">
                                <div class="bio">
                                    <h3><b>Boxiao Yu</b></h3>
                                    <h4><i>Ph.D. Student, 2022-Now</i></h4>
                                    <h4>Biomedical Engineering</h4>
                                </div>
                            </div>

<!--Ziqian Huang-->             <div class="member">
                                    <img src="img/lab/ZiqianHuang.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Ziqian Huang</b></h3>
                                        <h4><i>Ph.D. Student, 2022-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>



<!--#############-->            <br>
<!-- MS Students -->            <h3>M.S. Students</h3>
<!--#############-->            <br>
                                
<!--Everett-->                  <div class="member">
                                    <img src="img/lab/EverettSchwieg.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Everett J. Schwieg</b></h3>
                                        <h4><i>M.S. Student, 2022-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>            
                                
<!--Fan-->                      <div class="member">
                                    <img src="img/lab/FanYang.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Fan Yang</b></h3>
                                        <h4><i>M.S. Student, 2022-Now</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                    </div>
                                </div>      
                                
<!--Travis-->                   <div class="member">
                                    <img src="img/lab/traviskoenig.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Travis Koenig</b></h3>
                                        <h4><i>M.S. Student, 2023-Now</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>  
                    
<!--Pratyush-->                 <div class="member">
                                    <img src="img/lab/pratyushshukla.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Pratyush Shukla</b></h3>
                                        <h4><i>M.S. Student, 2023-Now</i></h4>
                                        <!--<h4>Electrical and Computer Engineering</h4>-->
                                    </div>
                                </div>  
            
                                          
<!--#####################-->    <br>                     
<!-- Research Assistants -->   <!---- <h3>Research Assistants</h3> -->
<!--#####################-->   

                                

<!--#######################-->  <br>
<!-- Undergraduate Students-->  <h3>Undergraduate Students</h3>
<!--#######################-->                                

<!--Kevin-->                    <div class="member">
                                    <img src="img/lab/kevinliu.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Kevin Liu</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Physics</h4>
                                    </div>
                                </div>

<!--Eugene                   <div class="member">
                                    <img src="img/lab/eugeneli.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Eugene Li</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science and Math</h4>
                                    </div>
                                </div>
-->


<!--Matthew                  <div class="member">
                                    <img src="img/lab/matthewnguyen.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Matthew Nguyen</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
    -->

<!--Ethan-->                    <div class="member">
                                    <img src="img/lab/ethansmith.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Ethan Smith</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Psychology</h4>
                                    </div>
                                </div>

<!--Thomas-->                   <div class="member">
                                    <img src="img/lab/thomashowland.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Thomas Howland</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>

<!--Justin-->                   <div class="member">
                                    <img src="img/lab/justinbroce.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Justin Broce</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>

<!--Kyle-->                     <div class="member">
                                    <img src="img/lab/kyledouglas.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Kyle Douglas</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>

<!--Akshay-->                   <div class="member">
                                    <img src="img/lab/akshayashok.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Akshay Ashok</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                        <h5>UF AI Scholar</h5>
                                    </div>
                                </div>
                        
<!--Veronica-->                 <div class="member">
                                    <img src="img/lab/veronicaramos.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Veronica Ramos</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>

<!--Thrisha-->                  <div class="member">
                                    <img src="img/lab/thrishaacharya.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Thrisha Acharya</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Microbiology and Cell Sciences</h4>
                                    </div>
                                </div>

<!--Michelle-->                 <div class="member">
                                    <img src="img/lab/michellemu.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Michelle Mu</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biology</h4>
                                    </div>
                                </div>

<!--Grace-->                    <div class="member">
                                    <img src="img/lab/gracecheng.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Grace Cheng</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                        <h5>UF AI Scholar</h5>
                                    </div>
                                </div>
                    

<!--Jason-->                    <div class="member">
                                    <img src="img/lab/jasonchen2.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jason Chen</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                        <h5>NSF REU Awardee, UF AI Scholar</h5>
                                    </div>
                                </div>

<!--Amy-->                      <div class="member">
                                    <img src="img/lab/amylazarte.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Amy Lazarte</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                        <h5>NSF REU Awardee, UF AI Scholar</h5>
                                    </div>
                                </div>

<!--Surya-->                    <div class="member">
                                    <img src="img/lab/suryakarthikeyanvijayalakshmi.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Surya Karthikeyan Vijayalakshmi</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>

<!--Joshua-->                   <div class="member">
                                    <img src="img/lab/joshualamb.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Joshua Lamb</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>

<!--Cynthia-->                  <div class="member">
                                    <img src="img/lab/cynthialiu.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Cynthia Liu</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>

                                <!--/Current Members-->

                                <!--Alumni-->
                                <div class="title text-center">
                                    <h1>Alumni</h1>
                                </div>

<!--##############-->                                
<!-- M.D. Alumni -->           <b><h3>M.D. Alumni</h3></b>
<!--##############-->
<!--Simeng-->                   <a href="https://scholar.google.com/citations?user=Ap3Xw9MAAAAJ&hl=en" target="_blank">
                                    <div class="member">
                                        <img src="img/lab/simengzhu.jpg" width="200" height="200" class="img-circle lab-img">
                                        <div class="bio">
                                            <h3><b>Simeng Zhu</b></h3>
                                            <h5>Doctor of Medicine, 2018-2022</h5>
                                            <h5>Medical Resident at Henry Ford Hospital Radiation Oncology, 2019-2023</h5>
                                            <h4>Assistant Professor at Ohio State University from Fall 2023</h4>
                                        </div>
                                    </div>
                                </a>


<!--##############-->                                
<!-- Ph.D. Alumni -->           <b><h3>Ph.D. Alumni</h3></b>
<!--##############-->
<!--Yao-->                      <a href="https://sites.google.com/view/yaoxiao" target="_blank">
                                    <div class="member">
                                        <img src="img/lab/yaoxiao.jpg" width="200" height="200" class="img-circle lab-img">
                                        <div class="bio">
                                            <h3><b>Yao Xiao</b></h3>
                                            <h5>Doctor of Philosophy, 2017-2020</h5>
                                            <h4>Biomedical Engineering</h4>
                                            <h5>BMES 2020 Career Development Award</h5>
                                            <h5>Graduate Student Speaker at College of Engineering Commencement 2020</h5>
                                            <h4>Senior Data Analyst, Mayo Clinic</h4>
                                        </div>
                                    </div>
                                    </a>
                                
<!--Peng-->                     <a href="https://rocmind.com/" target="_blank">
                                    <div class="member">
                                        <img src="img/lab/pengliu.jpg" width="200" height="200" class="img-circle lab-img">
                                        <div class="bio">
                                            <h3><b>Peng Liu</b></h3>
                                            <h5>Doctor of Philosophy, 2016-2021</h5>
                                            <h4>Biomedical Engineering</h4>
                                            <h5>Best Abstract Award at Montreal AI & Neuroscience (MAIN) Conference</h5>
                                            <h5>UF Informatics Institute Graduate Fellowship</h5>
                                            <!-- <div class="btags2 btw">Biology-Inspired Artificial Intelligence</div>
                                            <div class="btags2 btw">Medical Image Analysis</div>
                                            <div class="btags2 btw">AI-Inspired Neuroscience</div> -->
                                            <h4>Postdoc Associate, Dartmouth College</h4>
                                        </div>
                                    </div>
                                </a>
                                
<!--###########-->              <br>
<!--M.S. Alumni-->              <h3>M.S. Alumni</h3>
<!--###########-->

<!--Aysesha-->                  <div class="member">
                                    <img src="img/lab/AyseshaNaikodi.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Ayesha Naikodi</b></h3>
                                        <h4>M.S. Computer Information Science and Engineering, 2022-2023</h4>
                                        <h4>Ph.D. student, University of Florida</h4>
                                    </div>
                                </div>

<!--Hong Huang -->              <div class="member">
                                    <img src="img/lab/HongHuang.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Huang Hong</b></h3>
                                        <h4><i>Master of Engineering, 2021-2023</i></h4>
                                        <h4>Electrical and Computer Engineering</h4>
                                    </div>
                                </div>

<!--Jimmy-->                    <div class="member">
                                    <img src="img/lab/jimmyossa.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jimmy Ossa</b></h3>
                                        <h5>Master of Engineering, 2020-2022</h5>
                                        <h4>Software Engineer at Infotech</h4>
                                    </div>
                                </div>

<!--Shen-->                     <div class="member">
                                    <img src="img/lab/shenkai.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Shen Kai</b></h3>
                                        <h5>Master of Engineering, 2021-2022</i></h5>
                                        <h4>PhD Student at University of Florida</h4>
                                    </div>
                                </div>

<!--Jiaqing-->                  <div class="member">
                                    <img src="img/lab/JiaqingZhang.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jiaqing Zhang</b></h3>
                                        <h5>Master of Engineering, ECE, UF 2020-2022</h5>
                                        <h4>PhD student at University of Florida</h4>
                                    </div>
                                </div>
                                
  
                        
<!--Shreya-->                   <div class="member">
                                    <img src="img/lab/shreyaverma.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Shreya Verma</b></h3>
                                        <h5>Master of Engineering, BME, UF 2019-2021</h5>
                                        <h4>Ph.D. student at Penn State University</h4>
                                    </div>
                                </div>


<!--Bhavin-->                   <div class="member">
                                    <img src="img/lab/BhavinSoni.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Bhavin Soni</b></h3>
                                        <h5>Master of Engineering, BME, 2019-2021</h5>
                                        <h4>Neuroimaging Engineer, Washington University at St. Louis</h4>
                                    </div>
                                </div>



<!--Jun-->                      <a href="https://cn.linkedin.com/in/yangjunyi-li-6b8b97ab" target="_blank">
                                <div class="member">
                                    <img src="img/lab/YangjunyiLi.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Yangjunyi Li</b></h3>
                                        <h5>Masters Student, UF BME, 2017-2018</h5>
                                        <h4>Senior Scientist, Computational Biologist, Eli Lilly and Company</h4>
                                    </div>
                                </div>
                                </a>

<!--Yun-->	                    <a href="https://www.linkedin.com/in/yun-liang-51b17445" target="_blank">
                                <div class="member">
                                    <img src="img/lab/YunLiang.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Yun Liang</b></h3>
                                        <h5>UF BME, 2018-2019</h5>
                                        <h4>PhD student, UF BME</h4>
                                    </div>
                                </div>
                                </a>

<!--Micheal-->                  <a href="https://www.linkedin.com/in/adeyosoyemic/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/MichealAdeyosoye.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Micheal Adeyosoye</b></h3>
                                        <h5>MS-PhD, FIU Bridge to PhD Fellowship, 2016-2017</h5>
                                        <h4>PhD Student, FIU</h4>
                                    </div>
                                </div>
                                </a>

<!--Jingan-->                   <a href="https://www.linkedin.com/in/jinganqu/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/jinganqu.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jingan Qu</b></h3>
                                        <h5>Masters Student, 2015-2017</h5>
                                        <h4>Data Scientist, Applied Research Center FIU</h4>
                                    </div>
                                </div>
                                </a>

<!--Daniel-->                   <a href="https://www.linkedin.com/in/danieldotparra/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/DanielParra.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Daniel Parra</b></h3>
                                        <h5>Masters Student, 2015-2016</h5>
                                        <h4>Software Engineer, ProActive Technologies, LLC</h4>
                                    </div>
                                </div>
                                </a>

<!--Haodi-->                    <div class="member">
                                    <img src="img/lab/HaodiJiang.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Haodi Jiang</b></h3>
                                        <h5>Masters Student, 2014-2015</h5>
                                        <h4>PhD student at NJIT</h4>
                                    </div>
                                </div>

<!--Sherman-->                  <a href="https://www.linkedin.com/in/sherman-ng-a3801523/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/ShermanNg.jpeg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Sherman Ng</b></h3>
                                        <h5>M.Eng. 2010-2011 @ Cornell ECE</h5>
                                        <h4>Software Engineer, Microsoft</h4>
                                    </div>
                                </div>
                                </a>

<!--###########-->              <br>
<!--Undergrad Alumni-->         <h3>Undergraduate Alumni</h3>
<!--###########-->

<!--Jordi-->                    <div class="member">
                                    <img src="img/lab/jordibardia.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jordi Bardia</b></h3>
                                        <h4><i>B.E. Computer Science, UF, 2022</i></h4>
                                    </div>
                                </div>

<!--Benjamin-->                 <div class="member">
                                    <img src="img/lab/benjaminarnold.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Benjamin Arnold</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
                                
<!--Hely-->                     <div class="member">
                                    <img src="img/lab/helylin.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Hely Lin</b></h3>
                                        <h5>B.S. Biomedical Engineering, UF, 2020-2023</i></h5>
                                        <h4>Machine Learning Engineer, CAE Inc. </h4>

                                    </div>
                                </div>

<!--Yiru-->                     <div class="member">
                                    <img src="img/lab/yirumu.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Yiru Mu</b></h3>
                                        <h5>B.S. Computer Science, UF, 2021-2023</h5>
                                        <h4>M.S. student, Georgia Tech</h4>
                                    </div>
                                </div>

<!--Garret-->                   <div class="member">
                                    <img src="img/lab/garrettfullerton.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Garrett Fullerton</b></h3>
                                        <h5>B.S. Biomedical Engineering, UF, 2019-2022</h5>
                                        <h4>Ph.D. Student, Medical Physics, University of Wisconsin</h4>
                                        <h5>NSF GRFP Awardee</h5>
                                        <h5>NSF REU Awardee</h5>
                                        <h5>University Scholar Program</h5>
                                        
                                    </div>
                                </div>



<!--Gianna-->                   <div class="member">
                                    <img src="img/lab/giannasweeting.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Gianna Sweeting</b></h3>
                                        <h5>B.S. Biomedical Engineering, UF, 2020-2022</h5>
                                        <h5>Fernandez Family Scholar</h5>
                                        <h5>University Scholar Program</h5>
                                    </div>
                                </div>



<!--Simon-->                    <div class="member">
                                    <img src="img/lab/simonkato.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Simon Kato</b></h3>
                                        <h5>B.S. Math and Statistics, UF, 2020-2022</h5>
                                        <h4>Ph.D. Student, Computer Science, UIUC</h4>
                                        <h4>NSF REU Awardee</h4>
                                    </div>
                                </div>
   
<!--John-->                     <div class="member">
                                    <img src="img/lab/johnbraddock.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Brian "John" Braddock</b></h3>
                                        <h5>B.S. Biomedical Engineering, 2021-2023</h5>
                                        <h5>NSF REU Awardee</h5>
                                    </div>
                                </div>

<!--Maria-->                    <div class="member">
                                    <img src="img/lab/mariacardei.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Maria Cardei</b></h3>
                                        <h5>Undergraduate Student, 2020-2022</h5>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>

<!--Alvin-->                    <div class="member">
                                    <img src="img/lab/alvinnaiju.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Alvin Naiju</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biochemistry</h4>
                                    </div>
                                </div>

<!--Michael-->                  <div class="member">
                                    <img src="img/lab/michaelmcgaha.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Michael McGaha</b></h3>
                                        <h5>B.S. Computer Science and Statistics, UF, 2020-2022</h5>
                                        <h4>Software Engineering (SDE), Amazon</h4>

                                    </div>
                                </div>
                    
<!--Nathan-->                   <div class="member">
                                    <img src="img/lab/nathanbarkdull.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Nathan Barkdull</b></h3>
                                        <h5>B.S. Math, UF. 2020-2022</h5>
                                        <h4>Ph.D. student, Dynamical Neuroscience,UCSB</h4>
                                    </div>
                                </div>
                        
<!--Keyur-->                    <div class="member">
                                    <img src="img/lab/keyurpatel.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Keyur Patel</b></h3>
                                        <h5>B.E. Computer Science, 2021-2022</h5>
                                    </div>
                                </div>
                        
<!--Jason-->                    <div class="member">
                                     <img src="img/lab/jasonchen.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jason Chen</b></h3>
                                        <h5>B.E. Computer Science, 2019-2021.</h5>
                                        <h4>Software Development Engineer, Facebook</h4>
                                        <h5>NSFUF AI Scholar</h5>
                                    </div>
                                </div>

<!--Max-->                         <div class="member">
                                    <img src="img/lab/MaxDiaz.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Maximillian Diaz</b></h3>
                                        <h5>B.E. BME, 2018-2020</h5>
                                        <h5>University Scholar Program</h5>
                                        <h5>NSF Graduate Research Fellowship Program</h5>
                                        <h4>Ph.D. student at UF</h5>
                                    </div>
                                </div>


 <!--Neeva -->                   <div class="member">
                                    <img src="img/lab/neevasethi.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Neeva Sethi</b></h3>
                                        <h5>Undergraduate Student @ UF 2019-2023</h5>
                                        <h5>Computer Science</h5>
                                        <h5>Presidential Service Awardee</h5>
                                        <h5>CLAS Hall of Fame Inductee</h5>
                                    </div>
                                </div>

<!--Daniel-->	                <div class="member">
                                    <img src="img/lab/Daniel-basha.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Daniel El Basha</b></h3>
                                        <h5>B.E. BME, NSF REU Awardee 2017-2019</h5>
                                        <h5>NSF Graduate Research Fellowship Program</h5>
                                        <h4>PhD student at MD Anderson</h4>
                                    </div>
                                </div>

<!--Akshay-->	                <div class="member">
                                    <img src="img/lab/Akshay.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Akshay Mathavan</b></h3>
                                        <h5>Undergraduate Researcher, University Scholar Program, 2018-2019</h5>
                                        <h4>Doctor of Medicine student, UF</h4>
                                    </div>
                                </div>

<!--Akash-->		            <div class="member">
                                    <img src="img/lab/Akash.png" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Akash Mathavan</b></h3>
                                        <h5>Undergraduate Researcher, University Scholar Program, 2018-2019</h5>
                                        <h4>Doctor of Medicine student, UF</h4>
                                    </div>
                                </div>
                                
<!--Sumanth                     <div class="member">
                                    <img src="img/lab/sumanthaluri.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Sumanth Aluri</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>
-->


<!--Rachel                      <div class="member">
                                    <img src="img/lab/rachelpeebles.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Rachel Peebles</b></h3>
                                        <h4>Undergraduate Student</h4>
                                    </div>
                                </div>
-->
<!--Abdul                    <div class="member">
                                    <img src="img/lab/abduldozic.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Abdul-Vehab Dozic</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Physics</h4>
                                    </div>
                                </div>
-->

<!--Riley                       <div class="member">
                                    <img src="img/lab/peiwengao.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Peiwan (Riley) Gao</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>
--->

<!--Christopher                 <div class="member">
                                    <img src="img/lab/christopherfernandez.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Christopher Fernandez</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Science</h4>
                                    </div>
                                </div>
-->

<!--Sruthika                 <div class="member">
                                    <img src="img/lab/sruthikabaviriseaty.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Sruthika Baviriseaty</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
-->

<!--Jared                       <div class="member">
                                    <img src="img/lab/jaredhixenbaugh.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Jared Hixenbaugh</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Chemical Engineering</h4>
                                    </div>
                                </div>
-->
                                

                                
<!--Ahmet                       <div class="member">
                                    <img src="img/lab/ahmetbilgili.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Ahmet Bilgili</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
-->


<!--Muhamed                  <div class="member">
                                    <img src="img/lab/muhamedmaher.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Muhamed Maher</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
-->


<!--Edward                   <div class="member">
                                    <img src="img/lab/edwardzhang.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Edward Zhang</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Computer Engineering & Finance</h4>
                                    </div>
                                </div>
-->

<!--Adeeb                       <div class="member">
                                    <img src="img/lab/adeebrashid.jpeg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Adeeb Rashid</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering & Computer Science</h4>
                                    </div>
                                </div>
-->

<!--James                       <div class="member">
                                    <img src="img/lab/jamesbondnguyen.jpg" width="200" height="200" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>James-Bond Nguyen</b></h3>
                                        <h4><i>Undergraduate Student</i></h4>
                                        <h4>Biomedical Engineering</h4>
                                    </div>
                                </div>
-->
                                
                                <br>
<!--Visiting Students Alumni--> <h3>Visiting Students Alumni</h3>

<!--Yuanyuan-->                 <a href="https://www.linkedin.com/in/yyzcs/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/YuanyuanZhu.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Yuanyuan Zhu</b></h3>
                                        <h5>Visiting Undergraduate Student, 2016 Summer</h5>
                                        <h4>Software Engineer, Indeed.comock</h4>
                                    </div>
                                </div>
                                </a>

<!--Xing-->                     <div class="member">
                                    <img src="img/lab/XingPang.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Xing Pang</b></h3>
                                        <h5>Visiting Graduate Student, 2015-2016</h5>
                                        <h4>Nanjing University of Science and Technology</h4>
                                    </div>
                                </div>

                                <br>
                                <h3>K-12 Teachers</h3>
<!--Edda-->                     <a href="http://teacherweb.com/FL/JohnAFergusonHighSchool/EddaRivera/t.aspx" target="_blank">
                                <div class="member">
                                    <img src="img/lab/edda.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Edda Rivera</b></h3>
                                        <h5>NSF DoD RET Teacher, Best NSF RET Poster Award at FIU SCIS RET Presentation, 2016 Summer</h5>
                                        <h4>High School Teacher, John A. Ferguson Senior High School</h4>
                                    </div>
                                </div>
                                </a>

<!--Christian-->                <a href="http://teacherweb.com/FL/JohnAFergusonHighSchool/EddaRivera/t.aspx" target="_blank">
                                <div class="member">
                                    <img src="img/lab/chris.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Christian McDonald</b></h3>
                                        <h5>NSF DoD RET Teacher, Best NSF RET Poster Award at FIU SCIS RET Presentation, 2016 Summer</h5>
                                        <h4>High School Teacher, Miami Jackson Senior High School</h4>
                                    </div>
                                </div>
                                </a>

                                <br>
                                <h3>K-12 Students</h3>
<!--Paul Naghshineh-->          <a href="https://www.linkedin.com/in/paul-naghshineh-77a756112/" target="_blank">
                                <div class="member">
                                    <img src="img/lab/Paul.jpg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Paul Naghshineh</b></h3>
                                        <h5>NSF DoD REU Student, 2016 Summer</h5>
                                        <h4>Gaumard Scientific</h4>
                                    </div>
                                </div>
                                </a>

<!--Srividya-->                 <div class="member">
                                    <div class="bio">
                                        <img src="img/lab/smile.jpeg" class="img-circle lab-img">
                                        <h3><b>Srividya Vaishnavi Surampudi</b></h3>
                                        <h5>UF Student Science Training Program (SSTP), 2018 Summer</h5>
                                        <h4>Stanford University</h4>
                                    </div>
                                </div>
                                
<!--Imaan-->                    <div class="member">
                                    <img src="img/lab/smile.jpeg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Imaan Randhawa</b></h3>
                                        <h5>UF Student Science Training Program (SSTP), 2019 Summer</h5>
                                        <h4>University of Florida</h4>
                                    </div>
                                </div>
                                
<!--Aarushi-->                 <a href="https://www.linkedin.com/in/aarushiwalia/Aarushi Wali" target="_blank">
                                <div class="member">
                                    <img src="img/lab/Aarushi%20Walia.jpeg" class="img-circle lab-img">
                                    <div class="bio">
                                        <h3><b>Aarushi Walia</b></h3>
                                        <h5>UF Student Science Training Program (SSTP), 2019 Summer</h5>
                                        <h4>University of Berkeley</h4>
                                    </div>
                                </div>
                                </a>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Team-->

                <!--Research-->
                <div id="research" class="page">

                    <!--Research Summary-->
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Research Summary</h2>
                                <div class="row">
                                    <div class="col-md-8">
                                        <img alt="image" src="img/research/overvew.png" class="img-responsive">
                                    </div>

                                    <div class="col-md-4">
                                        <div class="subtitle text-center">
                                            <h3>Interests</h3>
                                        </div>
                                        <ul class="ul-boxed list-unstyled">
                                            <li>AI-Empowered Brain Health</li>
                                            <li>Brain-Inspired AI</li>
                                            <li>Deep Learning</li>
                                            <li>Brain Dynamics</li>
                                            <li>Medical Image Analysis</li>
                                        </ul>
                                    </div>
                                    <img alt="image" src="img/research/Tree.png" class="img-responsive">

                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/Research Summary-->

                    <!--NSF Funded Projects-->
                    <div class="section color-2">
                        <div class="section-container">
                            <div class="title text-center">
                                <h3>Funded Projects</h3>
                            </div>
                            <div class="row">
                                <div class="col-md-12">
                                    <ul class="ul-withdetails">
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/com.png" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>DRPD-ROF2023: Learning optimal treatment strategies for hypotension in critical care patients with acute kidney injury using artificial intelligence</h3>
                                                        <!--<a href="" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>-->
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p></p>
                                            </div>
                                        </li>
                                        
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nsf_logo.gif" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>NCS-FO-2318984: Brain-Informed Goal-Oriented and Bidirectional Deep Emotion Inference</h3>
                                                        <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2318984" class="tooltips" target="_blank"><h4>NSF</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Human emotions are dynamic, multidimensional responses to challenges and opportunities that emerge from network interactions in the brain. Disruptions of these dynamics underlie emotional dysregulation in many mental disorders including anxiety and depression. To empirically study the neural basis of human emotion inference, experimenters often have observers view natural images varying in affective content, while at the same time recording their brain activity using electroencephalogram (EEG) and/or Functional magnetic resonance imaging (fMRI). Despite extensive research over the last few decades, much remains to be learned about the computational principles subserving the recognition of emotions in natural scenes. A major roadblock faced by empirical neuroscientists is the inability to carry out precisely manipulate human neural systems and test the consequences in imaging data. Deep Neural Networks (DNN), owing to their high relevance to human neural systems and extraordinary prediction capability, have become a promising tool for testing these sorts of hypotheses in swift and nearly costless computer simulations. The overarching goal of this project is to develop a neuroscience-inspired, DNN-based deep learning framework for emotion inference in real-world scenarios by synergistically integrating neuron-, circuit-, and system-level mechanisms. Recognizing that the state-of-the-art DNNs are centered on bottom-up and feedforward-only processing, which disagrees with the strong goal-oriented top-down modulation recurrence observed in the physiology, this project aims to enrich DNNs and enable closer AI-neuroscience interaction by incorporating goal-oriented top-down modulation and reciprocal interactions DNNs and test the model assumptions and predictions on neuroimaging data.

                                                    To meet these goals, the project aims to develop a brain-inspired goal-oriented and bidirectional deep learning model for emotion inference. Despite the great promise shown by today?s deep learning as a framework for modeling biological vision, their architecture is limited to emulating the visual cortex for face/object/scene recognition and rarely goes beyond the inferotemporal cortex (IT), which is necessary for modeling high-level cognitive processes. In this project, we propose to build a biologically plausible deep learning architecture by integrating an in-silico amygdala module into the visual cortex architecture in DNN (the VCA model). The researchers hope to build neuron-, circuit-, and system-level modulation via goal-oriented attention priming, and multi-pathway predictive coding to 1) elucidate the mechanism of selectivity underlying preference and response to naturalistic emotions by artificial neurons; 2) differentiate fine-grained emotional responses via multi-path predictive coding, and 3) refine the neuroscientific understanding of human neuro-behavioral data by comparing attention priming and temporal generalization observed in simultaneous fMRI-EEG data to the computational observations using our brain-inspired VCA model. This project introduces two key innovations, both patterned after how brain operates, into DNN architecture and demonstrate their superior performance when applied to complex real-world tasks. Successful execution of the project can lead to the development of a new generation of AI-models that are inspired by neuroscience and that may in turn power neuroscience research.</p>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>R01AG081477: Cognitively engaging walking exercise and neuromodulation to enhance brain function in older adults</h3>
                                                        <a href="https://reporter.nih.gov/search/LKlN8t-fd0Om6OfpeU551g/project-details/10635832" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>There is a pressing need for effective interventions to remediate age-related cognitive decline and alter the trajectory toward Alzheimer’s disease. The NIA Alzheimer’s Disease Initiative funded Phase III Augmenting Cognitive Training in Older Adults (ACT) trial aimed to demonstrate that transcranial direct current stimulation (tDCS) paired with cognitive training could achieve this goal. The present study proposes a state of the art secondary data analysis of ACT trial data that will further this aim by 1) elucidate mechanism of action underlying response to tDCS treatment with CT, 2) address heterogeneity of response in tDCS augmented CT by determining how individual variation in the dose of electrical current delivered to the brain interacts with individual brain anatomical characteristics; and 3) refine the intervention strategy of tDCS paired with CT by evaluating methods for precision delivery targeted dosing characteristics to facilitate tDCS augmented outcomes. tDCS intervention to date, including ACT, apply a fixed dosing approach whereby a single stimulation intensity (e.g., 2mA) and set of electrode positions on the scalp (e.g., F3/F4) is applied to all participants/patients. However, our recent work has demonstrated that age-related changes in neuroanatomy as well as individual variability in head/brain structures (e.g., skull thickness) significantly impacts the distribution and intensity of electrical current induced in the brain from tDCS. This project will use person-specific MRI-derived finite element computational models of electric current characteristics (current intensity and direction of current flow) and new methods for enhancing the precision and accuracy of derived models to precisely quantify the heterogeneity of current delivery in older adults. We will leverage these individualized precision models with state-of-the-art support vector machine learning methods to determine the relationship between current characteristics and treatment response to tDCS and CT. We will leverage the inherent heterogeneity of neuroanatomy and fixed current delivery to provide insight in the not only which dosing parameters were associated with treatment response, but also brain region specific information to facilitate targeted delivery of stimulation in future trials. Further still, the current study will also pioneer new methods for calculation of precision dosing parameters for tDCS delivery to potentially optimize treatment response, as well as identify clinical and demographic characteristics that are associated with response to tDCS and CT in older adults. Leveraging a robust and comprehensive behavioral and multimodal neuroimaging data set for ACT with advanced computational methods, the proposed study will provide critical information for mechanism, heterogeneity of treatment response and a pathway to refined precision dosing approaches for remediating age- related cognitive decline and altering the trajectory of older adults toward Alzheimer’s disease.</p>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>RF1AG071469: Mechanisms, response heterogeneity and dosing from MRI-derived electric field models in tDCS augmented cognitive training: a secondary data analysis of the ACT study</h3>
                                                        <a href="https://reporter.nih.gov/search/tWAuFz5sDk2J_ueWh8eukA/project-details/10170947" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>There is a pressing need for effective interventions to remediate age-related cognitive decline and alter the trajectory toward Alzheimer’s disease. The NIA Alzheimer’s Disease Initiative funded Phase III Augmenting Cognitive Training in Older Adults (ACT) trial aimed to demonstrate that transcranial direct current stimulation (tDCS) paired with cognitive training could achieve this goal. The present study proposes a state of the art secondary data analysis of ACT trial data that will further this aim by 1) elucidate mechanism of action underlying response to tDCS treatment with CT, 2) address heterogeneity of response in tDCS augmented CT by determining how individual variation in the dose of electrical current delivered to the brain interacts with individual brain anatomical characteristics; and 3) refine the intervention strategy of tDCS paired with CT by evaluating methods for precision delivery targeted dosing characteristics to facilitate tDCS augmented outcomes. tDCS intervention to date, including ACT, apply a fixed dosing approach whereby a single stimulation intensity (e.g., 2mA) and set of electrode positions on the scalp (e.g., F3/F4) is applied to all participants/patients. However, our recent work has demonstrated that age-related changes in neuroanatomy as well as individual variability in head/brain structures (e.g., skull thickness) significantly impacts the distribution and intensity of electrical current induced in the brain from tDCS. This project will use person-specific MRI-derived finite element computational models of electric current characteristics (current intensity and direction of current flow) and new methods for enhancing the precision and accuracy of derived models to precisely quantify the heterogeneity of current delivery in older adults. We will leverage these individualized precision models with state-of-the-art support vector machine learning methods to determine the relationship between current characteristics and treatment response to tDCS and CT. We will leverage the inherent heterogeneity of neuroanatomy and fixed current delivery to provide insight in the not only which dosing parameters were associated with treatment response, but also brain region specific information to facilitate targeted delivery of stimulation in future trials. Further still, the current study will also pioneer new methods for calculation of precision dosing parameters for tDCS delivery to potentially optimize treatment response, as well as identify clinical and demographic characteristics that are associated with response to tDCS and CT in older adults. Leveraging a robust and comprehensive behavioral and multimodal neuroimaging data set for ACT with advanced computational methods, the proposed study will provide critical information for mechanism, heterogeneity of treatment response and a pathway to refined precision dosing approaches for remediating age- related cognitive decline and altering the trajectory of older adults toward Alzheimer’s disease.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nsf_logo.gif" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>NSF IIS 2123809: Collaborative Research: SCH: Trustworthy and Explainable AI for Neurodegenerative Diseases</h3>
                                                        <h4><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2123809" class="tooltips" target="_blank">NSF Abstract</a></h4>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Driven by its performance accuracy, machine learning (ML) has been used extensively for various applications in the healthcare domain. Despite its promising performance, researchers and the public have grown alarmed by two unsettling deficiencies of these otherwise useful and powerful models. First, there is a lack of trustworthiness - ML models are prone to interference or deception and exhibit erratic behaviors when in action dealing with unseen data, despite good practice during the training phase. Second, there is a lack of interpretability - ML models have been described as 'black-boxes' because there is little explanation for why the models make the predictions they do. This has called into question the applicability of ML to decision-making in critical scenarios such as image-based disease diagnostics or medical treatment recommendation. The ultimate goal of this project is to develop computational foundation for trustworthy and explainable Artificial Intelligence (AI), and offer a low-cost and non-invasive ML-based approach to early diagnosis of neurodegenerative diseases. In particular, the project aims to develop computational theories, ML algorithms, and prototype systems. The project includes developing principled solutions to trustworthy ML and making the ML prediction process transparent to end-users. The later will focus on explaining how and why an ML model makes such a prediction, while dissecting its underlying structure for deeper understanding. The proposed models are further extended to a multi-modal and spatial-temporal framework, an important aspect of applying ML models to healthcare. A verification framework with end-users is defined, which will further enhance the trustworthiness of the prototype systems. This project will benefit a variety of high-impact AI-based applications in terms of their explainability, trustworthy, and verifiability. It not only advances the research fronts of deep learning and AI, but also supports transformations in diagnosing neurodegenerative diseases.</p>
                                                    
                                                <p>This project will develop the computational foundation for trustworthy and explainable AI with several innovations. First, the project will systematically study the trustworthiness of ML systems. This will be measured by novel metrics such as, adversarial robustness and semantic saliency, and will be carried out to establish the theoretical basis and practical limits of trustworthiness of ML algorithms. Second, the project provides a paradigm shift for explainable AI, explaining how and why a ML model makes its prediction, moving away from ad-hoc explanations (i.e. what features are important to the prediction). A proof-based approach, which probes all the hidden layers of a given model to identify critical layers and neurons involved in a prediction from a local point of view, will be devised. Third, a verification framework, where users can verify the model's performance and explanations with proofs, will be designed to further enhance the trustworthiness of the system. Finally, the project also advances the frontier of neurodegenerative diseases early diagnosis from multimodal imaging and longitudinal data by: (i) identifying retinal vasculature biomarkers using proof-based probing in biomarker graph networks; (ii) connecting biomarkers of the retina and the brain vasculature via cross- modality explainable AI model; and, (iii) recognizing the longitudinal trajectory of vasculature biomarkers via a spatio-temporal recurrent explainable model. This synergistic effort between computer science and medicine will enable a wide range of applications to trustworthy and explainable AI for healthcare. The results of this project will be assimilated into the courses and summer programs that the research team have developed with specially designed projects to train students with trustworthy and explainable AI.</p>
                                            </div>
                                        </li>
                                        
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>P01AI165380: Multi-Scale Evaluation and Mitigation of Toxicities Following Internal Radionuclide Contamination</h3>
                                                        <a href="https://reporter.nih.gov/search/l0LOTy_1QkqWrBJcFCgkfg/project-details/10327393" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>History has taught us that exposures to radionuclides can happen any day almost anywhere in the US and elsewhere and we have done little to prepare ourselves. Our ability to perform dosimetry modeling for such scenarios and efforts into biomarker and mitigation discovery are archaic and our tendency to rely on external beam radiation to model these is utterly misplaced. We should and we can do much better. This program centers on the hypothesis that radiation from internal emitters is very unevenly distributed within a body, amongst organs, and even within organs, tissues and cells. The half-life and decay schema of the radionuclide, its activity and concentration, particle size and morphology, and its chemical form and solubility are all critical, as are the route of uptake, tissue structure, genetic makeup, physiology, danger signaling and the crosstalk with the immune system. Conceptually this suggests that the analysis of radionuclide distribution requires measurements at the MESO, MICRO and NANO level for accurate dosimetry modeling and biokinetics analyses, that will much better align with biological endpoints, and therefore with meaningful countermeasure development. In many ways our program integrates the three main pillars of radiation science, namely radiation physics, radiation chemistry and radiation biology, taking into account pharmacokinetics and pharmacodynamics aspects of particle distribution at subcellular, cellular, and tissue levels. In other words, to understand the biological effects of internal emitters and find the best possible mitigation strategies a systematic study is called for, one that includes but is not limited to: a) radionuclide physical and chemical form and intravital migration, b) protracted exposure times, c) radiation quality parameters, d) novel virtual phantom modeling beyond few MACRO reference models ; e) novel biokinetics with sex- and age- specificity; f) MESO, MICRO and NANO scale histology and immunohistochemistry with integrated radionuclide distribution information; g) exploration of molecular biomarkers of radionuclide intake and contamination and h) countermeasures that modulate radionuclide distribution and possibly also improve DNA, cell and tissue repair. We have assembled a team with diverse scientific expertise that can tackle these challenges within an integrated program. There is an incredibly impressive technological toolbox at our disposal and our goal is to generate a meaningful blueprint for understanding and predicting biological consequences of exposure to radionuclides. The possible benefits of this program to the radiation research community and the general population are immense.</p>
                                            </div>
                                        </li>
                                        
                                        
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>U24AA029959: Southern HIV and Alcohol Research Consortium Biomedical Data Repository</h3>
                                                        <a href="https://reporter.nih.gov/search/OfbDWJ_vikqIQ9S-eped2w/project-details/10401614" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>The purpose of the SHARE P01 research program project is to address HIV and alcohol use around three themes; 1) Emerging adulthood (ages 18 -29); 2) Self-management of HIV and alcohol; and 3) Translational behavioral science. Emerging adulthood is a developmental stage marked by significant change in social roles, expectations as a new adult, and increased responsibilities. It is also marked by poor HIV self- management and increased alcohol use. Emerging adults with HIV (hereafter called young people living with HIV; YPLWH) may face even more challenges given intersectional stigma. This age group continues to have very high rates of new HIV infections. Interventions designed specifically for the unique developmental challenges of emerging adults are needed, yet emerging adults are often included with older adults in intervention programs. The concept of self-management emerged concurrently within both the substance abuse and chronic illness literatures, and fits well with the developmental challenges of emerging adulthood. Self-management, a framework we have utilized in our work with YPLWH, refers to the ability to manage symptoms, treatments, lifestyle changes, and consequences of health conditions. Current research now identifies individual-level self-management skills such as self-control, decision-making, self-reinforcement, and problem solving as that protect against substance use and improve other health outcomes and can be embedded in the Information-Motivation-Behavioral Skills model. Although we have conducted multiple studies with YPLWH, only one intervention to date (Healthy Choices conducted by our team) improved both alcohol use and viral suppression in YPLWH in large trials. The goal of the SHARE P01 is to utilize advances in translational behavioral science to optimize behavioral interventions and define new developmentally- and culturally-appropriate intervention targets to improve self-management of alcohol and HIV in YPLWH. We will focus our efforts in Florida, a state hardest hit by the HIV epidemic but with a particularly strong academic- community partnership to support translation. We have assembled research teams to conduct self- management studies across the translational spectrum to address self-management and improve alcohol use and viral suppression (and thereby reduce transmission) in diverse YPLWH in Florida. The P01 will consist of three research projects (DEFINE, ENGAGE, and SUSTAIN), representing different stages on the translational spectrum and targeting different core competencies, supported by two cores (Community Engagement Core and Data Science Core). If successful, the SHARE P01 has the potential to greatly advance programs promoting self-management of HIV and alcohol use among a particularly vulnerable, but under-researched group, emerging adults living with HIV. SHARE also has a high potential for scale-up and implementation beyond Florida and across the United States.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>P01AA029543: Interventions to improve alcohol-related comorbidities along the gut-brain axis in persons with HIV infection</h3>
                                                        <a href="https://reporter.nih.gov/search/_3d8hDdWQk21uD8_SIp9lg/project-details/10304322" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>As persons living with HIV (PLWH) live longer, approximately 50% will experience HIV-related cognitive dysfunction, which may affect daily activities, contribute to morbidity and mortality, and increase the likelihood of HIV transmission. Alcohol consumption among PLWH may further exacerbate long-term cognitive dysfunction, with the presumed mechanism involving the gut microbiome, microbial translocation, systemic inflammation, and ultimately neuroinflammation. However, there are many gaps in our understanding regarding the specific pathophysiological mechanisms, and a need to offer interventions that are effective and acceptable in helping PLWH to reduce drinking or to protect them against alcohol-related harm. The overarching goal of this P01 is to identify and ultimately implement new/improved, targeted interventions that will improve outcomes related to cognitive and brain dysfunction in persons with HIV who drink alcohol. The proposed P01 activity will extend our current line of research that forms the core of the Southern HIV & Alcohol Research Consortium (SHARC). The specific aims of this P01 are to: 1) improve our understanding of the specific mechanisms that connect the gut microbiome to cognitive and brain health outcomes in persons with HIV; 2) evaluate interventions that are intended to reduce the impact of alcohol on brain and cognitive health in persons with HIV; and 3) connect and extend the research activity from this P01 with the training programs and community engagement activity in the SHARC. Our P01 will utilize two cores that provide infrastructure to two Research Components (RC1, RC2). The two RC will together enroll 200 PLWH with at-risk drinking into clinical trials that share common timepoints and outcome assessments. RC1 will compare two strategies to extend contingency management to 60 days, using breathalyzers and wrist-worn biosensors to monitor drinking. RC2 uses a hybrid trial design to evaluate two biomedical interventions targeting the gut-brain axis. One intervention is a wearable, transcutaneous vagus nerve stimulator that is hypothesized to stimulate the autonomic nervous system, resulting in decreased inflammation and improved cognition. The other intervention is a probiotic supplement intended to improve the gut microbiome in persons with HIV and alcohol consumption. All participants in RC2, and a subset of those in RC1 will have neuroimaging at two timepoints. The Data Science Core will provide data management and analytical support, and will analyze existing data and the data collected from this P01 using a machine learning and AI approach to identify factors associated with intervention success or failure. The Administrative Core will provide scientific leadership, clinical research and recruitment infrastructure, and connection to the outstanding training programs, development opportunities, and community engagement provided by the SHARC. Our community engagement with diverse populations, and collection of acceptability data from clinical trial participants, will facilitate our readiness to scale up the most promising interventions and move towards implementation in the next phase of our research.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>P01AA029547: SHARE Program: Innovations in Translational Behavioral Science to Improve Self- management of HIV and Alcohol Reaching Emerging adults</h3>
                                                        <a href="https://reporter.nih.gov/search/dv2koRY3tka8ocrvkhPLRg/project-details/10304691" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>The number of persons living with HIV (PLWH) continues to increase in the United States. Alcohol consumption is a significant barrier to both achieving the goal of ending the HIV epidemic and preventing comorbidities among PLWH, as it contributes to both HIV transmission and HIV-related complications. Recent advances in data capture systems such as mHealth devices, medical imaging, and high-throughput biotechnologies make large/complex research and clinical datasets available, including survey data, multi-omics data, electronic medical records, and/or other sources of reliable information related to engagement in care. This offers tremendous potential of applying “big” data to extract knowledge and insights regarding fundamental physiology, understand the mechanisms by which the pathogenic effects of biotic and abiotic factors are realized, and identify potential intervention targets. We propose to integrate the disparate data sources maintained by our partners and then utilize the big data to address research questions in treating HIV and alcohol-related morbidity and mortality. Specifically, we will pursue the following three aims: 1) Integrate the disparate data sources through standardization, harmonization, and merging; 2) Develop a web-based data sharing platform including virtual data sharing communities, data privacy protection, streamlined data approval and access, and tracking of ongoing research activities; 3) Provide statistical support to junior investigators to use the data repository for exploratory data analysis and proposal development. The proposed study will tap into disparate data sources, unleash the potential of data and information, accelerate knowledge discovery, advance data-powered health, and transform discovery to improve health outcomes for PLWH.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>R01MH125615: Acquisition, extinction, and recall of attention biases to threat: Computational modeling and multimodal brain imaging</h3>
                                                        <a href="https://reporter.nih.gov/search/2iGcM0lYv0ij-ARmPp4z_A/project-details/10296986" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Classical aversive conditioning is a well-established laboratory model for studying acquisition and extinction of defensive responses. In experimental animals, as well as in humans, research to date has been mainly focused on the role of limbic structures (e.g., the amygdala) in these responses. Recent evidence has begun to stress the important contribution by the brain’s sensory and attention control systems in maintaining the neural representations of conditioned responses and in facilitating their extinction. The proposed research breaks new ground by combining novel neuroimaging techniques with advanced computational methods to examine the brain’s visual and attention processes underlying fear acquisition and extinction in humans. Major advances will be made along three specific aims. In Aim 1, we characterize the brain network dynamics of visuocortical threat bias formation, extinction, and recall in a two-day learning paradigm. In Aim 2, we establish and test a computational model of threat bias generalization. In Aim 3, we examine the relation between individual differences in generalization and recall of conditioned visuocortical threat biases and individual differences in heightened autonomic reactivity to conditioned threat, a potential biomarker for assessing the predisposition to developing the disorders of fear and anxiety. It is expected that accomplishing these research aims will address two NIMH strategic priorities: defining the circuitry and brain networks underlying complex behaviors (Objective 1) and identifying and validating new targets for treatment that are derived from the understanding of disease mechanisms (Objective 3). It is further expected that this project will enable a paradigm shift in research on dysfunctional attention to threat from one that focuses primarily on limbic-prefrontal circuits to one that emphasizes the interactions among sensory, attention, executive control and limbic systems.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nih.jpg" class="img-responsive">
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>U01NS119562: Web-based Automated Imaging Differentiation of Parkinsonism</h3>
                                                        <a href="https://reporter.nih.gov/search/tmrKaiJCoEyFhnIugazINQ/project-details/10106864" class="tooltips" target="_blank"><h4>NIH REPORT</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Across the globe, there has been a considerable growth in the number of people diagnosed with Parkinsonism. Estimates indicate that from 1990 to 2015 the number of Parkinsonism diagnoses doubled, with more than 6 million people currently carrying the diagnosis, and by year 2040, 12 and 14.2 million people will be diagnosed with Parkinsonism. Parkinson’s disease (PD), multiple system atrophy Parkinsonian variant (MSAp), and progressive supranuclear palsy (PSP) are neurodegenerative forms of Parkinsonism, which can be difficult to diagnose as they share similar motor and non-motor features, and they each have an increased chance of developing dementia. In the first five years of a PD diagnosis, about 58% of PD are misdiagnosed, and of these misdiagnoses about half have either MSA or PSP. Since PD, MSAp, and PSP require unique treatment plans and different medications, and clinical trials testing new medications require the correct diagnosis, there is an urgent need for both clinic ready and clinical-trial ready markers for differential diagnosis of PD, MSAp, and PSP. Over the past decade, we have developed diffusion imaging as an innovative biomarker for differentiating PD, MSAp, and PSP. In this proposal, we will leverage our extensive experience to create a web-based software tool that can process diffusion imaging data from anywhere in the world. We will disseminate and test the tool in the largest prospective cohort of participants with Parkinsonism (PD, MSAp, PSP), working closely with the Parkinson Study Group. The reason to test this in the Parkinson Study Group network, is because they are the community that evaluates Phase II and Phase III clinical trials in Parkinsonism. This web-based software tool will be capable of reading raw diffusion imaging data, performing quality assurance procedures, analyzing the data using a validated pipeline, and providing imaging metrics and diagnostic probability. We will test the performance of the wAID-P by enrolling 315 total subjects (105 PD, 105 MSAp, 105 PSP) across 21 sites in the Parkinson Study Group. Each site will perform imaging, clinical scales, diagnosis, and will upload the data to the web-based software tool. The clinical diagnosis will be blinded to the diagnostic algorithm and the imaging diagnosis will be compared to the movement disorders trained neurologist diagnosis. We will also enroll a portion of the cohort into a brain bank to ascertain pathological confirmation and to test the algorithm against cases with post-mortem diagnoses. The final outcome will be to disseminate a validated diagnostic algorithm to the Parkinson neurological and radiological community and to make it available to all on a website.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nsf_logo.gif" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1908299" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>IIS-1908299 III: Small: Collaborative Research: Modeling Multi-Level Connectivity of Brain Dynamics</h3>
                                                        <a href="./projects/IIISmall2019.html" target="_blank"><h4>Project Page</h4></a>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>The temporal dynamics of blood flows through the network of cerebral arteries and veins provides a window into the health of the human brain. Since the brain is vulnerable to disrupted blood supply, brain dynamics serves as a crucial indicator for many kinds of neurological diseases such as stroke, brain cancer, and Alzheimer's disease. Existing efforts at characterizing brain dynamics have predominantly centered on 'isolated' models in which data from single-voxel, single-modality, and single-subject are characterized. However, the brain is a vast network, naturally connected on structural and functional levels, and multimodal imaging provides complementary information on this natural connectivity. Thus, the current isolated models are deemed not capable of offering the platform necessary to enable many of the potential advancements in understanding, diagnosing, and treating neurological and cognitive diseases, leaving a critical gap between the current computational modeling capabilities and the needs in brain dynamics analysis. This project aims to bridge this gap by exploiting multi-scale structural (voxel, vasculature, tissue) connectivity and multi-modal (anatomical, angiography, perfusion) connectivity to develop an integrated connective computational paradigm for characterizing and understanding brain dynamics.</p>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nsf_logo.gif" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1564892" target="_blank">
                                                                <i class="fa fa-search"></i>
                                                            </a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>IIS-1564892 CRII: SCH: Characterizing, Modeling and Evaluating Brain Dynamics</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>The temporal dynamics of blood flows through the network of cerebral arteries and veins provides a window into the health of the human brain. Since the brain is vulnerable to disrupted blood supply, brain dynamics serves as a crucial indicator for many kinds of neurological diseases such as stroke, brain cancer, and Alzheimer's disease. Existing efforts at characterizing brain dynamics have predominantly centered on 'isolated' models in which data from single-voxel, single-modality, and single-subject are characterized. However, the brain is a vast network, naturally connected on structural and functional levels, and multimodal imaging provides complementary information on this natural connectivity. Thus, the current isolated models are deemed not capable of offering the platform necessary to enable many of the potential advancements in understanding, diagnosing, and treating neurological and cognitive diseases, leaving a critical gap between the current computational modeling capabilities and the needs in brain dynamics analysis. This project aims to bridge this gap by exploiting multi-scale structural (voxel, vasculature, tissue) connectivity and multi-modal (anatomical, angiography, perfusion) connectivity to develop an integrated connective computational paradigm for characterizing and understanding brain dynamics.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nsf_logo.gif" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747783" class="tooltips" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>CNS-1747783: Phase I IUCRC University of Florida: Center for Big Learning</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>This project establishes the NSF Industry/University Collaborative Research Center for Big Learning (CBL). The vision is to create intelligence towards intelligence-driven society. Through catalyzing the fusion of diverse expertise from the consortium of faculty members, students, industry partners, and federal agencies, CBL seeks to create state-of-the-art deep learning methodologies and technologies and enable intelligent applications, transforming broad domains, such as business, healthcare, Internet-of-Things, and cybersecurity. This timely initiative creates a unique platform for empowering our next-generation talents with cutting-edge technologies of societal relevance and significance. This project establishes the NSF Industry/University Collaborative Research Center for Big Learning (CBL) at University of Florida (UF). With substantial breakthroughs in multiple modalities of challenges, such as computer vision, speech recognitions, and natural language understanding, the renaissance of machine intelligence is dawning. The CBL vision is to create intelligence towards intelligence-driven society. The mission is to pioneer novel deep learning algorithms, systems, and applications through unified and coordinated efforts in the CBL consortium. The UF Site will focus on intelligent platforms and applications and closely collaborate with other sites on deep learning algorithms, systems, and applications. The CBL will have broad transformative impacts in technologies, education, and society. CBL aims to create pioneering research and applications to address a broad spectrum of real-world challenges, making significant contributions and impacts to the deep learning community. The discoveries from CBL will make significant contributions to promote products and services of industry in general and CBL industry partners in particular. As the magnet of deep learning research and applications, CBL offers an ideal platform to nurture next-generation talents through world-class mentors from both academia and industry, disseminates the cutting-edge technologies, and facilitates industry/university collaboration and technology transfer. The center repository will be hosted at http://nsfcbl.org. The data, code, documents will be well organized and maintained on the CBL servers for the duration of the center for more than five years and beyond. The internal code repository will be managed by GitLab. After the software packages are well documented and tested, they will be released and managed by popular public code hosting services, such as GitHub and Bitbucket.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/nvidia.jpg" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.bme.ufl.edu/fang-and-ding-selected-for-uf-catalyst-fund/" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>Artificial Intelligence Catalyst Award: VCA-DNN: Neuroscience-Inspired Artificial Intelligence for Visual Emotion Recognition</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Human emotions are dynamic, multidimensional responses to challenges and opportunities, which emerge from network interactions in the brain. Disruptions of these network interactions underlie emotional dysregulation in many mental disorders, including anxiety and depression. Creating an AI-based model system that is informed and validated by known biological findings and can be used to carry out causal manipulations and test the consequences against human imaging data will thus be a highly significant development in the short term. The long-term goal is to understand how the human brain processes emotional information and how the process breaks down in mental disorders. NIH currently funds the team to record and analyze fMRI data from humans viewing natural images of varying emotional content. In the process of their research, they recognize that empirical studies such as theirs have significant limitations. Chief among them is the lack of ability to manipulate the system to establish the causal basis for the observed relationship between brain and behavior. The advent of AI, especially deep neural networks (DNNs), opens a new avenue to address this problem. Creating an AI-based model system that is informed and validated by known biological findings and that can be used to carry out causal manipulations and allow the testing of the consequences against human imaging data will thus be a significant step toward achieving our long-term goal.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/UFII.png" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.bme.ufl.edu/bme-student-receives-ufii-graduate-student-fellowship/" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>UFII: Biology and Cognition Inspired Deep Learning</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Human emotions are dynamic, multidimensional responses to challenges and opportunities, which emerge from network interactions in the brain. Disruptions of these network interactions underlie emotional dysregulation in many mental disorders, including anxiety and depression. Creating an AI-based model system that is informed and validated by known biological findings and can be used to carry out causal manipulations and test the consequences against human imaging data will thus be a highly significant development in the short term. The long-term goal is to understand how the human brain processes emotional information and how the process breaks down in mental disorders. NIH currently funds the team to record and analyze fMRI data from humans viewing natural images of varying emotional content. In the process of their research, they recognize that empirical studies such as theirs have significant limitations. Chief among them is the lack of ability to manipulate the system to establish the causal basis for the observed relationship between brain and behavior. The advent of AI, especially deep neural networks (DNNs), opens a new avenue to address this problem. Creating an AI-based model system that is informed and validated by known biological findings and that can be used to carry out causal manipulations and allow the testing of the consequences against human imaging data will thus be a significant step toward achieving our long-term goal.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/UFII.png" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.bme.ufl.edu/fang-receives-uf-informatics-institute-seed-fund-grant/" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>UFII Junior SEED Award: Multimodal Visual-Text Learning from Clinical Narrative and Image for Early Detection of Diabetic Retinopathy</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>Vision-threatening diseases are one of the leading causes of blindness. DR, a common complication of diabetes, is the leading cause of blindness in American adults and the fastest growing disease threatening nearly 415 million diabetic patients worldwide. With professional eye imaging devices such as fundus cameras or Optical Coherence Tomography (OCT) scanners, most of the vision-threatening diseases can be curable if detected early. However, these diseases are still damaging people’s vision and leading to irreversible blindness, especially in rural areas and low-income communities where professional imaging devices and medical specialists are not available or not even affordable. There is an urgent need for early detection of vision-threatening diseases before vision loss in these areas. The current practice of DR screening relies on human experts to manually examine and diagnose DR in stereoscopic color fundus photographs at hospitals using professional fundus camera, which is time-consuming and infeasible for large-scale screening. It also puts an enormous burden on ophthalmologists and increases waiting lists and may undermine the standards of health care. Therein, automatic DR diagnosis systems with ophthalmologist-level performance are a critical and unmet need for DR screening. Electronic Health Records (EHR) have been increasingly implemented in US hospitals. Vast amounts of longitudinal patient data have been accumulated and are available electronically in structured tables, narrative text, and images. There is an increasing need for multimodal synergistic learning methods to link different data sources for clinical and translational studies. Recent emerging of AI technologies, especially deep learning (DL) algorithms, have greatly improved the performance of automated vision-disease diagnosis systems based on EHR data. However, the current systems are unable to detect early stage of vision-diseases. On the other hand, the clinical text provides detailed diagnosis, symptoms, and other critical observations documented by physicians, which could be a valuable resource to help lesion detection from medical images. Multimodal synergistic learning is the key to linking clinical text to medical images for lesion detection. This study proposes to leverage the narrative clinical text to improve lesion level detection from medical images via clinical Natural Language Processing (NLP). The team hypothesizes that early stage vision-threatening diseases can be detected using smartphone-based fundus camera via multimodal learning integrating clinical text and images with limited lesion-level labels via clinical NLP. The ultimate goal is to improve the early detection and prevention of vision-threatening diseases among rural and low-income areas by developing a low-cost, highly efficient system that can leverage both clinical narratives and images.</p>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/UFII.png" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.ctsi.ufl.edu/research/funding-opportunities/pilot-project-awardees/" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>UFII-CTSI Pilot Award: Toward prevention of cardiotoxicity in cancer: a multimodal approach leveraging genomics, images and clinical data</h3>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/CTSI.png" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.bme.ufl.edu/bme-doctoral-students-awarded-nih-ctsi-tl1-predoctoral-fellowship/" class="tooltips" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>NIH CTSI TL1: Predicting short-term and long-term effects of spinal cord stimulation: implications for clinical practice</h3>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/CTSI.png" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="https://www.bme.ufl.edu/fang-receives-uf-informatics-institute-seed-fund-grant/" class="tooltips" title="External link" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>Pilot Award: Precision Dose:Personalized Radiation Dose Optimization for Multimodal Imaging</h3>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>
                                
                                        <li>
                                            <div class="row">
                                                <div class="col-sm-6 col-md-3">
                                                    <div class="image">
                                                        <img alt="image" src="img/acknowlegements/orau.jpg" class="img-responsive">
                                                        <div class="imageoverlay">
                                                            <a href="" class="tooltips" target="_blank"><i class="fa fa-search"></i></a>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="col-sm-6 col-md-9">
                                                    <div class="meta">
                                                        <h3>Modeling, Estimating and Reasoning in Limited Data Brain</h3>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="details">
                                                <p>In the current era of invigorating brain research, there is emerging attention in leveraging machine learning in understanding the brain, particularly exploring the brain dynamics. With the ever-increasing amount of neuroscience data, new challenges and opportunities arise for brain dynamics analysis, such as data-driven reconstruction and computer-aided diagnosis. However, there are few attempts to bridge the semantic gaps between the raw brain imaging data and the diagnosis. We will develop robust and data-driven techniques for the purpose of modeling, estimating functional parameters from the limited data brain images, and making decision support practical based on efficient direct estimation of the brain dynamics. This is an interdisciplinary research combining medical image analysis, machine learning, neuroscience, and the domain expertise. </p>
                                            </div>
                                        </li>


                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/NSF Funded Projects-->

                </div>
                <!--/Research-->

                <!--Publications-->
                <div id="publications" class="page">
                    <div class="page-container">
                        <div class="pageheader">
                            <div class="headercontent">
                                <div class="section-container">
                                    <h2 class="title">Publications</h2>
                                    <div class="row">
                                        <div class="col-md-12">
                                            <p></p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="pagecontents">
                            <div class="section color-1" id="filters">
                                <div class="section-container">
                                    <div class="row">
                                        <div class="col-md-3">
                                            <h3>Filter by type:</h3>
                                        </div>
                                        <div class="col-md-6">
                                            <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                            <!-- Publication Catergories Start-->

                                            <option class="filter" value="all" selected>All types (143)</option>
                                            <option class="filter" value="Preprint">Preprint (2)</option>
                                            <option class="filter" value="Journal">Journal (45)</option>
                                            <option class="filter" value="Conference">Conference (79)</option>
                                            <option class="filter" value="Dissertation">Dissertation (3)</option>
                                            <option class="filter" value="Patents">Patents (10)</option>
                                            <option class="filter" value="Book Chapters">Book Chapters (4)</option>
                                            <!-- Publication Catergories End-->
                                            </select>
                                        </div>
                                        <div class="col-md-3" id="sort">
                                            <span>Sort by year:</span>
                                            <div class="btn-group pull-right">
                                                <button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default"><i class="fa fa-sort-numeric-asc"></i></button>
                                                <button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default"><i class="fa fa-sort-numeric-desc"></i></button>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="section color-2" id="pub-grid">
                                <div class="section-container">
                                    <div class="row">
                                        <div class="col-md-12">

                                            <!-- Publications  Start -->
                                            <div class="pitems">

				                                <!--- Publication Example Code
                                                Journal
                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-37-8-1249" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/osa-josaa.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Physiological wound assessment from coregistered and segmented tissue hemoglobin maps</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">E. A. Robledo, R. Schutzman, <strong>R. Fang</strong>, C. Fernandez, R. Kwasinski, K. Leiva, F. Perez-Clavijo, and A. Godavarty</div>
                                                            <div class="pubcite">Journal of the Optical Society of America A</div>
                                                            <div class="pubdate">Publication Year: July, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>A handheld near-infrared optical scanner (NIROS) was recently developed to map for effective changes in oxy- and deoxyhemoglobin concentration in diabetic foot ulcers (DFUs) across weeks of treatment. Herein, a coregistration and image segmentation approach was implemented to overlay hemoglobin maps onto the white light images of ulcers. Validation studies demonstrated over 97% accuracy in coregistration. Coregistration was further applied to a healing DFU across weeks of healing. The potential to predict changes in wound healing was observed when comparing the coregistered and segmented hemoglobin concentration area maps to the visual area of the wound.
                                                    </div>
                                                </div>

                                                Conference
                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://neuromodec.com/nyc-neuromodulation-online-2020/index.html" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neuromodec.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Determinants of Treatment Response to Transcranial Direct Current Stimulation</h4>
                                                            <h5><strong>Outstanding Presentation by Early Career Scientist Award</strong></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Albizu A, <strong>Fang R</strong> Indahlastari A, Nissim NR, OShea A, Woods AJ</div>
                                                            <div class="pubcite">5th Annual NYC Neuromodulation Conference</div>
                                                            <div class="pubdate">Publication Year: April 20-22, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>


                                                Book
                                                <div class="item mix Book Chapters" data-year="2019">
                                                    <div class="pubmain">
                                                        <img width="125" src="img/pubs/Springer.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        <h4 class="pubtitle">Deep Spatial-Temporal Convolutional Neural Networks for Medical Image Restoration Deep Learning and Convolutional Neural Networks for Medical Image Computing </h4>
                                                        <div class="pubauthor">Yao Xiao, Skylar Stolte, Peng Liu, Yun Liang, Pina Sanelli, Ajay Gupta, Jana Ivanidze, and <strong>Ruogu Fang</strong> </div>
                                                        <div class="pubcite"><span class="label label-warning">Book Chapter </span>Deep Learning and Convolutional Neural Networks for Medical Image Computing, Springer Publisher, 2019. </div>
                                                    </div>
                                                </div>

                                                Patents
                                                <div class="item mix Patents" data-year="2018">
                                                    <div class="pubmain">
                                                    <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <h4 class="pubtitle">
                                                            Neural Network Evolution Using Expedited Genetic Algorithm for Medical Image Denoising
                                                        </h4>
                                                        <div class="pubauthor">Peng Liu and <strong> Ruogu Fang</strong></div>
                                                        <div class="pubcite">
                                                            <span class="label label-info">Patents</span>Ref. No: UF-17344, Filed on 9/10/2018, Provisional Patent. US 62/728,995
                                                        </div>
                                                    </div>
                                                </div>

                                                -->

                                                <!--Preferred Image Sizes: Width: 125px-->
                                                <!--ONLY bold for Ruogu Fang-->
                                                <!--ONLY underline for corresponding author-->
                                                <!--2024-->
                                                <div class="item mix Conference" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://sprweb.org/page/FuturePastMeetings" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SPR.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Implementation of an AI Generated Affective Picture Set: Self-report and Psychophysiological Validation</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Faith E Gilbert, Fan Yang, Andrew Farkas, Sarah M Gardy, Hannah M Engle, Angie Cordova, Ricky Cheng, Dean Sabatinelli, Mingzhou Ding, <b>Ruogu Fang</b>, <u>Andreas Keil</u></div>
                                                            <div class="pubcite">Society for Psychophysiological Research 64th Annual Meeting</div>
                                                            <div class="pubdate">Publication Year: October 23-26, 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Preprint" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>

                                                            <a href="https://arxiv.org/abs/2406.10729" class="tooltips" title="arXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/arxiv.png" class="attachment-medium size-medium wp-post-image" alt=""  hspace="20">
                                                        </div>

                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A Comprehensive Survey of Foundation Models in Medicine</h4>
                                                            <span class="label label-warning">Preprint</span>
                                                            <div class="pubauthor">Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubdate">Publication Date: June 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Foundation models (FMs) are large-scale deep-learning models trained on extensive datasets using self-supervised techniques. These models serve as a base for various downstream tasks, including healthcare. FMs have been adopted with great success across various domains within healthcare, including natural language processing (NLP), computer vision, graph learning, biology, and omics. Existing healthcare-based surveys have not yet included all of these domains. Therefore, this survey provides a comprehensive overview of FMs in healthcare. We focus on the history, learning strategies, flagship models, applications, and challenges of FMs. We explore how FMs such as the BERT and GPT families are reshaping various healthcare domains, including clinical large language models, medical image analysis, and omics data. Furthermore, we provide a detailed taxonomy of healthcare applications facilitated by FMs, such as clinical NLP, medical computer vision, graph learning, and other biology-related tasks. Despite the promising opportunities FMs provide, they also have several associated challenges, which are explained in detail. We also outline potential future directions to provide researchers and practitioners with insights into the potential and limitations of FMs in healthcare to advance their deployment and mitigate associated risks.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Preprint" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>

                                                            <a href="https://arxiv.org/abs/2406.10395" class="tooltips" title="arXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>

                                                            <a href="https://github.com/lab-smile/GatorBrain" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/arxiv.png" class="attachment-medium size-medium wp-post-image" alt=""  hspace="20">
                                                        </div>

                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">BrainFounder: Towards Brain Foundation Models for Neuroimage Analysis</h4>
                                                            <span class="label label-warning">Preprint</span>
                                                            <div class="pubauthor">Joseph Cox, Peng Liu, Skylar E. Stolte, Yunchao Yang, Kang Liu, Kyle B. See, Huiwen Ju, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubdate">Publication Date: June 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The burgeoning field of brain health research increasingly leverages artificial intelligence (AI) to interpret and analyze neurological data. This study introduces a novel approach towards the creation of medical foundation models by integrating a large-scale multi-modal magnetic resonance imaging (MRI) dataset derived from 41,400 participants in its own. Our method involves a novel two-stage pretraining approach using vision transformers. The first stage is dedicated to encoding anatomical structures in generally healthy brains, identifying key features such as shapes and sizes of different brain regions. The second stage concentrates on spatial information, encompassing aspects like location and the relative positioning of brain structures. We rigorously evaluate our model, BrainFounder, using the Brain Tumor Segmentation (BraTS) challenge and Anatomical Tracings of Lesions After Stroke v2.0 (ATLAS v2.0) datasets. BrainFounder demonstrates a significant performance gain, surpassing the achievements of the previous winning solutions using fully supervised learning. Our findings underscore the impact of scaling up both the complexity of the model and the volume of unlabeled training data derived from generally healthy brains, which enhances the accuracy and predictive capabilities of the model in complex neuroimaging tasks with MRI. The implications of this research provide transformative insights and practical applications in healthcare and make substantial steps towards the creation of foundation models for Medical AI.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://pubmed.ncbi.nlm.nih.gov/38168460/" class="tooltips" title="publication site" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/bioinformatics.gif" class="attachment-medium size-medium wp-post image" alt="" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Morphological Profiling for Drug Discovery in the Era of Deep Learning</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Qiaosi Tang, Ranjala Ratnayake, Gustavo Seabra, Zhe Jiang, <b>Ruogu Fang</b>, Lina Cui, Yousong Ding, Tamer Kahveci, Jiang Bian, Chenglong Li, Hendrik Luesch, <u>Yanjun Li</u></div>
                                                            <div class="pubcite">Briefings in Bioinformatics (Impact factor=9.5)</div>
                                                            <div class="pubdate">Publication Date: May 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Morphological profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-cell resolution. Concurrently, significant advances in machine learning and deep learning, especially in computer vision, have led to substantial improvements in analyzing large-scale high-content images at high-throughput. These efforts have facilitated understanding of compound mechanism-of-action (MOA), drug repurposing, characterization of cell morphodynamics under perturbation, and ultimately contributing to the development of novel therapeutics. In this review, we provide a comprehensive overview of the recent advances in the field of morphological profiling. We summarize the image profiling analysis workflow, survey a broad spectrum of analysis strategies encompassing feature engineering- and deep learning-based approaches, and introduce publicly available benchmark datasets. We place a particular emphasis on the application of deep learning in this pipeline, covering cell segmentation, image representation learning, and multimodal learning. Additionally, we illuminate the application of morphological profiling in phenotypic drug discovery and highlight potential challenges and opportunities in this field.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2024">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://embc.embs.org/2024/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/EMBC2024.jpg" class="attachment-medium size-medium wp-post-image" alt="" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Learning Analysis of Retinal Structures and Risk Factors of Alzheimer’s Disease</h4>
                                                            <h5><b>IEEE EMBS NextGen Scholar Award</b></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Seowung Leem, Yunchao Yang, Adam J. Woods, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">The 46th International Conference of the IEEE Engineering in Medicine and Biology Society, , Orlando, FL</div>
                                                            <div class="pubdate">Publication Date: July 15-19, 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                    </div>
                                                </div>

                                                <div class="item mix Book Chapters" data-year="2024">
                                                    <div class="pubmain">
                                                       <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i></a>
                                                            <a href="https://link.springer.com/book/9781071636411" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Ctenophores.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Analysis and Visualization of Single-Cell Sequencing Data with Scanpy and MetaCell: A Tutorial</h4>
                                                            <span class="label label-success">Book Chapter</span>
                                                            <div class="pubauthor">Yanjun Li, Chaoyue Sun, Daria Y. Romanova, Dapeng O. Wu, <u><b>Ruogu Fang</b></u>, Leonid L. Moroz.</div>
                                                            <div class="pubcite">Ctenophores, Methods and Protocols, Springer Publisher</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                    <!--    <h4>Abstract</h4>
                                                    Computed tomography perfusion (CTP) facilitates low-cost diagnosis and treatment of acute stroke. Cine scanning allows users to visualize brain anatomy and blood flow in virtually live time. However, effective visualization exposes patients to radiocontrast pharmaceuticals and extended scan times. Higher radiation dosage exposes patients to potential risks including hair loss, cataract formation, and cancer. To alleviate these risks, radiation dosage can be reduced along with tube current and/or X-ray radiation exposure time. However, resulting images may lack sufficient information or be affected by noise and/or artifacts. In this chapter, we propose a deep spatial-temporal convolutional neural network to preserve CTP image quality at reduced tube current, low spatial resolution, and shorter exposure time. This network structure extracts multi-directional features from low-dose and low-resolution patches at different cross sections of the spatial-temporal data and reconstructs high-quality CT volumes. We assess the performance of the network concerning image restoration at different tube currents and multiple resolution scales. The results indicate the ability of our network in restoring high-quality scans from data captured at as low as 21% of the standard radiation dose. The proposed network achieves an average improvement of 7% in perfusion maps compared to the state-of-the-art method.
                                                    -->
                                                </div>
                                                </div>

                                               
                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>

                                                            <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011351" class="tooltips" title="publication site" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>

                                                            <a href="https://www.biorxiv.org/content/10.1101/2023.07.17.549268v1" class="tooltips" title="biorvix" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>

                                                            <a href="https://github.com/lab-smile/DeepDynaForcast" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/PLOS_CB.PNG" class="attachment-medium size-medium wp-post image" alt="" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">DeepDynaForecast: Phylogenetic-informed graph deep learning for epidemic transmission dynamic prediction</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Chaoyue Sun, <u><b>Ruogu Fang</b></u>, Marco Salemi, Mattia Prosperi, Brittany Rife Magalis</div>
                                                            <div class="pubcite">PLOS Computational Biology</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>In the midst of an outbreak or sustained epidemic, reliable prediction of transmission risks and patterns of spread is critical to inform public health programs. Projections of transmission growth or decline among specific risk groups can aid in optimizing interventions, particularly when resources are limited. Phylogenetic trees have been widely used in the detection of transmission chains and high-risk populations. Moreover, tree topology and the incorporation of population parameters (phylodynamics) can be useful in reconstructing the evolutionary dynamics of an epidemic across space and time among individuals. We now demonstrate the utility of phylodynamic trees for transmission modeling and forecasting, developing a phylogeny-based deep learning system, referred to as \textit{DeepDynaForecast}. Our approach leverages a primal-dual graph learning structure with shortcut multi-layer aggregation, which is suited for the early identification and prediction of transmission dynamics in emerging high-risk groups. We demonstrate the accuracy of \textit{DeepDynaForecast} using simulated outbreak data and the utility of the learned model using empirical, large-scale data from the human immunodeficiency virus epidemic in Florida between 2012 and 2020. Our framework is available as open-source software (MIT license) at github.com/lab-smile/DeepDynaForcast.</p>
                                                    </div>
                                                </div>

                                                
                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>

                                                            <a href="https://www.nature.com/articles/s41598-024-58121-8" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>

                                                            <a href="https://zenodo.org/badge/latestdoi/590054290" class="tooltips" title="zenodo" target="_blank">
                                                                <i class="fa fa-code"></i>
                                                            </a>

                                                            <a href="https://arxiv.org/abs/2302.03008" class="tooltips" title="arXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>

                                                            <a href="https://github.com/lab-smile/LAVA" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SciReports.jpg" class="attachment-medium size-medium wp-post-image" alt=""  hspace="20">
                                                        </div>

                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, <u><b>Ruogu Fang</b></u>, <u>My T. Thai</u></div>
                                                            <div class="pubcite">Nature Scientific Reports</div>
                                                            <div class="pubdate">Publication Date: April 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Alzheimer’s Disease (AD) is a progressive neurodegenerative disease and the leading cause of dementia. Early diagnosis is critical for patients to benefit from potential intervention and treatment. The retina has emerged as a plausible diagnostic site for AD detection owing to its anatomical connection with the brain. However, existing AI models for this purpose have yet to provide a rational explanation behind their decisions and have not been able to infer the stage of the disease’s progression. Along this direction, we propose a novel model-agnostic explainable-AI framework, called Granur Neuron-leel Expliner (LAVA), an interpretation prototype that probes into intermediate layers of the Convolutional Neural Network (CNN) models to directly assess the continuum of AD from the retinal imaging without the need for longitudinal or clinical evaluations. This innovative approach aims to validate retinal vasculature as a biomarker and diagnostic modality for evaluating Alzheimer’s Disease. Leveraged UK Biobank cognitive tests and vascular morphological features demonstrate significant promise and effectiveness of LAVA in identifying AD stages across the progression continuum.</p>
                                                    </div>
                                                </div>

                                            

                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            
                                                            <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011943" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>

                                                            <a href="https://www.biorxiv.org/content/10.1101/2023.04.16.537079v1" class="tooltips" title="Link" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/PLOS_CB.PNG" class="attachment-medium size-medium wp-post image" alt="" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Emergence of Emotion Selectivity in A Deep Neural Network Trained to Recognize Visual Objects</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Peng Liu, Ke Bo, Mingzhou Ding, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">PLOS Computational Biology</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Recent neuroimaging studies have shown that the visual cortex plays an important role in representing the affective significance of visual input. The origin of these affect-specific visual representations is debated: they are intrinsic to the visual system versus they arise through reentry from frontal emotion processing structures such as the amygdala. We examined this problem by combining convolutional neural network (CNN) models of the human ventral visual cortex pre-trained on ImageNet with two datasets of affective images. Our results show that in all layers of the CNN models, there were artificial neurons that responded consistently and selectively to neutral, pleasant, or unpleasant images and lesioning these neurons by setting their output to zero or enhancing these neurons by increasing their gain led to decreased or increased emotion recognition performance respectively. These results support the idea that the visual system may have the intrinsic ability to represent the affective significance of visual input and suggest that CNNs offer a fruitful platform for testing neuroscientific theories.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2024">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://doi.org/10.5220/0012375400003657" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/scitepress.png" class="attachment-medium size-medium wp-post-image" alt="" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Learning on Forecasting HIV Epidemic Based on Individuals' Contact Networks</h4>
                                                            <h5><b>Best Paper Award</b></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Chaoyue Sun, Yiyang Liu, Christina Parisi, Rebecca Fisk-Hoffman, Marco Salemi, <b>Ruogu Fang</b>, Brandi Danforth, Mattia Prosperi and Simone Marini</div>
                                                            <div class="pubcite">The 17th International Conference on Health Informatics (HEALTHINF/BIOSTEC), Rome - Italy</div>
                                                            <div class="pubcite">Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies, Volume 2, ISBN 978-989-758-688-0, ISSN 2184-4305, pages 103-111, 2024.</div>
                                                            <div class="pubdate">Publication Date: February 21 - 23, 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Improving the diagnosis of HIV is a fundamental objective of the Ending the HIV Epidemic initiative, as it represents the initial step toward treatment and achieving undetectable status, thereby reducing transmission. To attain these objectives effectively, it is crucial to identify the groups most susceptible to HIV, allowing interventions to be tailored to their specific needs. In this study, we developed a predictive model designed to assess individual HIV risk within a high-risk contact network predicting treatment or at-risk leveraging surveillance data collected through routine HIV case interviews in Florida. Unique to our analysis, we explored the incorporation of behavioral network information with Graph Neural Networks to enhance the predictive capacity for identifying individuals within the treatment or intervention categories, when compared to models that mainly consider conventional HIV risk factors. Our deployed Graph Isomorphism Network achieved 77.3% and 73.2% balanced accuracy in inductive and transductive learning scenarios respectively, outperforming the traditional prediction algorithms that do not leverage the network structure. We then used our model to further investigate the importance of demographic and behavioral factors in the HIV risk prediction process. Our findings provide valuable insights for healthcare practitioners and policymakers in their efforts to combat HIV infection.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/article/10.1038/s41598-024-54251-1?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20240213&utm_content=10.1038/s41598-024-54251-1" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="https://github.com/lab-smile/RetinaPD" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SciReports.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Learning Predicts Prevalent and Incident Parkinson’s Disease From UK Biobank Fundus Imaging</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Charlie Tran, Kai Shen, Kang Liu, Akshay Ashok, Adolfo Ramirez-Zamora4 Jinghua Chen, Yulin Li, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Nature Scientific Reports</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Parkinson’s disease is the world’s fastest-growing neurological disorder. Research to elucidate the mechanisms of Parkinson’s disease and automate diagnostics would greatly improve the treatment of patients with Parkinson’s disease. Current diagnostic methods are expensive and have limited availability. Considering the insidious and preclinical onset and progression of the disease, a desirable screening should be diagnostically accurate even before the onset of symptoms to allow medical interventions. We highlight retinal fundus imaging, often termed a window to the brain, as a diagnostic screening modality for Parkinson’s disease. We conducted a systematic evaluation of conventional machine learning and deep learning techniques to classify Parkinson’s disease from UK Biobank fundus imaging. Our results suggest Parkinson’s disease individuals can be differentiated from age and gender-matched healthy subjects with 68% accuracy. This accuracy is maintained when predicting either prevalent or incident Parkinson’s disease. Explainability and trustworthiness are enhanced by visual attribution maps of localized biomarkers and quantified metrics of model robustness to data perturbations.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00090/119208/Precise-and-Rapid-Whole-Head-Segmentation-from" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IMAGNeuro.png" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Precise and Rapid Whole-Head Segmentation from Magnetic Resonance Images of Older Adults using Deep Learning</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Skylar E. Stolte, Aprinda Indahlastari, Jason Chen, Alejandro Albizu, Ayden Dunn, Samantha Pedersen, Kyle B. See, Adam J. Woods, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Imaging Neuroscience-Inspired</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Whole-head segmentation from Magnetic Resonance Images (MRI) establishes the foundation for individualized computational models using finite element method (FEM). This foundation paves the path for computer-aided solutions in fields, particularly in non-invasive brain stimulation. Most current automatic head segmentation tools are developed using healthy young adults. Thus, they may neglect the older population that is more prone to age-related structural decline such as brain atrophy. In this work, we present a new deep learning method called GRACE, which stands for General, Rapid, And Comprehensive whole-hEad tissue segmentation. GRACE is trained and validated on a novel dataset that consists of 177 manually corrected MR-derived reference segmentations that have undergone meticulous manual review. Each T1-weighted MRI volume is segmented into 11 tissue types, including white matter, grey matter, eyes, cerebrospinal fluid, air, blood vessel, cancellous bone, cortical bone, skin, fat, and muscle. To the best of our knowledge, this work contains the largest manually corrected dataset to date in terms of number of MRIs and segmented tissues. GRACE outperforms five freely available software tools and a traditional 3D U-Net on a five-tissue segmentation task. On this task, GRACE achieves an average Hausdorff Distance of 0.21, which exceeds the runner-up at an average Hausdorff Distance of 0.36. GRACE can segment a whole-head MRI in about 3 seconds, while the fastest software tool takes about 3 minutes. In summary, GRACE segments a spectrum of tissue types from older adults T1-MRI scans at favorable accuracy and speed. The trained GRACE model is optimized on older adult heads to enable high-precision modeling in age-related brain disorders. To support open science, the GRACE code and trained weights will be made available online and open to the research community upon publication.</p>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Journal" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002754?dgcid=coauthor" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/JVCIR.gif" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Texture and motion aware perception in-loop filter for AV1</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Tianqi Liu, Hong Huang, Zhijun Lei, <b>Ruogu Fang</b>, Dapeng Wu</div>
                                                            <div class="pubcite">Journal of Visual Communication and Image Representation</div>
                                                            <div class="pubdate">Publication Year: February 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Lossy compression introduces artifacts, and many conventional in-loop filters have been adopted in the AV1 standard to reduce these artifacts. Researchers have explored deep learning-based filters to remove artifacts in the compression loop. However, the high computational complexity of CNN-based filters remains a challenge. In this paper, a Texture- and Motion-Aware Perception (TMAP) in-loop filter is proposed to addresses this issue by selectively applying CNNs to texture-rich and high-motion regions, while utilizing non-learning methods to detect these regions. The proposed method introduces a new CNN structure, the Dense-Dual-Field Network (DDFN), which leverages a larger receptive field to enhance the quality of reconstructed frames by incorporating more contextual information. Furthermore, to improve perceptual quality, a novel loss function integrating wavelet-based perceptual information is presented. Experimental results demonstrate the superiority of our proposed models over other lightweight CNN models, and the effectiveness of the perceptual loss function is validated using the VMAF metric.</p>
                                                    </div>
                                                </div>

                                                <!--2023-->
                                                <div class="item mix Book Chapters" data-year="2024">
                                                    <div class="pubmain">
                                                       <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i></a>
                                                            <a href="https://www.routledge.com/Medical-Image-Synthesis-Methods-and-Clinical-Applications/Yang/p/book/9781032152844" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/TaylorFrancis.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Medical Imaging Denoising</h4>
                                                            <span class="label label-success">Book Chapter</span>
                                                            <div class="pubauthor">Yao Xiao, Kai Huang, Hely Lin, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Medical Image Synthesis: Methods and Clinical Applications, Taylor & Francis group</div>
                                                            <div class="pubdate">Publication Year: 2024</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                    <!--    <h4>Abstract</h4>
                                                    Computed tomography perfusion (CTP) facilitates low-cost diagnosis and treatment of acute stroke. Cine scanning allows users to visualize brain anatomy and blood flow in virtually live time. However, effective visualization exposes patients to radiocontrast pharmaceuticals and extended scan times. Higher radiation dosage exposes patients to potential risks including hair loss, cataract formation, and cancer. To alleviate these risks, radiation dosage can be reduced along with tube current and/or X-ray radiation exposure time. However, resulting images may lack sufficient information or be affected by noise and/or artifacts. In this chapter, we propose a deep spatial-temporal convolutional neural network to preserve CTP image quality at reduced tube current, low spatial resolution, and shorter exposure time. This network structure extracts multi-directional features from low-dose and low-resolution patches at different cross sections of the spatial-temporal data and reconstructs high-quality CT volumes. We assess the performance of the network concerning image restoration at different tube currents and multiple resolution scales. The results indicate the ability of our network in restoring high-quality scans from data captured at as low as 21% of the standard radiation dose. The proposed network achieves an average improvement of 7% in perfusion maps compared to the state-of-the-art method.
                                                    -->
                                                </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.nature.com/articles/s41746-023-00953-1?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20231117&utm_content=10.1038/s41746-023-00953-1" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/nature.digitalmedicine.png" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Ethnic disparity in diagnosing asymptomatic bacterial vaginosis using machine learning</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Cameron Celeste, Dion Ming, Justin Broce, Diandra P. Ojo, Emma Drobina, Adetola F. Louis-Jacques, Juan E. Gilbert, <u><b>Ruogu Fang</b></u>†, Ivana Parker † <br/>
                                                            († co-corresponding authors)</div>
                                                            <div class="pubcite">Nature npj Digital Medicine</div>
                                                            <div class="pubdate">Publication Year: November 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>A handheld near-infrared optical scanner (NIROS) was recently developed to map for effective changes in oxy- and deoxyhemoglobin concentration in diabetic foot ulcers (DFUs) across weeks of treatment. Herein, a coregistration and image segmentation approach was implemented to overlay hemoglobin maps onto the white light images of ulcers. Validation studies demonstrated over 97% accuracy in coregistration. Coregistration was further applied to a healing DFU across weeks of healing. The potential to predict changes in wound healing was observed when comparing the coregistered and segmented hemoglobin concentration area maps to the visual area of the wound.</p>
                                                    </div>
                                                </div>


                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            
                                                            <a href="https://www.bmes.org/meetings/2023-bmes-annual-meeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Ethnic Disparity in Diagnosing Asymptomatic Bacterial Vaginosis Using Machine Learning</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Cameron Celeste, Dion Ming, Justin Broce, Diandra Ojo, Emma Drobina, Juan Gilbert, <b>Ruogu Fang</b>, Ivana Parker</div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Seattle, WA.</div>
                                                            <div class="pubdate">Publication Date: October 11-14, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            
                                                            <a href="https://www.bmes.org/meetings/2023-bmes-annual-meeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Feature selection in ML identifies unique bacteria to consider for fair BV diagnosis among ethnicities</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Dion Ming, Cameron Celeste, Emma Drobina, Justin Broce, Diandra Ojo, <b>Ruogu Fang</b>, Ivana Parker</div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Seattle, WA.</div>
                                                            <div class="pubdate">Publication Date: October 11-14, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="" class="tooltips" title="MICCAI" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="https://arxiv.org/abs/2308.10453" class="tooltips" title="ArXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>
                                                            <a href="" class="tooltips" title="CodeOcean" target="_blank">
                                                                <i class="icon-codeocean"></i>
                                                            </a>
                                                            <a href="https://github.com/lab-smile/DOMINOplusplus" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam Woods, Kevin Brink, Matthew Hale, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), Vancouver, Canada. </div>
                                                            <div class="pubdate">Publication Year: October 08-12, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            
                                                            <a href="https://www.bmes.org/meetings/2023-bmes-annual-meeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Large Brain Models: Large-scale 3D Pretrained Deep Learning Models for Neuroimages</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Joseph Cox, Yunchao Yang, Huiwen Ju, Justin Broce, <u><b>Ruogu Fang</b></u>.</div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Seattle, WA.</div>
                                                            <div class="pubdate">Publication Date: October 11-14, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            
                                                            <a href="https://www.bmes.org/meetings/2023-bmes-annual-meeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                                                                                                                            
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Can Deep Convolutional Neural Network Associate Emotions with Gabor Patches?</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Seowung Leem, Andreas Keil, Peng Liu, Mingzhou Ding, <u><b>Ruogu Fang</b></u>.</div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Seattle, WA.</div>
                                                            <div class="pubdate">Publication Date: October 11-14, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://sprweb.org/page/FuturePastMeetings" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SPR.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Building and Evaluating an AI Generated, Standardized Affective Picture Dataset</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Faith E Gilbert, Ethan Smith, Hannah M Engle, Caitlin M Traiser, Arash Mirifar, Christian Panitz, Jourdan Pouliot, Laura C Ahumada Hernandez, , Mingzhou Ding, <b>Ruogu Fang</b>, <u>Andreas Keil</u></div>
                                                            <div class="pubcite">Society for Psychophysiological Research 63rd Annual Meeting</div>
                                                            <div class="pubdate">Publication Year: September 27 - October 1, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.brainstimjrnl.com/article/S1935-861X(23)01787-4/fulltext" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/brainstim.gif" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine-Learning Defined Precision tDCS for Improving Cognitive Function</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Alejandro Albizu, Aprinda Indahlastari, Ziqian Huang, Jori Waner, Skylar E. Stolte, <u><b>Ruogu Fang</b></u>, <u>Adam J. Woods</u></div>
                                                            <div class="pubdate">Publication Year: June, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <h4>Background</h4>
                                                        Transcranial direct current stimulation (tDCS) paired with cognitive training (CT) is widely inves- tigated as a therapeutic tool to enhance cognitive function in older adults with and without neurodegenerative disease. Prior research demonstrates that the level of benefit from tDCS paired with CT varies from person to person, likely due to individual differences in neuroanatomical structure.
                                                        
                                                        <h4>Objective</h4>
                                                        The current study aims to develop a method to objectively optimize and personalize current dosage to maximize the functional gains of non-invasive brain stimulation.
                                                        
                                                        <h4>Methods</h4>
                                                        A support vector machine (SVM) model was trained to predict treatment response based on compu- tational models of current density in a sample dataset (n = 14). Feature weights of the deployed SVM were used in a weighted Gaussian Mixture Model (GMM) to maximize the likelihood of converting tDCS non-responders to responders by finding the most optimum electrode montage and applied current intensity (optimized models).
                                                        
                                                        <h4>Results</h4>
                                                        Current distributions optimized by the proposed SVM-GMM model demonstrated 93% voxel-wise coherence within target brain regions between the originally non-responders and responders. The optimized current distribution in original non-responders was 3.38 standard deviations closer to the current dose of re- sponders compared to the pre-optimized models. Optimized models also achieved an average treatment response likelihood and normalized mutual information of 99.993% and 91.21%, respectively. Following tDCS dose optimization, the SVM model successfully predicted all tDCS non-responders with optimized doses as responders.
                                                        
                                                        <h4>Conclusion</h4>
                                                        The results of this study serve as a foundation for a custom dose optimization strategy towards precision medicine in tDCS to improve outcomes in cognitive decline remediation for older adults.                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Journal" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2023.1208253/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Human_Neuroscience&id=1208253" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Frontiers.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Editorial: Frontiers of women in brain imaging and brain stimulation</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><strong>Ruogu Fang</strong>, Lijun Bai, Wen Li</div>
                                                            <div class="pubdate">Publication Year: May, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Advancements in brain imaging and stimulation have revolutionized our understanding of the human brain, its functioning, and the associated disorders. However, the historical male-dominated culture and practice in this field and the underrepresentation of women researchers and leaders could curb its development and limit its full potential. As such, this Research Topic, “Women in brain imaging and stimulation,” aims to showcase the work led by female researchers in the field and highlight their scholarship and scientific achievements at the frontier of interdisciplinary research of brain imaging and stimulation.</p>
                                                    </div>
                                                </div>


                                                <div class="item mix Conference" data-year="2023">
                                                    <div class="pubmain"></a>
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            
                                                            <a href="https://icdcs2023.icdcs.org/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                             </a>
                                                        </div>

                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        
                                                        
                                                        
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Distributed Pruning Towards Tiny Neural Networks in Federated Learning</h4>
                                                            <h5><b>Acceptance Rate: 18.9%</b></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Hong Huang, Lan Zhang, Chaoyue Sun, <u><b>Ruogu Fang</b></u>, Xiaoyong Yuan, and Dapeng Wu.</div>
                                                            <div class="pubcite">43rd IEEE International Conference on Distributed Computing Systems (ICDCS 2023).</div>
                                                            <div class="pubdate">Publication Year: July 18-21, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Neural network pruning is an essential technique for reducing the size and complexity of deep neural networks, enabling large-scale models on devices with limited resources. However, existing pruning approaches heavily rely on training data for guiding the pruning strategies, making them ineffective for federated learning over distributed and confidential datasets. Additionally, the memory- and computation-intensive pruning process becomes infeasible for recourse-constrained devices in federated learning. To address these challenges, we propose FedTiny, a distributed pruning framework for federated learning that generates specialized tiny models for memory- and computing-constrained devices. We introduce two key modules in FedTiny to adaptively search coarse- and finer-pruned specialized models to fit deployment scenarios with sparse and cheap local computation. First, an adaptive batch normalization selection module is designed to mitigate biases in pruning caused by the heterogeneity of local data. Second, a lightweight progressive pruning module aims to finer prune the models under strict memory and computational budgets, allowing the pruning policy for each layer to be gradually determined rather than evaluating the overall model structure. The experimental results demonstrate the effectiveness of FedTiny, which outperforms state-of-the-art approaches, particularly when compressing deep models to extremely sparse tiny models. FedTiny achieves an accuracy improvement of 2.61% while significantly reducing the computational cost by 95.91% and the memory footprint by 94.01% compared to state-of-the-art methods.</p>
                                                    </div>
                                                </div>


                                                <div class="item mix Journal" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S2665963823000155?via%3Dihub" class="tooltips" title="Link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="https://arxiv.org/abs/2302.05142" class="tooltips" title="ArXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>
                                                            <a href="https://codeocean.com/capsule/6022409/tree/v2" class="tooltips" title="CodeOcean" target="_blank">
                                                                <i class="icon-codeocean"></i>
                                                            </a>
                                                            <a href="https://github.com/lab-smile/DOMINO" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SoftwareImpacts.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">DOMINO: Domain-aware Model Calibration in Medical Image Segmentation</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Skylar Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam Woods, Kevin Brink, Matthew Hale, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Software Impacts </div>
                                                            <div class="pubdate">Accepted: Feb, 2023</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Model calibration measures the agreement between the predicted probability estimates and the true correctness likelihood. Proper model calibration is vital for high-risk applications. Unfortunately, modern deep neural networks are poorly calibrated, compromising trustworthiness and reliability. Medical image segmentation particularly suffers from this due to the natural uncertainty of tissue boundaries. This is exasperated by their loss functions, which favor overconfidence in the majority classes. We address these challenges with DOMINO, a domain-aware model calibration method that leverages the semantic confusability and hierarchical similarity between class labels. Our experiments demonstrate that our DOMINO-calibrated deep neural networks outperform non-calibrated models and state-of-the-art morphometric methods in head image segmentation. Our results show that our method can consistently achieve better calibration, higher accuracy, and faster inference times than these methods, especially on rarer classes. This performance is attributed to our domain-aware regularization to inform semantic model calibration. These findings show the importance of semantic ties between class labels in building confidence in deep learning models. The framework has the potential to improve the trustworthiness and reliability of generic medical image segmentation models.</p>
                                                    </div>
                                                </div>

                                                <!--2022-->                                                

                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0197458022002299?via%3Dihub" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/NoA.jpeg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Association of Longitudinal Cognitive Decline with Diffusion Changes in Gray Matter, and Amyloid and Tau Deposition</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Wei-en Wang, Rob Chen, Robin Perry Mayrand, Malek Adjouadi, <b>Ruogu Fang</b>, Steven T. DeKosky, Ranjan Duara, Stephen A. Coombes, David E. Vaillancourt, for the Alzheimer's Disease Neuroimaging Initiative</div>
                                                            <div class="pubcite">Neurobiology of Aging, </div>
                                                            <div class="pubdate">Publication Year: 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <h4>Background</h4>
                                                        <p>Extracellular amyloid plaques in gray matter are the earliest pathological marker for Alzheimer’s disease (AD), followed by abnormal intraneuronal tau protein accumulation. Diffusion MRI (dMRI) is an imaging technique that estimates diffusion properties of the extracellular and tissue compartments. The link between diffusion changes and amyloid and tau pathology in gray matter is not well understood. We aimed to characterize the relationship between diffusion measures and amyloid and tau deposits in the gray matter across Braak stages, as assessed by tau PET imaging, in mild cognitive impairment (MCI) and AD patients. </p>

                                                        <h4>Methods</h4>
                                                        We performed cross-sectional analyses on neuroimages including T1-weighted imaging, dMRI, and amyloid and tau positron emission tomography (PET) images from the Alzheimer’s Disease Neuroimaging Initiative database (ADNI2/3). The selected cohort included 77 normal controls (CN), 97 MCI, and 90 AD patients. We evaluated cortical volume, free-water, fractional anisotropy (FA), and amyloid and tau standardized uptake value ratio (SUVRs) in all subjects. Demographic and clinical data were also assessed. We used support vector machine regression to predict an individual’s Mini Mental State Exam (MMSE) score at baseline (T1) and one year later (T2), and then compared the r-squared values of different predictive models that varied based on which imaging modalities they included.

                                                        <h4>Results</h4>
                                                        Significant between-group differences in T1 volume, free-water, FA, and amyloid and tau SUVRs were found in multiple gray matter brain regions across Braak stages. For the AD and MCI groups, increasing amyloid burden was associated with reduced extracellular free-water in the entorhinal cortex and hippocampus compared to controls, whereas increasing tau burden was associated with increased extracellular free-water in the same regions for the AD group. Diffusion measures alone predicted MMSE score one year later with a high r-square value (93%), whereas tau PET (72%), T1 volume (43%), and amyloid PET had lower r-square values (9%). Combining tau PET and diffusion measures predicted MMSE with a high r-square (94%).  

                                                        <h4>Discussion</h4>
                                                        Microstructural disruption of the extracellular and tissue compartments in gray matter regions across Braak stages is evident in both MCI and AD. We provide evidence of close associations between amyloid and tau deposits and diffusion changes in the entorhinal cortex and hippocampus in MCI and AD. Diffusion imaging of the mesial temporal region appears to be a potent marker for predicting cognitive decline, more sensitive than amyloid or tau imaging. While diffusion imaging changes do not indicate a specific diagnosis, the regional distribution of free water changes may identify abnormalities in a pattern indicative of a particular diagnosis. 
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://alz-journals.onlinelibrary.wiley.com/doi/abs/10.1002/alz.067612" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/AA.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Augmenting cognitive training in older adults with transcranial direct current stimulation: Initial results from the Phase III ACT trial and new directions</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u>Adam J. Woods</u>, Gene Alexander, Ronald Cohen, Michael Marsiske, Steven T DeKosky, Georg A. Hishaw, Samuel S. Wu, Aprinda Indahlastari, Alejandro Albizu, <b>Ruogu Fang</b></div>
                                                            <div class="pubcite">Alzheimer's Association</div>
                                                            <div class="pubdate">Publication Year: 20 Dec, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <h4>Background</h4>
                                                        <p>Effective non-pharmacological interventions to remediate age-related cognitive decline and alter trajectories toward dementia are limited. The Augmenting Cognitive Training in Older Adults trial (ACT) was the first phase III randomized clinical trial initiated for transcranial direct current stimulation.                                                        </p>

                                                        <h4>Methods</h4>
                                                        <p> NIA funded trial sought to evaluate whether 3 months of cognitive training paired with bilateral 2mA tDCS to the frontal lobes could produce clinically meaningful improvement in a composite measure of cognitive function in healthy older adults: the NIH Toolbox Fluid Cognition Composite score. The ACT trial will be unblinded April 30, 2022. Further still, over the past 5 years, it has become increasingly evident that fixed dosing approaches to tDCS, like those used in the ACT and every other trial to date, are insufficient for addressing individual differences and maximizing clinical outcomes.</p>

                                                        <h4>Results</h4>
                                                        <p>We will present, for the first time, the primary outcome results from the ACT trial. In addition, we will present initial findings from related secondary neuroimaging and cognitive indices. In this talk, we will also present preliminary findings from our ongoing work to refine dosing technology for tDCS in older adults using computational modeling, artificial intelligence and multimodal imaging, paired with tDCS outcomes from the ACT trial.</p>

                                                        <h4>Conclusions</h4>
                                                        <p>We will present new analyses, available only upon unblinding of ACT. These data use person-specific computational models of tDCS current flow paired with machine learning and clinical outcomes to identify critical characteristics of tDCS current in the brain (e.g., intensity, direction of current flow) most strongly associated with response vs. non-response. These data will provide initial insight into which regions of the brain and what characteristics of current were strongly associated with treatment response in the ACT trial. In addition, these data also provide critical insight into how stimulation dosing (electrode positioning, stimulation intensity) can be modified at a person-specific level to potentially enhance clinical outcomes. Thus, the proposed talk will provide state of the art trial findings from the first completed tDCS Phase III clinical trial paired with next generation approaches to remediated age-related cognitive decline using tDCS technology.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-022-01996-2" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMC.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Zehao Yu , Xi Yang, Gianna L. Sweeting, Yinghan Ma, Skylar E. Stolte, <b>Ruogu Fang</b>, Yonghui Wu</div>
                                                            <div class="pubcite">BMC Medical Informatics and Decision Making</div>
                                                            <div class="pubdate">Publication Year: Sept, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <h4>Background</h4>
                                                        <p>Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports.</p>

                                                        <h4>Methods</h4>
                                                        In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including ‘gold-standard’ setting—where gold-standard concepts were used–and end-to-end setting.

                                                        <h4>Results</h4>
                                                        For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores.

                                                        <h4>Conclusions</h4>
                                                        This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it’s necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better.
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Conference" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.sfn.org/meetings/neuroscience-2022" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SfN.jpeg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Differential Aversive and Appetitive Conditioning in Artificial Neural Networks</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Seowung Leem, Andreas Keil, Peng Liu, Mingzhou Ding, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Neuroscience 2022, San Diego, USA</div>
                                                            <div class="pubdate">Publication Year: Nov.12 - Nov.16, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                            
                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fradi.2022.904601/full" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/frontiers-radiology.png" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">PIMA-CT: Physical Model-Aware Cyclic Simulation and Denoising for Ultra-Low-Dose CT Restoration</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Peng Liu, Linsong Xu, Garrett Fullerton, Yao Xiao, James-Bond Nguyen, Zhongyu Li, Izabella Barreto, Catherine Olguin, <b><u>Ruogu Fang</u></b></div>
                                                            <div class="pubcite">Frontiers in Radiology</div>
                                                            <div class="pubdate">Publication Year: May, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>A body of studies has proposed to obtain high-quality images from low-dose and noisy Computed Tomography (CT) scans for radiation reduction. However, these studies are designed for population-level data without considering the variation in CT devices and individuals, limiting the current approaches' performance, especially for ultra-low-dose CT imaging. Here, we proposed PIMA-CT, a physical anthropomorphic phantom model integrating an unsupervised learning framework, using a novel deep learning technique called Cyclic Simulation and Denoising (CSD), to address these limitations. We first acquired paired low-dose and standard-dose CT scans of the phantom and then developed two generative neural networks: noise simulator and denoiser. The simulator extracts real low-dose noise and tissue features from two separate image spaces (e.g., low-dose phantom model scans and standard-dose patient scans) into a unified feature space. Meanwhile, the denoiser provides feedback to the simulator on the quality of the generated noise. In this way, the simulator and denoiser cyclically interact to optimize network learning and ease the denoiser to simultaneously remove noise and restore tissue features. We thoroughly evaluate our method for removing both real low-dose noise and Gaussian simulated low-dose noise. The results show that CSD outperforms one of the state-of-the-art denoising algorithms without using any labeled data (actual patients' low-dose CT scans) nor simulated low-dose CT scans. This study may shed light on incorporating physical models in medical imaging, especially for ultra-low level dose CT scans restoration.
                                                    </div>
                                                </div>
                                                
                                                <!--
                                                <div class="item mix Conference" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.rsna.org/annual-meeting?gclid=Cj0KCQjwxIOXBhCrARIsAL1QFCZYwtWhaJQMfaHYhT_I7cnRznr0GMUMckBNLmcwJaUKewrRn1FjduAaApsfEALw_wcB" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/RSNA.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">MAGIC: Multitask synthesis of contrast-free CT perfusion maps via generative adversarial network </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Garrett Fullerton, Simon Kato, Dhanashree Rajderkar, John Rees, Pina Sanelli, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">108th Annual Meeting of the Radiology Society of North America (RSNA), Chicago, USA</div>
                                                            <div class="pubdate">Publication Year: Nov. 27 - Dec.1, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                                -->
                                                
                                                <div class="item mix Conference" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://conferences.miccai.org/2022/papers/170-Paper1693.html" class="tooltips" title="MICCAI" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="https://arxiv.org/abs/2209.06077" class="tooltips" title="ArXiv" target="_blank">
                                                                <i class="fa fa-book"></i>
                                                            </a>
                                                            <a href="https://codeocean.com/capsule/6022409/tree/v2" class="tooltips" title="CodeOcean" target="_blank">
                                                                <i class="icon-codeocean"></i>
                                                            </a>
                                                            <a href="https://github.com/lab-smile/DOMINO" class="tooltips" title="Github" target="_blank">
                                                                <i class="fa fa-github"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">DOMINO: Domain-aware Model Calibration in Medical Image Segmentation</h4>
                                                            <h5><b>Best Paper Presentation Award Runner Up, Women in MICCAI. Oral Presentation (rate=2.3%), Early Acceptance (rate=13%), Student Travel Award</b></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam Woods, Kevin Brink, Matthew Hale, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), Singapore. </div>
                                                            <div class="pubdate">Publication Year: September 18-22, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                                                                                
                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://diabetesjournals.org/diabetes/article/71/Supplement_1/173-OR/146043/173-OR-Associations-between-Post-Discharge-Care" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Diabetes.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Associations between Post-Discharge Care (PDC) and Cognitive Impairment-Related Hospital Readmissions for Ketoacidosis and Severe Hypoglycemia in Adults with Diabetes</strong></h5>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Yehua Wang, Ping Zhang, <strong>Ruogu Fang</strong>, Joshua Brown, Jingchuan Guo, Tianze Jiao, Hui Shao</div>
                                                            <div class="pubcite">Diabetes 71, no. Supplement_1 </div>
                                                            <div class="pubdate">Publication Date: June 01, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                            
                                                <div class="item mix Journal" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://diabetesjournals.org/diabetes/article/71/Supplement_1/893-P/145410" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Diabetes.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Incremental Health Care Utilizations and Medical Expenditures Associated with Cognitive Impairment among Older Adults with Diabetes</strong></h5>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Dawei Guan, Ping Zhang, Shichao Tang, Joshua Brown, <strong>Ruogu Fang</strong>, Jingchuan Guo, Yongkang Zhang, Hui Shao</div>
                                                            <div class="pubcite">Diabetes 71, no. Supplement_1 </div>
                                                            <div class="pubdate">Publication Date: June 01, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                        
                                                <div class="item mix Patents" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">System and Method for Precision Dosing For Electrical Stimulation of the Brain</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor">Adam Woods, Alejandro Albizu, <u><b>Ruogu Fang</b></u>, Aprinda Indahlastari</div>
                                                            <div class="pubcite">WO 2022/026573 A1</div>
                                                            <div class="pubdate">International patent published on February 3, 2022</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                                
                                                
                                                <!--2021-->
                                        
                                                <div class="item mix Patents" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine Learning For Predicting Parkinson’s Disease Based On Retinal Fundus Images</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Max Diaz</div>
                                                            <div class="pubcite">U.S. Patent Recorded on December 22, 2021</div>
                                                            <div class="pubdate"></div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A Machine Learning System And Method For Predicting Alzheimer’s Disease Based On Retinal Fundus Images</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Jianqiao Tian</div>
                                                            <div class="pubcite">T18201US001 (222107-8215). International Patent. WO 2021/243246 A1</div>
                                                            <div class="pubdate">Published on December 2, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Systems And Methods For Reconstructing Realistic Noisy Medical Images</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Peng Liu</div>
                                                            <div class="pubcite">WO 2021/202170 A1. International patent</div>
                                                            <div class="pubdate">Published on October 7, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multimodal CT Image Super-Resolution Via Transfer Generative Adversarial Network</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Yao Xiao</div>
                                                            <div class="pubcite">U.S-2021-0272237-A1</div>
                                                            <div class="pubdate">Published on September 2, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Neural Network Evolution Using Expedited Genetic Algorithm for Medical Image Denoising</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Peng Liu</div>
                                                            <div class="pubcite">U.S. Utility Patent US 11,069,033 B2</div>
                                                            <div class="pubdate">Published on July 20, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                 <div class="item mix Dissertation" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/uf.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Biology and Neuroscience Inspired Deep Learning</h4>
                                                            <span class="label label-success">PhD Dissertation</span>
                                                            <div class="pubauthor"><strong>Peng Liu</strong></div>
                                                            <div class="pubcite">Biomedical Engineering, University of Florida</div>
                                                            <div class="pubdate">Publication Year: 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1053811921009824" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/NeuroImage.gif" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Unraveling Somatotopic Organization in the Human Brain using Machine Learning and Adaptive Supervoxel-based Parcellations</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Kyle B. See, David J. Arpin, David E. Vaillancourt, <u><b>Ruogu Fang</b></u>, Stephen A. Coombes</div>
                                                            <div class="pubcite">NeuroImage</div>
                                                            <div class="pubdate">Publication Date: November, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>In addition to the well-established somatotopy in the pre- and post-central gyrus, there is now strong evidence that somatotopic organization is evident across other regions in the sensorimotor network. This raises several experimental questions: To what extent is activity in the sensorimotor network effector-dependent and effector-independent? How important is the sensorimotor cortex when predicting the motor effector? Is there redundancy in the distributed somatotopically organized network such that removing one region has little impact on classification accuracy? To answer these questions, we developed a novel experimental approach. fMRI data were collected while human subjects performed a precisely controlled force generation task separately with their hand, foot, and mouth. We used a simple linear iterative clustering (SLIC) algorithm to segment whole-brain beta coefficient maps to build an adaptive brain parcellation and then classified effectors using extreme gradient boosting (XGBoost) based on parcellations at various spatial resolutions. This allowed us to understand how data-driven adaptive brain parcellation granularity altered classification accuracy. Results revealed effector-dependent activity in regions of the post-central gyrus, precentral gyrus, and paracentral lobule. SMA, regions of the inferior and superior parietal lobule, and cerebellum each contained effector-dependent and effector-independent representations. Machine learning analyses showed that increasing the spatial resolution of the data-driven model increased classification accuracy, which reached 94% with over 1,755 supervoxels. Our SLIC-based supervoxel parcellation outperformed classification analyses using established brain templates and random simulations. Occlusion experiments further demonstrated redundancy across the sensorimotor network when classifying effectors. Our observations extend our understanding of effector-dependent and effector-independent organization within the human brain and provide new insight into the functional neuroanatomy required to predict the motor effector used in a motor control task.</p>
                                                        </p>
                                                    </div>
                                                </div>
                                            
                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fnagi.2021.758298/full" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/frontiers-in-aging-neuroscience.png" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Baseline neuroimaging predicts decline to dementia from amnestic mild cognitive impairment</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Joseph M Gullett, Alejandro Albizu, <b>Ruogu Fang</b>, David A Loewenstein, Ranjan Duara, Monica Rosselli, Melissa J Armstrong, Tatjana Rundek, Hanna K Hausman, Steven T Dekosky, Adam J Woods, Ronald A Cohen</div>
                                                            <div class="pubcite">Frontiers in Aging Neuroscience</div>
                                                            <div class="pubdate">Publication Date: November, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Background and Objectives: Prediction of decline to dementia using objective biomarkers in high-risk patients with amnestic mild cognitive impairment (aMCI) has immense utility. Our objective was to use multimodal MRI to 1) determine whether accurate and precise prediction of dementia conversion could be achieved using baseline data alone, and 2) generate a map of the brain regions implicated in longitudinal decline to dementia.</p>
                                                        
                                                        <p>Methods: Participants meeting criteria for aMCI at baseline (N=55) were classified at follow-up as remaining stable/improved in their diagnosis (N=41) or declined to dementia (N=14). Baseline T1 structural MRI and resting-state fMRI (rsfMRI) were combined and a semi-supervised support vector machine (SVM) which separated stable participants from those who decline at follow-up with maximal margin. Cross-validated model performance metrics and MRI feature weights were calculated to include the strength of each brain voxel in its ability to distinguish the two groups.</p>
                                                        
                                                        <p>Results: Total model accuracy for predicting diagnostic change at follow-up was 92.7% using baseline T1 imaging alone, 83.5% using rsfMRI alone, and 94.5% when combining T1 and rsfMRI modalities. Feature weights that survived the p<0.01 threshold for separation of the two groups revealed the strongest margin in the combined structural and functional regions underlying the medial temporal lobes in the limbic system.</p>
                                                        
                                                        <p>Discussion: An MRI-driven SVM model demonstrates accurate and precise prediction of later dementia conversion in aMCI patients. The multi-modal regions driving this prediction were the strongest in the medial temporal regions of the limbic system, consistent with literature on the progression of Alzheimer’s disease.</p>
                                                        </p>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221015642" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neurocomputing.png" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">CADA: Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Peng Liu, Charlie Tran, Bin Kong, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Neurocomputing</div>
                                                            <div class="pubdate">Publication Date: October 29, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Recently, deep neural networks have demonstrated comparable and even better performance than board-certified ophthalmologists in well-annotated datasets. However, the diversity of retinal imaging devices poses a significant challenge: domain shift, which leads to performance degradation when applying the deep learning models trained on one domain to new testing domains. In this paper, we propose a multi-scale input along with multiple domain adaptors applied hierarchically in both feature and output spaces. The proposed training strategy and novel unsupervised domain adaptation framework, called Collaborative Adversarial Domain Adaptation (CADA), can effectively overcome the challenge. Multi-scale inputs can reduce the information loss due to the pooling layers used in the network for feature extraction, while our proposed CADA is an interactive paradigm that presents an exquisite collaborative adaptation through both adversarial learning and ensembling weights at different network layers. In particular, to produce a better prediction for the unlabeled target domain data, we simultaneously achieve domain invariance and model generalizability via adversarial learning at multi-scale outputs from different levels of network layers and maintaining an exponential moving average (EMA) of the historical weights during training. Without annotating any sample from the target domain, multiple adversarial losses in encoder and decoder layers guide the extraction of domain-invariant features to confuse the domain classifier. Meanwhile, the ensembling of weights via EMA reduces the uncertainty of adapting multiple discriminator learning. Comprehensive experimental results demonstrate that our CADA model incorporating multi-scale input training can overcome performance degradation and outperform state-of-the-art domain adaptation methods in segmenting retinal optic disc and cup from fundus images stemming from the REFUGE, Drishti-GS, and Rim-One-r3 datasets. The code will be available at https://github.com/cswin/CADA
                                                        </p>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://aip.scitation.org/doi/10.1063/5.0066049" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Physics_of_Fluids.jpeg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Rotational and Reflectional Equivariant Convolutional Neural Network for data-limited applications: Multiphase Flow demonstration</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Bhargav Siddani, S. Balachandar, <b>Ruogu Fang</b></div>
                                                            <div class="pubcite">Physics of Fluids</div>
                                                            <div class="pubdate">Publication Date: October 22, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>This article deals with approximating steady-state particle-resolved fluid flow around a fixed particle of interest under the influence of randomly distributed stationary particles in a dispersed multiphase setup using convolutional neural network (CNN). The considered problem involves rotational symmetry about the mean velocity (streamwise) direction. Thus, this work enforces this symmetry using SE(3)-equivariant, special Euclidean group of dimension 3, CNN architecture, which is translation and three-dimensional rotation equivariant. This study mainly explores the generalization capabilities and benefits of a SE(3)-equivariant network. Accurate synthetic flow fields for Reynolds number and particle volume fraction combinations spanning over a range of [86.22, 172.96] and [0.11, 0.45], respectively, are produced with careful application of symmetry-aware data-driven approach.
                                                        </p>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/article/10.1007/s00162-021-00593-9" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/TCFD.jpeg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine Learning for Physics-Informed Generation of Dispersed Multiphase Flow Using Generative Adversarial Networks</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Bhargav Siddani, S. Balachandar., William C. Moore, Yunchao Yang, <b>Ruogu Fang</b></div>
                                                            <div class="pubcite">Theoretical and Computational Fluid Dynamics</div>
                                                            <div class="pubdate">Publication Date: October 28, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Fluid flow around a random distribution of stationary spherical particles is a problem of substantial importance in the study of dispersed multiphase flows. In this paper we present a machine learning methodology using Generative Adversarial Network framework and Convolutional Neural Network architecture to recreate particle-resolved fluid flow around a random distribution of monodispersed particles. The model was applied to various Reynolds number and par- ticle volume fraction combinations spanning over a range of [2.69, 172.96] and [0.11, 0.45] respectively. Test performance of the model for the studied cases is very promising. <br>
                                                        <b>Keywords</b>: Pseudo-turbulence, Multiphase Flow prediction, Generative Adversarial Network (GAN), Convolutional Neural Network (CNN)</p>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.main2021.org/home" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MAIN2021.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A deep neural network for emotion perception</h4>
                                                            <h5><strong> <a href="https://www.youtube.com/watch?t=530&v=VAU0MfQtLOk&feature=youtu.be" target="_blank">Best Abstract Award (Undegraduate and Graduate Level)</a></strong></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, Ke Bo, Lihan Cui, Yujun Chen, Charlie Tran, Mingzhou Ding†, <u><b>Ruogu Fang</b></u>†, <br>
                                                                († co-corresponding authors)</div>
                                                            <div class="pubcite">Montreal AI & Neuroscience Annual Meeting <br>
                                                                November 29-30, Montreal, Canada</div>
                                                            <div class="pubdate">Publication Date: November 29-30, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>                                               
                                        
                                        
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.sfn.org/meetings/neuroscience-2021" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SfN.jpeg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Emergence of emotion selectivity in deep neural networks trained to recognize visual objects</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, Ke Bo, Lihan Cui, Yujun Chen, Charlie Tran, Mingzhou Ding†, <u><b>Ruogu Fang</b></u>†,  <br>
                                                                († co-corresponding authors)</div>
                                                            <div class="pubcite">Society of Neuroscience (SfN) Annual Meeting <br>
                                                                Virtual: November 8-11, In-Person: November 13-16, Chicago, IL</div>
                                                            <div class="pubdate">Publication Date: November 8-16, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.sfn.org/meetings/neuroscience-2021" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SfN.jpeg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A deep neural network model for emotion perception</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, Ke Bo, Lihan Cui, Yujun Chen, Charlie Tran, <u><b>Ruogu Fang</b></u>†, Mingzhou Ding† <br>
                                                                († co-corresponding authors)</div>
                                                            <div class="pubcite">Society of Neuroscience (SfN) Annual Meeting <br>
                                                                Virtual: November 8-11, In-Person: November 13-16, Chicago, IL</div>
                                                            <div class="pubdate">Publication Date: November 8-16, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>                          
                                                
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.sfn.org/meetings/neuroscience-2021" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SfN.jpeg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine-Learning Defined Precision tDCS for Improving Cognitive Function </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Alejandro Albizu, <b>Ruogu Fang</b>, Aprinda Indahlastari, Andrew O’Shea, Skylar E. Stolte, Kyle B. See, Emanuel M. Boutzoukas, Jessica N. Kraft, Nicole R. Nissim, and Adam J. Woods</div>
                                                            <div class="pubcite">Society of Neuroscience (SfN) Annual Meeting <br>
                                                                Virtual: November 8-11, In-Person: November 13-16, Chicago, IL</div>
                                                            <div class="pubdate">Publication Date: November 8-16, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                                
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://ieeexplore.ieee.org/abstract/document/9565706/authors#authors" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="https://ohnlp.github.io/HealthNLP2021/Health%20NLP%202021_files/vbc.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Identify Diabetic Retinopathy-related Clinical Concepts Using Transformer-based Natural Language Processing Methods</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Zehao Yu, Xi Yang, Gianna L Sweeting, Yinghan Ma, Skylar E Stolte, <b>Ruogu Fang</b>, Yonghui Wu</div>
                                                            <div class="pubcite">The Fourth International Workshop on Health Natural Language Processing, Victoria, Canada (virtual)</div>
                                                            <div class="pubdate">Publication Date: August 9, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                <!--
                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.bmes.org/annualmeeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">MAGIC: Multitask Automated Generation of Inter-modal CT Perfusion Maps via Generative Adversarial Network</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Garrett Fullerton, Simon Kato, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Orlando, FL.</div>
                                                            <div class="pubdate">Publication Date: October 6-9, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
-->

                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.bmes.org/annualmeeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Predicting Treatment Outcome in Spinal Cord Stimulation with EEG</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Kyle See, Rachel Judy, Stephen Coombes, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Orlando, FL.</div>
                                                            <div class="pubdate">Publication Date: October 6-9, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.bmes.org/annualmeeting" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Ensemble Machine Learning for Alzheimer’s disease Classification from Retinal Vasculature</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Hely Lin, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Orlando, FL.</div>
                                                            <div class="pubdate">Publication Date: October 6-9, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/66361-tl1-team-approach-to-predicting-response-to-spinal-cord-stimulation-for-chronic-low-back-pain/DDE70E18EAF3E88623DFC9F5645CC278" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/journal_of%20clinical%20and%20translational%20science.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">TL1 Team Approach to Predicting Response to Spinal Cord Stimulation for Chronic Low Back Pain</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Kyle See, Rachel Ho, Steven Coombes, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Journal of Clinical and Translational Sciences</div>
                                                            <div class="pubdate">Publication Date: March 30, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>


                                                <div class="item mix Journal" data-year="2021">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--<a href="" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>-->

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.nature.com/articles/s41598-020-80312-2" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SciReports.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Modular machine learning for Alzheimer's disease classification from retinal vasculature</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Jianqiao Tian, Glenn Smith, Han Guo, Boya Liu, Zehua Pan, Zijie Wang, Shuangyu Xiong, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Nature Scientific Reports</div>
                                                            <div class="pubdate">Publication Date: January 8, 2021</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Alzheimer's disease is the leading cause of dementia. The long progression period in Alzheimer's disease provides a possibility for patients to get early treatment by having routine screenings. However, current clinical diagnostic imaging tools do not meet the specific requirements for screening procedures due to high cost and limited availability. In this work, we took the initiative to evaluate the retina, especially the retinal vasculature, as an alternative for conducting screenings for dementia patients caused by Alzheimer's disease. Highly modular machine learning techniques were employed throughout the whole pipeline. Utilizing data from the UK Biobank, the pipeline achieved an average classification accuracy of 82.44%. Besides the high classification accuracy, we also added a saliency analysis to strengthen this pipeline's interpretability. The saliency analysis indicated that within retinal images, small vessels carry more information for diagnosing Alzheimer's diseases, which aligns with related studies.</p>
                                                    </div>
                                                </div>

                                                <!--2020-->
                                                <div class="item mix Patents" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">CFEA: Collaborative Feature Ensembling Adaptation For Domain Adaptation In Unsupervised Optic Disc and Cup Segmentation</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor">Peng Liu and <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Ref No.: T18094US001 (222107-8940) U.S. Provisional Patent Application Serial No. 63/001,771</div>
                                                            <div class="pubdate">Filed on March 30, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Prediction of Functional Motor Tasks with Dynamic Supervoxel Parcellations</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Kyle See, Steven Coombes</div>
                                                            <div class="pubcite">Provisional patent pending.</div>
                                                            <div class="pubdate"></div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">System and Methods for Predicting Perfusion Images from Non-Contrast Scans</h4>
                                                            <span class="label label-info">Patents</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Garrett Fullerton, Simon Kato.</div>
                                                            <div class="pubcite">Provisional patent pending.</div>
                                                            <div class="pubdate"></div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.brainstimjrnl.com/article/S1935-861X(20)30268-0/pdf" class="tooltips" title="PDF" target="_blank">
                                                            <i class="fa fa-file-pdf-o"></i>

                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1935861X20302680" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/brainstim.gif" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine learning and individual variability in electric field characteristics predict tDCS treatment response.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Alejandro Albizu, <strong>Ruogu Fang</strong>, Aprinda Indahlastari, Andrew OShea, Skylar E. Stolte, Kyle B. See, Emanuel M. Boutzoukas, Jessica N. Kraft, Nicole R. Nissim and Adam J. Woods</div>
                                                            <div class="pubcite">Brain Stimulation</div>
                                                            <div class="pubdate">Publication Year: November/December, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <h5>Background</h5>
                                                        <p>Transcranial direct current stimulation (tDCS) is widely investigated as a therapeutic tool to enhance cognitive function in older adults with and without neurodegenerative disease. Prior research demonstrates that electric current delivery to the brain can vary significantly across individuals. Quantification of this variability could enable person-specific optimization of tDCS outcomes. This pilot study used machine learning and MRI-derived electric field models to predict working memory improvements as a proof of concept for precision cognitive intervention.</p>

                                                        <h5>Methods</h5>
                                                        <p>Fourteen healthy older adults received 20 minutes of 2 mA tDCS stimulation (F3/F4) during a two-week cognitive training intervention. Participants performed an N-back working memory task pre-/post-intervention. MRI-derived current models were passed through a linear Support Vector Machine (SVM) learning algorithm to characterize crucial tDCS current components (intensity and direction) that induced working memory improvements in tDCS responders versus non-responders.</p>

                                                        <h5>Main results</h5>
                                                        <p>SVM models of tDCS current components had 86% overall accuracy in classifying treatment responders vs. non-responders, with current intensity producing the best overall model differentiating changes in working memory performance. Median current intensity and direction in brain regions near the electrodes were positively related to intervention responses.</p>

                                                        <h5>Conclusions</h5>
                                                        <p>This study provides the first evidence that pattern recognition analyses of MRI-derived tDCS current models can provide individual prognostic classification of tDCS treatment response with 86% accuracy. Individual differences in current intensity and direction play important roles in determining treatment response to tDCS. These findings provide important insights into mechanisms of tDCS response as well as proof of concept for future precision dosing models of tDCS intervention.</p>

                                                        <p><img width="600" src="https://ars.els-cdn.com/content/image/1-s2.0-S1935861X20302680-fx1_lrg.jpg">
                                                    </div>
                                                </div>


                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <!--Update Link after meeting-->
                                                            <a href="https://press.rsna.org/timssnet/media/pressreleases/14_pr_target.cfm?ID=2229" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/RSNA.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Machine Learning for Parkinsons Disease Diagnosis Using Fundus Eye Images</h4>
                                                            <h5><strong>Featured by <a href="https://www.forbes.com/sites/jackierocheleau/2020/11/25/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/" target="_blank">Forbes</a> and 30+ Media</strong></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Maximillian Diaz, Jianqiao Tian, Adolfo Ramirez-Zamora, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Annual Meeting of Radiology Society of North America</div>
                                                            <div class="pubdate">Publication Year: December, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.ahajournals.org/doi/abs/10.1161/circ.142.suppl_3.15036?af=R" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/AHA.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Artificial Intelligence For Characterizing Heart Failure In Cardiac Magnetic Resonance Images</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, Yonghui Wu, William R Hogan, Yan Gong, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">American Heart Association Scientific Session</div>
                                                            <div class="pubdate">Publication Year: November 13-17, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>


                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-37-8-1249" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/osa-josaa.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Physiological wound assessment from coregistered and segmented tissue hemoglobin maps</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">E. A. Robledo, R. Schutzman, <strong>R. Fang</strong>, C. Fernandez, R. Kwasinski, K. Leiva, F. Perez-Clavijo, and A. Godavarty</div>
                                                            <div class="pubcite">Journal of the Optical Society of America A</div>
                                                            <div class="pubdate">Publication Year: July, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>A handheld near-infrared optical scanner (NIROS) was recently developed to map for effective changes in oxy- and deoxyhemoglobin concentration in diabetic foot ulcers (DFUs) across weeks of treatment. Herein, a coregistration and image segmentation approach was implemented to overlay hemoglobin maps onto the white light images of ulcers. Validation studies demonstrated over 97% accuracy in coregistration. Coregistration was further applied to a healing DFU across weeks of healing. The potential to predict changes in wound healing was observed when comparing the coregistered and segmented hemoglobin concentration area maps to the visual area of the wound.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/4085-tl1-team-approach-to-predicting-shortterm-and-longterm-effects-of-spinal-cord-stimulation/9040EFDA2EB3ABE295E5B662DC0F4C33#article" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/journal_of%20clinical%20and%20translational%20science.jpg" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">TL1 Team Approach to Predicting Short-term and Long-term Effects of Spinal Cord Stimulation</h4>
                                                            <span class="label label-primary">Journal</span>
                                                            <div class="pubauthor">Kyle See, Rachel Louise Mahealani Judy, Stephen Coombes, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Journal of Clinical and Translational Science</div>
                                                            <div class="pubdate">Publication Year: July, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>OBJECTIVES/GOALS: Spinal cord stimulation (SCS) is an intervention for patients with chronic back pain. Technological advances have led to renewed optimism in the field, but mechanisms of action in the brain remain poorly understood. We hypothesize that SCS outcomes will be associated with changes in neural oscillations.

                                                            METHODS/STUDY POPULATION: The goal of our team project is to test patients who receive SCS at 3 times points: baseline, at day 7 during the trial period, and day 180 after a permanent system has been implanted. At each time point participants will complete 10 minutes of eyes closed, resting electroencephalography (EEG). EEG will be collected with the ActiveTwo system, a 128-electrode cap, and a 256 channel AD box from BioSemi. Traditional machine learning methods such as support vector machine and more complex models including deep learning will be used to generate interpretable features within resting EEG signals.

                                                            RESULTS/ANTICIPATED RESULTS: Through machine learning, we anticipate that SCS will have a significant effect on resting alpha and beta power in sensorimotor cortex. DISCUSSION/SIGNIFICANCE OF

                                                            IMPACT: This collaborative project will further the application of machine learning in cognitive neuroscience and allow us to better understand how therapies for chronic pain alter resting brain activity.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Dissertation" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/uf.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Learning For Multimodal CT Image Quality Enhancement and Radiation Exposure Optimization</h4>
                                                            <span class="label label-success">PhD Dissertation</span>
                                                            <div class="pubauthor"><strong>Yao Xiao</strong></div>
                                                            <div class="pubcite">Biomedical Engineering, University of Florida</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1361841520301067" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A Survey on Medical Image Analysis in Diabetic Retinopathy</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Skylar Stolte, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Medical Image Analysis, In Press</div>
                                                            <div class="pubdate">Publication Year: May 30, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                            <p>Diabetic Retinopathy (DR) represents a highly-prevalent complication of diabetes in which individuals suffer from damage to the blood vessels in the retina. The disease manifests itself through lesion presence, starting with microaneurysms, at the nonproliferative stage before being characterized by neovascularization in the proliferative stage. Retinal specialists strive to detect DR early so that the disease can be treated before substantial, irreversible vision loss occurs. The level of DR severity indicates the extent of treatment necessary - vision loss may be preventable by effective diabetes management in mild (early) stages, rather than subjecting the patient to invasive laser surgery. Using artificial intelligence (AI), highly accurate and efficient systems can be developed to help assist medical professionals in screening and diagnosing DR earlier and without the full resources that are available in specialty clinics. In particular, deep learning facilitates diagnosis earlier and with higher sensitivity and specificity. Such systems make decisions based on minimally handcrafted features and pave the way for personalized therapies. Thus, this survey provides a comprehensive description of the current technology used in each step of DR diagnosis. First, it begins with an introduction to the disease and the current technologies and resources available in this space. It proceeds to discuss the frameworks that different teams have used to detect and classify DR. Ultimately, we conclude that deep learning systems offer revolutionary potential to DR identification and prevention of vision loss.
                                                    </div>
                                                </div>


                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://neuromodec.com/nyc-neuromodulation-online-2020/index.html" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neuromodec.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Determinants of Treatment Response to Transcranial Direct Current Stimulation</h4>
                                                            <h5><strong>Outstanding Presentation by Early Career Scientist Award</strong></h5>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Albizu A, <strong>Fang R</strong>, Indahlastari A, Nissim NR, OShea A, Woods AJ</div>
                                                            <div class="pubcite">5th Annual NYC Neuromodulation Conference</div>
                                                            <div class="pubdate">Publication Year: April 20-22, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.the-ins.org/meetings/denver2020/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" height="125" src="img/pubs/INS.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Building Personalized Medicine Models for Therapeutic Applications of Transcranial Electrical Stimulation</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Albizu A, Indahlastari A, Nissim NR, OShea A, <strong>Ruogu Fang</strong>, Woods AJ</div>
                                                            <div class="pubcite">48th Annual Meeting of the International Neuropsychological Society</div>
                                                            <div class="pubdate">Publication Year: February 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520300219" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Domain-Invariant Interpretable Fundus Image Quality Assessment</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Yaxin Shen, Bin Sheng, <strong>Ruogu Fang</strong>, Huating Li, Ling Dai, Skylar Stolte*, Jing Qin, Weiping Jia, Dinggang Shen</div>
                                                            <div class="pubcite">Medical Image Analysis, volume 61</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Objective and quantitative assessment of fundus image quality is essential for the diagnosis of retinal diseases. The major factors in fundus image quality assessment are image artifact, clarity, and field definition. Unfortunately, most of existing quality assessment methods focus on the quality of overall image, without interpretable quality feedback for real-time adjustment. Furthermore, these models are often sensitive to the specific imaging devices, and cannot generalize well under different imaging conditions. This paper presents a new multi-task domain adaptation framework to automatically assess fundus image quality. The proposed framework provides interpretable quality assessment with both quantitative scores and quality visualization for potential real-time image recapture with proper adjustment. In particular, the present approach can detect optic disc and fovea structures as landmarks, to assist the assessment through coarse-to-fine feature encoding. The framework also exploit semi-tied adversarial discriminative domain adaptation to make the model generalizable across different data sources. Experimental results demonstrated that the proposed algorithm outperforms different state-of-the-art approaches and achieves an area under the ROC curve of 0.9455 for the overall quality classification.
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://siim.org/page/siim2020" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SIIM.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multi-Series CT Image Super-Resolution by using Transfer Generative Adversarial Network</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Manuel M. Arreola, Izabella Barreto, Wesley E. Bolch, W. Christopher Fox, Keith Peters, Dhanashree A. Rajderkar, John H. Rees, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Society for Imaing Informatics in Medicine Annual Meeting in Austin, TX</div>
                                                            <div class="pubdate">Publication Year: June 24-26, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Transfer-GAN: Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Networks</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Keith R. Peters, W. Christopher Fox, John H. Rees, Dhanashree A. Rajderkar, Manuel M. Arreola, Izabella Barreto, Wesley E. Bolch, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">IEEE International Symposium on Biomedical Imaging in Iowa City, IA</div>
                                                            <div class="pubdate">Publication Year: April 3-7, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://spie.org/conferences-and-exhibitions/past-conferences-and-exhibitions/medical-imaging-2020" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SPIE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Transfer Generative Adversarial Network for Multimodal CT Image Super-Resolution</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, <strong>Ruogu Fang</strong></div>
                                                            <div class="pubcite">SPIE Medical Imaging in Houston, TX</div>
                                                            <div class="pubdate">Publication Year: February 15-20, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="http://snamc2020.jpn.org/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img height="50" src="img/pubs/SNAMC2020.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Monte Carlo Dosimetry For CT Brain Perfusion Studies Utilizing Volumetric Acquisitions</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Justin L Brown, Daniel El Basha∗, Nathalie Correa, Yao Xiao, Izabella Barreto, <strong>Ruogu Fang</strong>, Chan Kim, Wesley E. Bolch </div>
                                                            <div class="pubcite">Joint International Conference on Supercomputing in Nuclear Applications + Monte Carlo</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" height="170" src="img/pubs/ASCPT.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">ZMAT4 and DOCK9 Variants Associated with Heart Failure in Breast Cancer Patients in the UK Biobank data</h4><font color="red"><h5><strong>Presidential Trainee Award, 2020 David J. Goldstein Trainee Award</strong></h5></font>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Marwa Tantawy, Sonal Singh, Guang Yang, Matt Gitzendanner, Yiqing Chen, Yonghui Wu, <strong>Ruogu Fang</strong>, William Hogan, Yan Gong</div>
                                                            <div class="pubcite">American Society for Clinical Pharmacology and Therapeutics Annual Meeting in Houston, TX</div>
                                                            <div class="pubdate">Publication Year: March 18-21, 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S0167610519306269" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/JWEIA.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Low-Rise Gable Roof Buildings Pressure Prediction using Deep Neural Networks</h4>
                                                            <span class="label label-warning">Journal </span>
                                                            <div class="pubauthor">Jianqiao Tian, Kurtis Gurley, Maximillian Diaz, Pedro L. Fernández Cabán, Forrest J. Masters, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Journal of Wind Engineering & Industrial Aerodynamics</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>This paper presents a deep neural network (DNN) based approach for predicting mean and peak wind pressure coefficients on the surface of a scale model low-rise, gable roof residential building. Pressure data were collected on the model at multiple prescribed wind directions and terrain roughnesses. The resultant pressure coefficients quantified from a subset of these directions and terrains were used to train an DNN to predict coefficients for directions and terrains excluded from the training. The approach is able to leverage a variety of input conditions to predict pressure coefficients with high accuracy, while the prior work has limited flexibility with the number of input variables and yielded lower prediction accuracy. A two-step nested DNN procedure is introduced to improve the prediction of peak coefficients. The optimal correlation coefficients of return predictions were 0.9993 and 0.9964, for mean and peak coefficient prediction, respectively. The concept of super resolution based on global prediction was also discussed. With a sufficiently large database, the proposed DNN-based approach can augment existing experimental methods to improve the yield of knowledge while reducing the number of tests required to gain that knowledge.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1361841519301033?via%3Dihub" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">IDRiD: Diabetic Retinopathy – Segmentation and Grading Challenge</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Prasanna Porwal, Samiksha Pachade, Manesh Kokare, Girish Deshmukh, Jaemin Son, Woong Bae, Lihong Liu, Jianzong Wang, Xinhui Liu, Liangxin Gao, TianBo Wu, Jing Xiao, Fengyan Wang, Baocai Yin, Yunzhi Wang, Gopichandh Danala, Linsheng He, Yoon Ho Choi, Yeong Chan Lee, Sang-Hyuk Jung, Zhongyu Li, Xiaodan Sui, Junyan Wu, Xiaolong Li, Ting Zhou, Janos Toth, Agnes Baran, Avinash Kori, Sai Saketh Chennamsetty, Mohammed Safwan, Varghese Alex, Xingzheng Lyu,r, Li Cheng,D, Qinhao Chu, Pengcheng Li, Xin Ji, Sanyuan Zhang, Yaxin Shen, Ling Dai$, Oindrila Saha, Rachana Sathish, Tânia Melo, Teresa Araújo, Balazs Harangi, Bin Sheng, <strong>Ruogu Fang</strong>, Debdoot Sheet, Andras Hajdu, Yuanjie Zheng, Ana Maria Mendonça, Shaoting Zhang, Aurélio Campilho, Bin Zheng, Dinggang Shen, Luca Giancardo, Gwenolé Quellec, Fabrice Mériaudeau</div>
                                                            <div class="pubcite">Medical Image Analysis, volume 59</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on “Diabetic Retinopathy – Segmentation and Grading” was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i></a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1361841519301100" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">REFUGE Challenge: A Unified Framework for Evaluating Automated Methods for Glaucoma Assessment from Fundus Photographs</h4>
                                                            <span class="label label-warning">Journal </span>
                                                            <div class="pubauthor">Jose Ignacio Orlando, Huazhu Fu, Joa ̃o Barbossa Breda, Karel van Keer, Deepti R. Bathula, Andre ́s Diaz-Pinto, <strong>Ruogu Fang</strong>, Pheng-Ann Heng, Jeyoung Kim, JoonHo Lee, Joonseok Lee, Xiaoxiao Li, Peng Liu, Shuai Lu, Balamurali Murugesan, Valery Naranjo, Sai Samarth R. Phaye, Sharath M. Shankaranarayana, Apoorva Sikka, Jaemin Son, Anton van den Hengel, Shujun Wang, Junyan Wu, Zifeng Wu, Guanghui Xu, Yongli Xu, Pengshuai Yin, Fei Li, Xiulan Zhang, Yanwu Xu, Hrvoje Bogunovic ́</div>
                                                            <div class="pubcite">Medical Image Analysis, volume 59</div>
                                                            <div class="pubdate">Publication Year: 2020</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Glaucoma is one of the leading causes of irreversible but preventable blindness in working age populations. Color fundus photography (CFP) is the most cost-effective imaging modality to screen for retinal disorders. However, its application to glaucoma has been limited to the computation of a few related biomarkers such as the vertical cup-to-disc ratio. Deep learning approaches, although widely applied for medical image analysis, have not been extensively used for glaucoma assessment due to the limited size of the available data sets. Furthermore, the lack of a standardize benchmark strategy makes difficult to compare existing methods in a uniform way. In order to overcome these issues we set up the Retinal Fundus Glaucoma Challenge, REFUGE (https://refuge.grand-challenge.org), held in conjunction with MICCAI 2018. The challenge consisted of two primary tasks, namely optic disc/cup segmentation and glaucoma classification. As part of REFUGE, we have publicly released a data set of 1200 fundus images with ground truth segmentations and clinical glaucoma labels, currently the largest existing one. We have also built an evaluation framework to ease and ensure fairness in the comparison of different models, encouraging the development of novel techniques in the field. 12 teams qualified and participated in the online challenge. This paper summarizes their methods and analyzes their corresponding results. In particular, we observed that two of the top-ranked teams outperformed two human experts in the glaucoma classification task. Furthermore, the segmentation results were in general consistent with the ground truth annotations, with complementary outcomes that can be further exploited by ensembling the results.
                                                    </div>
                                                </div>




                                                <!--2019-->
                                                <div class="item mix Book Chapters" data-year="2019">
                                                    <div class="pubmain">
                                                       <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i></a>
                                                            <a href="https://www.springerprofessional.de/en/deep-spatial-temporal-convolutional-neural-networks-for-medical-/17189984" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Springer.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Spatial-Temporal Convolutional Neural Networks for Medical Image Restoration Deep Learning and Convolutional Neural Networks for Medical Image Computing</h4>
                                                            <span class="label label-success">Book Chapter</span>
                                                            <div class="pubauthor">Yao Xiao, Skylar Stolte, Peng Liu, Yun Liang, Pina Sanelli, Ajay Gupta, Jana Ivanidze, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Deep Learning and Convolutional Neural Networks for Medical Image Computing, Springer Publisher</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                    Computed tomography perfusion (CTP) facilitates low-cost diagnosis and treatment of acute stroke. Cine scanning allows users to visualize brain anatomy and blood flow in virtually live time. However, effective visualization exposes patients to radiocontrast pharmaceuticals and extended scan times. Higher radiation dosage exposes patients to potential risks including hair loss, cataract formation, and cancer. To alleviate these risks, radiation dosage can be reduced along with tube current and/or X-ray radiation exposure time. However, resulting images may lack sufficient information or be affected by noise and/or artifacts. In this chapter, we propose a deep spatial-temporal convolutional neural network to preserve CTP image quality at reduced tube current, low spatial resolution, and shorter exposure time. This network structure extracts multi-directional features from low-dose and low-resolution patches at different cross sections of the spatial-temporal data and reconstructs high-quality CT volumes. We assess the performance of the network concerning image restoration at different tube currents and multiple resolution scales. The results indicate the ability of our network in restoring high-quality scans from data captured at as low as 21% of the standard radiation dose. The proposed network achieves an average improvement of 7% in perfusion maps compared to the state-of-the-art method.
                                                    </div>
                                                </div>

                                                <div class="item mix Book Chapters" data-year="2019">
                                                    <div class="pubmain">
                                                         <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i></a>
                                                         <a href="https://www.taylorfrancis.com/chapters/big-data-computational-health-informatics-ruogu-fang-yao-xiao-jianqiao-tian-samira-pouyanfar-yimin-yang-shu-ching-chen-iyengar/e/10.1201/b22410-5" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                        </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/CRC.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Big Data in Computational Health Informatics</h4>
                                                            <span class="label label-success">Book Chapter</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Samira Pouyanfar, Yimin Yang, Yao Xiao, Jianqiao Tian, Shu-Ching Chen, and S.S. Iyengar </div>
                                                            <div class="pubcite">Big Data in Multimodal Medical Imaging, CRC Publisher</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                    The recent explosive surge of digital health data has made a significant impact on the proliferation of data science research in healthcare. However, traditional approaches have reached limited achievements in facing the big health data due to their weak scalability and poor applicability in tackling massive amount of healthcare data. By the structured analysis of the historical and modern methods, this article presents a comprehensive overview of the existing challenges, techniques, and future directions of computational health informatics in the big data era. This chapter outlines the challenges in the generic big health data as four high Vs, which are high volume, velocity, variety, and veracity. Moreover, it introduces a systematic data processing pipeline that covers data capturing, storing, sharing, analyzing, searching, and decision support. In this book chapter, we compare and categorize numerous machine learning techniques and algorithms for computational health informatics, based on which, we identify and analyze the essential prospects lying ahead in this big data age.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2019">
                                                    <div class="pubmain">
                                                        <!--
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fneur.2019.00647/full" class="tooltips" title="External link" target="_blank"><i class="fa fa-external-link"></i></a>
                                                        </div>
                                                        -->
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Lancet.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Development and Validation of the Automated Imaging Diﬀerentiation in Parkinsonism (AID-P): A Multi-Site Machine Learning Study </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Derek B. Archer, ..., <strong>Ruogu Fang</strong>, ..., David E. Vaillancourt</div>
                                                            <div class="pubcite">The Lancet Digital Health</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <!--
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Computed Tomography Perfusion (CTP) imaging is a cost-effective and fast approach to provide diagnostic images for acute stroke treatment. Its cine scanning mode allows the visualization of anatomic brain structures and blood flow; however, it requires contrast agent injection and continuous CT scanning over an extended time. In fact, the accumulative radiation dose to patients will increase health risks such as skin irritation, hair loss, cataract formation, and even cancer. Solutions for reducing radiation exposure include reducing the tube current and/or shortening the X-ray radiation exposure time. However, images scanned at lower tube currents are usually accompanied by higher levels of noise and artifacts. On the other hand, shorter X-ray radiation exposure time with longer scanning intervals will lead to image information that is insufficient to capture the blood flow dynamics between frames. Thus, it is critical for us to seek a solution that can preserve the image quality when the tube current and the temporal frequency are both low. We propose STIR-Net in this paper, an end-to-end spatial-temporal convolutional neural network structure, which exploits multi-directional automatic feature extraction and image reconstruction schema to recover high-quality CT slices effectively. With the inputs of low-dose and low-resolution patches at different cross-sections of the spatio-temporal data, STIR-Net blends the features from both spatial and temporal domains to reconstruct high-quality CT volumes. In this study, we finalize extensive experiments to appraise the image restoration performance at different levels of tube current and spatial and temporal resolution scales.The results demonstrate the capability of our STIR-Net to restore high-quality scans at as low as 11% of absorbed radiation dose of the current imaging protocol, yielding an average of 10% improvement for perfusion maps compared to the patch-based log likelihood method.
                                                    </div>
                                                    -->
                                                </div>

                                                <div class="item mix Journal" data-year="2019">
                                                    <div class="pubmain">
                                                        <!--
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fneur.2019.00647/full" class="tooltips" title="External link" target="_blank"><i class="fa fa-external-link"></i></a>
                                                        </div>
                                                        -->
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/JAMIA.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">  Identifying Relations of Medications with Adverse Drug Events Using Recurrent Convolutional Neural Networks and Gradient Boosting </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Xi Yang, Jiang Bian, <strong>Ruogu Fang</strong>, Ragnhildur I. Bjarnadottir, William R. Hogan, and Yonghui Wu</div>
                                                            <div class="pubcite">Journal of the American Medical Informatics Association</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <!--
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Computed Tomography Perfusion (CTP) imaging is a cost-effective and fast approach to provide diagnostic images for acute stroke treatment. Its cine scanning mode allows the visualization of anatomic brain structures and blood flow; however, it requires contrast agent injection and continuous CT scanning over an extended time. In fact, the accumulative radiation dose to patients will increase health risks such as skin irritation, hair loss, cataract formation, and even cancer. Solutions for reducing radiation exposure include reducing the tube current and/or shortening the X-ray radiation exposure time. However, images scanned at lower tube currents are usually accompanied by higher levels of noise and artifacts. On the other hand, shorter X-ray radiation exposure time with longer scanning intervals will lead to image information that is insufficient to capture the blood flow dynamics between frames. Thus, it is critical for us to seek a solution that can preserve the image quality when the tube current and the temporal frequency are both low. We propose STIR-Net in this paper, an end-to-end spatial-temporal convolutional neural network structure, which exploits multi-directional automatic feature extraction and image reconstruction schema to recover high-quality CT slices effectively. With the inputs of low-dose and low-resolution patches at different cross-sections of the spatio-temporal data, STIR-Net blends the features from both spatial and temporal domains to reconstruct high-quality CT volumes. In this study, we finalize extensive experiments to appraise the image restoration performance at different levels of tube current and spatial and temporal resolution scales.The results demonstrate the capability of our STIR-Net to restore high-quality scans at as low as 11% of absorbed radiation dose of the current imaging protocol, yielding an average of 10% improvement for perfusion maps compared to the patch-based log likelihood method.
                                                    </div>
                                                    -->
                                                </div>

                                                <div class="item mix Journal" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1361841518307734?dgcid=author" class="tooltips" title="External link" target="_blank"><i class="fa fa-external-link"></i></a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Evolutionary Networks with Expedited Genetic Algorithms for Medical Image Denoising </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Peng Liu, Mohammad D El Basha, Yangjunyi Li, Yao Xiao, Pina C.Sanelli, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Medical Image Analysis, vol. 54, pp. 306-315</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Deep convolutional neural networks offer state-of-the-art performance for medical image analysis. However, their architectures are manually designed for particular problems. On the one hand, a manual designing process requires many trials to tune a large number of hyperparameters and is thus quite a time-consuming task. On the other hand, the fittest hyperparameters that can adapt to source data properties (e.g., sparsity, noisy features) are not able to be quickly identified for target data properties. For instance, the realistic noise in medical images is usually mixed and complicated, and sometimes unknown, leading to challenges in applying existing methods directly and creating effective denoising neural networks easily. In this paper, we present a Genetic Algorithm (GA)-based network evolution approach to search for the fittest genes to optimize network structures automatically. We expedite the evolutionary process through an experience-based greedy exploration strategy and transfer learning. Our evolutionary algorithm procedure has flexibility, which allows taking advantage of current state-of-the-art modules (e.g., residual blocks) to search for promising neural networks. We evaluate our framework on a classic medical image analysis task: denoising. The experimental results on computed tomography perfusion (CTP) image denoising demonstrate the capability of the method to select the fittest genes for building high-performance networks, named EvoNets. Our results outperform state-of-the-art methods consistently at various noise levels.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                            <a href="https://www.frontiersin.org/articles/10.3389/fneur.2019.00647/full" class="tooltips" title="External link" target="_blank"><i class="fa fa-external-link"></i></a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                        <img width="125" src="img/pubs/Frontiers.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">STIR-Net: Spatial-Temporal Image Restoration Net for CT Perfusion Radiation Reduction</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Yao Xiao, Peng Liu, Yun Liang, Skylar Stolte, Pina Sanelli, Ajay Gupta, Jana Ivanidze, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Frontiers in Nuerology</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Computed Tomography Perfusion (CTP) imaging is a cost-effective and fast approach to provide diagnostic images for acute stroke treatment. Its cine scanning mode allows the visualization of anatomic brain structures and blood flow; however, it requires contrast agent injection and continuous CT scanning over an extended time. In fact, the accumulative radiation dose to patients will increase health risks such as skin irritation, hair loss, cataract formation, and even cancer. Solutions for reducing radiation exposure include reducing the tube current and/or shortening the X-ray radiation exposure time. However, images scanned at lower tube currents are usually accompanied by higher levels of noise and artifacts. On the other hand, shorter X-ray radiation exposure time with longer scanning intervals will lead to image information that is insufficient to capture the blood flow dynamics between frames. Thus, it is critical for us to seek a solution that can preserve the image quality when the tube current and the temporal frequency are both low. We propose STIR-Net in this paper, an end-to-end spatial-temporal convolutional neural network structure, which exploits multi-directional automatic feature extraction and image reconstruction schema to recover high-quality CT slices effectively. With the inputs of low-dose and low-resolution patches at different cross-sections of the spatio-temporal data, STIR-Net blends the features from both spatial and temporal domains to reconstruct high-quality CT volumes. In this study, we finalize extensive experiments to appraise the image restoration performance at different levels of tube current and spatial and temporal resolution scales.The results demonstrate the capability of our STIR-Net to restore high-quality scans at as low as 11% of absorbed radiation dose of the current imaging protocol, yielding an average of 10% improvement for perfusion maps compared to the patch-based log likelihood method.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                            <a href="https://www.nature.com/articles/s41598-019-39795-x" class="tooltips" title="External link" target="_blank"><i class="fa fa-external-link"></i></a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/NATURE.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Automatic Choroid Layer Segmentation from Optical Coherence Tomography Images Using Deep Learning </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Saleha Masood, <strong>Ruogu Fang</strong>, Huating Li, Bin Sheng, Ping Li, Akash Mathavan, Xiangning Wang, Po Yang, Qiang Wu, Jing Qin, and Weiping Jia</div>
                                                            <div class="pubcite">Nature Scientiﬁc Reports, 9(1):3058</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The choroid layer is a vascular layer in human retina and its main function is to provide oxygen and support to the retina. Various studies have shown that the thickness of the choroid layer is correlated with the diagnosis of several ophthalmic diseases. For example, diabetic macular edema (DME) is a leading cause of vision loss in patients with diabetes. Despite contemporary advances, automatic segmentation of the choroid layer remains a challenging task due to low contrast, inhomogeneous intensity, inconsistent texture and ambiguous boundaries between the choroid and sclera in Optical Coherence Tomography (OCT) images. The majority of currently implemented methods manually or semi-automatically segment out the region of interest. While many fully automatic methods exist in the context of choroid layer segmentation, more effective and accurate automatic methods are required in order to employ these methods in the clinical sector. This paper proposed and implemented an automatic method for choroid layer segmentation in OCT images using deep learning and a series of morphological operations. The aim of this research was to segment out Bruch’s Membrane (BM) and choroid layer to calculate the thickness map. BM was segmented using a series of morphological operations, whereas the choroid layer was segmented using a deep learning approach as more image statistics were required to segment accurately. Several evaluation metrics were used to test and compare the proposed method against other existing methodologies. Experimental results showed that the proposed method greatly reduced the error rate when compared with the other state-of-the-art methods.
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/RSNA.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Network</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Manual Arreola, Izabella Barrreto, W. Christopher Fox, Keith Peters, <u><b>Ruogu Fang</b></u> </div>
                                                            <div class="pubcite">Annual Meeting of Radiology Society of North American</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        <a href="https://github.com/cswin/AWC" class="tooltips" title="Github" target="_blank">
                                                            <i class="fa fa-github"></i>
                                                        </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">CFEA: Collaborative Feature Ensembling Adaptation for Domain Adaptation in Unsupervised Optic Disc and Cup Segmentation</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, Bin Kong, Zhongyu Li, Shaoting Zhang, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Medical Image Analysis and Computer Assisted Intervention</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Abdominal Adipose Tissue Segmentation in MRI with Double Loss Function Collaborative Learning</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Siyuan Pan, Yuxin Xue, Bin Sheng, Xuhong Hou, Huating Li, <strong>Ruogu Fang</strong>, Weiping Jia, and Jing Qin </div>
                                                            <div class="pubcite">Medical Image Analysis and Computer Assisted Intervention</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multimodal CT Image Super-Resolution via Transfer-GAN.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Deep Learning-based Alzheimers Disease Classification of FDG-PET and AV45 PET Images.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Jianqiao Tian, Max Diaz, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Artificial Intelligence For Automated Diagnosis of Glaucoma In Stereoscopic Images</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Classification Of Neural Stimulations In The Brain With Super Voxels</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Kyle See, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Retinal Disease Diagnosis Using Mobile Devices</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, Kyle See, Daniel El Basha, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2019</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <!-- 2018-->
                                                <div class="item mix Journal" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.hindawi.com/journals/cin/2018/8234734/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/CIN.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Mining Big Neuron Morphological Data</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Maryamossadat Aghili, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Computational Intelligence and Neuroscience</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The advent of automatic tracing and reconstruction technology has led to a surge in the number of neurons 3D reconstruction data and consequently the neuromorphology research. However, the lack of machine-driven annotation schema to automatically detect the types of the neurons based on their morphology still hinders the development of this branch of science. Neuromorphology is important because of the interplay between the shape and functionality of neurons and the far-reaching impact on the diagnostics and therapeutics in neurological disorders. This survey paper provides a comprehensive research in the field of automatic neurons classification and presents the existing challenges, methods, tools, and future directions for automatic neuromorphology analytics. We summarize the major automatic techniques applicable in the field and propose a systematic data processing pipeline for automatic neuron classification, covering data capturing, preprocessing, analyzing, classification, and retrieval. Various techniques and algorithms in machine learning are illustrated and compared to the same dataset to facilitate ongoing research in the field.
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://ieeexplore.ieee.org/document/8362709" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEECyber.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Retinal Vessel Segmentation Using Minimum Spanning Superpixel Tree Detector</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Bin Sheng, Ping Li, Shuangjia Mo, Huating Li, Xuhong Hou, Qiang Wu, Jing Qin, <strong>Ruogu Fang</strong>, and David Dagan Feng</div>
                                                            <div class="pubcite">IEEE Transaction on Cybernetics, 99, pp.1-13</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The retinal vessel is one of the determining factors in an ophthalmic examination. Automatic extraction of retinal vessels from low-quality retinal images still remains a challenging problem. In this paper, we propose a robust and effective approach that qualitatively improves the detection of low-contrast and narrow vessels. Rather than using the pixel grid, we use a superpixel as the elementary unit of our vessel segmentation scheme. We regularize this scheme by combining the geometrical structure, texture, color, and space information in the superpixel graph. And the segmentation results are then refined by employing the efficient minimum spanning superpixel tree to detect and capture both global and local structure of the retinal images. Such an effective and structure-aware tree detector significantly improves the detection around the pathologic area. Experimental results have shown that the proposed technique achieves advantageous connectivity-area-length (CAL) scores of 80.92% and 69.06% on two public datasets, namely, DRIVE and STARE, thereby outperforming state-of-the-art segmentation methods. In addition, the tests on the challenging retinal image database have further demonstrated the effectiveness of our method. Our approach achieves satisfactory segmentation performance in comparison with state-of-the-art methods. Our technique provides an automated method for effectively extracting the vessel from fundus images
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/chapter/10.1007/978-3-030-00928-1_2" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Neural Network Evolution Using Expedited Genetic Algorithm for Medical Image Denoising</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, Yangjunyi Li, Mohammad D El Basha, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Medical Image Analysis and Computer Assisted Intervention, Granada, Spain.</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Convolutional neural networks offer state-of-the-art performance for medical image denoising. However, their architectures are manually designed for different noise types. The realistic noise in medical images is usually mixed and complicated, and sometimes unknown, leading to challenges in creating effective denoising neural networks. In this paper, we present a Genetic Algorithm (GA)-based network evolution approach to search for the fittest genes to optimize network structures. We expedite the evolutionary process through an experience-based greedy exploration strategy and transfer learning. The experimental results on computed tomography perfusion (CTP) images denoising demonstrate the capability of the method to select the fittest genes for building high-performance networks, named EvoNets, and our results compare favorably with state-of-the-art methods
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/chapter/10.1007/978-3-030-00919-9_4" class="tooltips" title="External Link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MLMI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">  Multi-task Fundus Image Quality Assessment via Transfer Learning and Landmarks Detection</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yaxin Shen, <strong>Ruogu Fang</strong>, Bin Sheng, Ling Dai, Huating Li, Jing Qin, Qiang Wu, and Weiping Jia </div>
                                                            <div class="pubcite">Machine Learning in Medical Imaging, Granada, Spain.</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The quality of fundus images is critical for diabetic retinopathy diagnosis. The evaluation of fundus image quality can be affected by several factors, including image artifact, clarity, and field definition. In this paper, we propose a multi-task deep learning framework for automated assessment of fundus image quality. The network can classify whether an image is gradable, together with interpretable information about quality factors. The proposed method uses images in both rectangular and polar coordinates, and fine-tunes the network from trained model grading of diabetic retinopathy. The detection of optic disk and fovea assists learning the field definition task through coarse-to-fine feature encoding. The experimental results demonstrate that our framework outperform single-task convolutional neural networks and reject ungradable images in automated diabetic retinopathy diagnostic systems.
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Low-Dose CT Perfusion Image Restoration and Radiation Reduction.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Peng Liu, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Atlanta, GA</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Eﬃcient Multi Modality Medical Image Joint Recosntruction via Vectorized Gradient</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Yun Liang, Yunmei Chen, Xiaojing Ye, <u><b>Ruogu Fang</b></u> </div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Atlanta, GA</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multi-Modality Brain Image Co-Registration</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Skylar Stolte, Yao Xiao, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Atlanta, GA</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Decision Tree-based Classiﬁcation for Diﬀerentiating System Lupus Erythematosus and Mixed Connective Tissue Disease</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Kyle B. See, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Biomedical Engineering Society Annual Meeting, Atlanta, GA</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/TAPIA.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">STDN: Spatial-Temporal Denoising Net for Radiation Optimization in CT Perfusion</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Liupeng, Yun Liang, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">ACM Richard Tapia Celebration of Diversity in Computing, September, Orlando, FL</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/ASNR.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Multi-Modality PET-MRI Image Joint Reconstruction</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Yun Liang, Yunmei Chen, Xiaojing Ye, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">ASNR 56th Annual Meeting & The Foundation of the ASNR Symposium, Vancouver, Canada</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/ASNR.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Image Super-Resolution and Radiation Reduction via Deep Learning</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Pina C. Sanelli, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">ASNR 56th Annual Meeting & The Foundation of the ASNR Symposium, Vancouver, Canada</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/ASNR.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Regulated-convolutional Networks for Low-dose Cerebral CT Perfusion Restoration</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"> Peng Liu, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">ASNR 56th Annual Meeting & The Foundation of the ASNR Symposium, Vancouver, Canada</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> SDCNET: Smoothed Dense-Convolution Network For Restoring Low-Dose Cerebral CT Perfusion</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"> Peng Liu, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">IEEE International Symposium on Biomedical Imaging, Washington D.C.</div>
                                                            <div class="pubdate">Publication Year: 2018</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                            
                                                <!--2017-->
                                                <div class="item mix Journal" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2017.0273" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IET.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Automatic Choroid Layer Segmentation Using Normalized Graph Cut </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Saleha Masood, Bin Sheng, Ping Li, Ruimin Shen, <strong>Ruogu Fang</strong>, Qiang Wu</div>
                                                            <div class="pubcite"> IET Image Processing. pp. 22, DOI:<a href="http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2017.0273">10.1049/iet-ipr.2017.0273</a>, Online ISSN 1751-9667, 2017.</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Optical coherence tomography (OCT) is an immersive technique for depth analysis of retinal layers. Automatic choroid layer segmentation is a challenging task because of the low contrast inputs. Existing methodologies carried choroid layer segmentation manually or semi-automatically. In this paper, we proposed automated choroid layer segmentation based on normalized cut algorithm, which aims at extracting the global impression of images and treats the segmentation as a graph partitioning problem. Due to the complexity of the layering structure of retinal layers and choroid layer, we employed a series of preprocessing to make the cut more deterministic and accurate. The proposed method divided the image into several patches and ran the normalized cut on every image patch separately. The aim was to avoid insignificant vertical cuts and focus on horizontal cutting. After processing every patch, we acquired a global cut on the original image by combining all the patches. Later we measured the choroidal thickness which is highly helpful in the diagnosis of several retinal diseases. The results were computed on a total of 525 images of 21 real patients. Experimental results showed that the mean relative error rate of the proposed method was around 0.4 as the compared the manual segmentation performed by the experts.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/chapter/10.1007/978-3-319-67389-9_12" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MLMI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">STAR: Spatio-Temporal Architecture for super-Resolution in Low-Dose CT Perfusion.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, Ajay Gupta, Pina C. Sanelli, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">Machine Learning in Medical Imaging (MIML), Medical Image Computing and Computer Assisted Intervention (MICCAI), Lecture Notes in Computer Science book series (LNCS, volume 10541), pp 97-105, Quebec, Canada, Sep. 2017.</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Computed tomography perfusion (CTP) is one of the most widely used imaging modality for cerebrovascular disease diagnosis and treatment, especially in emergency situations. While cerebral CTP is ca- pable of quantifying the blood flow dynamics by continuous scanning at a focused region of the brain, the associated excessive radiation increases the patients' risk levels of developing cancer. To reduce the necessary radiation dose in CTP, decreasing the temporal sampling frequency is one promising direction. In this paper, we propose STAR, an end-to- end Spatio-Temporal Architecture for super-Resolution to significantly reduce the necessary scanning time and therefore radiation exposure. The inputs into STAR are multi-directional 2D low-resolution spatio- temporal patches at different cross sections over space and time. Via training multiple direction networks followed by a conjoint reconstruc- tion network, our approach can produce high-resolution spatio-temporal volumes. The experiment results demonstrate the capability of STAR to maintain the image quality and accuracy of cerebral hemodynamic parameters at only one-third of the original scanning time.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Cardiovascular Disease Prediction and Risk Factor Mining with RFMiner. </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite"> Biomedical Engineering Society Annual Meeting (BMES), 2017 Annual Meeting, Phoenix, Arizona.</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Accelerated Brain Perfusion Imaging via Spatio-Temporal Super-Resolution.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite"> Biomedical Engineering Society Annual Meeting (BMES), 2017 Annual Meeting, Phoenix, Arizona.</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A Simple and Realistic Simulation Method for Low-Dose CT.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Peng Liu, <u><b>Ruogu Fang</b></u>></div>
                                                            <div class="pubcite"> Biomedical Engineering Society Annual Meeting (BMES), 2017 Annual Meeting, Phoenix, Arizona.</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010656" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEHealth.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">RFMiner: Risk Factors Discovery and Mining for Preventive Cardiovascular Health.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Yao Xiao, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">The Second IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE), Philadelphia, PA</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Cardiovascular disease is one of the leading causes of death in the United States. It is critical to identify the risk factors associated with cardiovascular diseases and to alert individuals before they experience a heart attack. In this paper we propose RFMiner, a risk factor discovery and mining framework for identifying significant risk factors using integrated measures. We provide the blueprints for accurately predicting the possibility of heart attacks in the near future while identifying notable risk factors - especially the factors which are not well recognized.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <!--<a href="http://users.cis.fiu.edu/~rfang/publications/NC16_TENDER.pdf" class="tooltips" title="Download" target="_blank">
                                                            <i class="fa fa-cloud-download"></i>
                                                            </a> -->
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Pattern_Recognition.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Indexing and Mining Large-Scale Neuron Databases using Maximum Inner Product Search.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Zhongyu Li, <strong>Ruogu Fang</strong>, Fumin Shen, Amin Katouzian, Shaoting Zhang.</div>
                                                            <div class="pubcite"> Pattern Recognition, vol. 63, pp. 680-688</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Morphological retrieval is an effective approach to explore large-scale neuronal databases, as the morphology is correlated with neuronal types, regions, functions, etc. In this paper, we focus on the neuron identification and analysis via morphological retrieval. In our proposed framework, multiple features are extracted to represent 3D neuron data. Because each feature reflects different levels of similarity between neurons, we group features into different hierarchies to compute the similarity matrix. Then, compact binary codes are generated from hierarchical features for efficient similarity search. Since neuronal cells usually have tree-topology structure, it is hard to distinguish different types of neurons simply via traditional binary coding or hashing methods based on Euclidean distance metric and/or linear hyperplanes. Therefore, we employ an asymmetric binary coding strategy based on the maximum inner product search (MIPS), which not only makes it easier to learn the binary coding functions, but also preserves the non-linear characteristics of the neuron morphological data. We evaluate the proposed method on more than 17,000 neurons, by validating the retrieved neurons with associated cell types and brain regions. Experimental results show the superiority of our approach in neuron morphological retrieval compared with other state-of-the-art methods. Moreover, we demonstrate its potential use cases in the identification and analysis of neuron characteristics from large neuron databases.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S0925231216313480" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <!--
                                                            <a href="http://users.cis.fiu.edu/~rfang/publications/NC16_TENDER.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="fa fa-cloud-download"></i>
                                                            </a>
                                                            -->
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neurocomputing.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Abdominal Adipose Tissues Extraction Using Multi-Scale Deep Neural Network.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor">Fei Jiang, Huating Li, Xuhong Hou, Bin Sheng, Ruimin Shen, Xiao-Yang Liu, Weiping Jia, Ping Li, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">NeuroComputing, vol. 229, pp. 23-33</div>
                                                            <div class="pubdate">Publication Year: 2017</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Segmentation of abdominal adipose tissues (AAT) into subcutaneous adipose tissues (SAT) and visceral adipose tissues (VAT) is of crucial interest for managing the obesity. Previous methods with raw or hand-crafted features rarely work well on large-scale subject cohorts, because of the inhomogeneous image intensities, artifacts and the diverse distributions of VAT. In this paper, we propose a novel two-stage coarse-to-fine algorithm for AAT seg- mentation. In the first stage, we formulate the AAT segmentation task as a pixel-wise classification problem. First, three types of features, intensity, spatial and contextual fea- tures, are adopted. Second, a new type of deep neural network, named multi-scale deep neural network (MSDNN), is provided to extract high-level features. In the second stage, to improve the segmentation accuracy, we refine coarse segmentation results by determining the internal boundary of SAT based on coarse segmentation results and continuous of SAT internal boundary. Finally, we demonstrate the efficacy of our algorithm for both 2D and 3D cases on a wide population range. Compared with other algorithms, our method is not only more suitable for large-scale dataset, but also achieves better segmentation results. Fur- thermore, our system takes about 2 seconds to segment an abdominal image, which implies potential clinical applications.</p>
                                                    </div>
                                                </div>

                                                <!-- 2016-->
                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/WIML.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Towards High-Throughput Abnormal Brain Screening in MRI Images</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"> Maryamossadat Aghili, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite"> Women in Machine Learning Workshop, Neural Information Processing Systems (NIPS), Barcelona, Spain.</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S0925231216313753" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="http://users.cis.fiu.edu/~rfang/publications/NC16_TENDER.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="fa fa-cloud-download"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neurocomputing.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">TENDER: TEnsor Non-local Deconvolution Enabled Radiation Reduction in CT Perfusion.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ajay Gupta, Junzhou Huang, Pina Sanelli.</div>
                                                            <div class="pubcite"> NeuroComputing, vol. 229, pp. 13-22</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Stroke is the leading cause of long-term disability and the second leading cause of mortality in the world, and exerts an enormous burden on the public health. CT remains one of the most widely used imaging modality for stroke diagnosis. However when coupled with CT perfusion, the excessive radiation exposure in repetitive imaging to assess treatment response and prognosis has raised significant public concerns regarding its potential hazards to both short- and longterm health outcomes. Tensor total variation has been proposed to reduce the necessary radiation dose in CT perfusion without comprising the image quality by fusing the information of the local anatomical structure with the temporal blood flow model. However the local search in the framework fails to leverage the non-local information in the spatio-temporal data. In this paper, we propose TENDER, an efficient framework of non-local tensor deconvolution to maintain the accuracy of the hemodynamic parameters and the diagnostic reliability in low radiation dose CT perfusion. The tensor total variation is extended using non-local spatio-temporal cubics for regularization to integrate contextual and non-local information. We also propose an efficient framework consisting of fast nearest neighbor search, accelerated optimization and parallel computing to improve the efficiency and scalability of the non-local spatio-temporal algorithm. Evaluations on clinical data of subjects with cerebrovascular disease and normal subjects demonstrate the advantage of non-local tensor deconvolution for reducing radiation dose in CT perfusion.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://dl.acm.org/citation.cfm?id=2932707" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="http://users.cis.fiu.edu/~rfang/publications/ACM16_Survey.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="fa fa-cloud-download"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/ACM.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Computational Health Informatics in the Big Data Age: A Survey</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang*</b></u>, Samira Pouyanfar*, Yimin Yang, Shu-Ching Chen, S. S. Iyengar (* indicates equal contributions)</div>
                                                            <div class="pubcite"> Journal CSUR, ACM Computing Survey, Volume 49 Issue 1, Article No. 12</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The explosive growth and widespread accessibility of digital health data have led to a surge of research activity in the healthcare and data sciences fields. The conventional approaches for health data management have achieved limited success as they are incapable of handling the huge amount of complex data with high volume, high velocity, and high variety. This article presents a comprehensive overview of the existing challenges, techniques, and future directions for computational health informatics in the big data age, with a structured analysis of the historical and state-of-the-art methods. We have summarized the challenges into four Vs (i.e., volume, velocity, variety, and veracity) and proposed a systematic data-processing pipeline for generic big data in health informatics, covering data capturing, storing, sharing, analyzing, searching, and decision support. Specifically, numerous techniques and algorithms in machine learning are categorized and compared. On the basis of this material, we identify and discuss the essential prospects lying ahead for computational health informatics in this big data age.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/WoundHealing.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Hemodynamic Imaging of Lower Extremity Ulcers.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Rebecca Kwasinski, Cristianne Fernandez, Kevin Leiva, Edwin Robledo, Yuanyuan Zhu, Penelope Kallis, Francesco-Perez Clavijo, <strong>Ruogu Fang</strong>, Robert Kirsner, Anuradha Godavarty.</div>
                                                            <div class="pubcite"> Innovations in Wound Healing</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Clinicians employ visual inspection of the wound and reduction in its size over time to monitor its healing process. Although these are standard clinical assessments, there is a need to develop a physiological approach that can map sub-surface tissue oxygenation at and around the wound region.  Recently, a non-contact, portable, hand-held near infrared optical scanner (NIROS) has been developed to functionally image wound sites and differentiate healing from non-healing in lower extremity ulcers. Past studies using NIROS focused on differentiating healing from non-healing wounds based on NIR optical contrast between the wound and healthy surrounding tissue. However, these studies did not showcase the physiological changes in tissue oxygenation. Herein, NIROS has been modified to perform multi wavelength imaging in order to obtain the oxy and deoxy- hemoglobin maps of the wound and its surroundings. Clinical studies are currently performed at two clinical sites in Miami on lower extremity ulcers (2, diabetic foot ulcers (DFUs) and 4 venous leg ulcers (VLUs to date). Preliminary results have shown changes in oxy- and deoxy-hemoglobin maps of the wound and background across weeks of the treatment process. Image segmentation studies quantified regions of varied tissue oxygenation around and beneath the wound to potentially determine sub-surface healing regions. Ongoing efforts involve systematic 8-week imaging studies to obtain physiological indicators of healing from hemodynamic studies of DFUs and VLUs.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                        <!--
                                                        <a href="http://users.cis.fiu.edu/~rfang/publications/BMES16_SR.pdf" class="tooltips" title="Download" target="_blank">
                                                            <i class="fa fa-cloud-download"></i>
                                                        </a>
                                                        -->
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">CT perfusion image super-resolution using a deep convolutional network.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Paul Naghshineh, Peng Liu, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">BMES, Biomedical Engineering Society Annual Meeting in Minneapolis, Minnesota.</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                    <!--    <a href="http://users.cis.fiu.edu/~rfang/publications/BMES16_physiological.pdf" class="tooltips" title="Download" target="_blank">
                                                            <i class="fa fa-cloud-download"></i>
                                                        </a>-->
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Physiological Assessment of Wound Healing using a Near-Infrared Optical Scanner.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Anuradha Godavarty, Rebecca Kwasinki, Cristianne Fernandez, Yuanyuan Zhu, Edwin Robledo, F. Perez-Clavijo, <u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite"> Biomedical Engineering Society Annual Meeting (BMES) in Minneapolis, Minnesota.</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7493340&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7493340" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Maximum Inner Product Search for Morphological Retrieval of Large-Scale Neuron Data</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Zhongyu Li, Fumin Shen, <strong>Ruogu Fang</strong>, Sailesh Conjeti, Amin Katouzian, Shaoting Zhang.</div>
                                                            <div class="pubcite">ISBI, IEEE International Symposium on Biomedical Imaging, Prague, Czech Republic</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Morphological retrieval is an effective approach to explore neurons' databases, as the morphology is correlated with neuronal types, regions, functions, etc. In this paper, we focus on the neuron identification and analysis via morphological retrieval. In our proposed framework, both global and local features are extracted to represent 3D neuron data. Then, compacted binary codes are generated from original features for efficient similarity search. As neuron cells usually have tree-topology structure, it is hard to distinguish different types of neuron simply via traditional binary coding or hashing methods based on Euclidean distance metric and/or linear hyperplanes. Thus, we propose a novel binary coding method based on the maximum inner product search (MIPS), which is not only more easier to learn the binary coding function, but also preserves the non-linear characteristics of neuron morphology data. We evaluate the proposed method on more than 17,000 neurons, by validating the retrieved neurons with associated cell types and brain regions. Experimental results show the superiority of our approach in neuron morphological retrieval compared with other state-of-the-art methods. Moreover, we demonstrate its potential use case in the identification and analysis of neuron characteristics.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7493372&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel7%2F7486633%2F7493185%2F07493372.pdf%3Farnumber%3D7493372" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Direct Estimation of Permeability Maps for Low-Dose CT Perfusion </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ajay Gupta, Pina C. Sanelli</div>
                                                            <div class="pubcite"> ISBI, IEEE International Symposium on Biomedical Imaging, Prague, Czech Republic</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>With the goal of achieving low radiation exposure from
                                                        medical imaging, computed tomography perfusion (CTP)
                                                        introduces challenging problems for both image reconstruction
                                                        and perfusion parameter estimation in the qualitative
                                                        and quantitative analyses. Conventional approaches address
                                                        the reconstruction and the estimation processes separately.
                                                        Since the hemodynamic parameter maps have much lower
                                                        dimensionality than the original sinogram data, estimating
                                                        hemodynamic parameters directly from sinogram will further
                                                        reduce radiation exposure and save computational resources
                                                        to reconstruct the intermediate time-series images. In this
                                                        work, we propose the first direct estimation framework for
                                                        CTP that integrates the time-series image reconstruction,
                                                        contrast conversion, hematocrit correction and hemodynamic
                                                        parameter estimation in one optimization function, which is
                                                        solved using an efficient algorithm. Evaluations on the digital
                                                        brain perfusion phantom and a clinical acute stroke subject
                                                        demonstrate that the proposed direct estimation framework
                                                        boosts the estimation accuracy remarkably in CTP scanning
                                                        with lower radiation exposure.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Automatic Segmentation of Lower Extremity Ulcers in Near-Infrared Optical Imaging</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><strong>Ruogu Fang</strong>, Xing Pang, Arash Dadkhah, Jiali Lei, Elizabeth Solis, Suset Rodriguesz, Francisco Perez-Clavijo, Stephen Wigley, Charles Buscemi, Anuradha Godvarty.</div>
                                                            <div class="pubcite">ISBI, IEEE International Symposium on Biomedical Imaging, Prague, Czech Republic</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://8.18.37.105/abstract.cfm?uri=OTS-2016-JTu3A.43" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/OSA.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Near-Infrared Optical Imaging and Wound Segmentation in Lower Extremity Ulcers</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Xing Pang, Arash Dadkhah, Jaili Lei, Elizabeth Solis, Suset Rodriguez, Francisco Perez-Clavijo, Stephen Wigley, <strong>Ruogu Fang</strong>, Anuradha Godvarty.</div>
                                                            <div class="pubcite">OSA, Optical Society of America Annual Meeting</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Near-Infrared (NIR) optical imaging can reveal tissue oxygenation of the wound, complementing the visual inspection of the surface granulation. Herein, graph cuts algorithm is applied to segment NIR images of the wound from its peripheries.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2016">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=2501771" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SPIE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Wound Size Measurement of Lower Extremity Ulcers Using Segmentation Algorithms</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Arash Dadkhah, Xing Pang, Elizabeth Solis, <strong>Ruogu Fang</strong>, Anuradha Godvarty.</div>
                                                            <div class="pubcite"> SPIE Proceedings in Photonics West, San Francisco</div>
                                                            <div class="pubdate">Publication Year: 2016</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Lower extremity ulcers are one of the most common complications that not only affect many people around the world but also have huge impact on economy since a large amount of resources are spent for treatment and prevention of the diseases. Clinical studies have shown that reduction in the wound size of 40% within 4 weeks is an acceptable progress in the healing process. Quantification of the wound size plays a crucial role in assessing the extent of healing and determining the treatment process. To date, wound healing is visually inspected and the wound size is measured from surface images. The extent of wound healing internally may vary from the surface. A near-infrared (NIR) optical imaging approach has been developed for non-contact imaging of wounds internally and differentiating healing from non-healing wounds. Herein, quantitative wound size measurements from NIR and white light images are estimated using a graph cuts and region growing image segmentation algorithms. The extent of the wound healing from NIR imaging of lower extremity ulcers in diabetic subjects are quantified and compared across NIR and white light images. NIR imaging and wound size measurements can play a significant role in potentially predicting the extent of internal healing, thus allowing better treatment plans when implemented for periodic imaging in future.</p>
                                                    </div>
                                                </div>

                                                <!-- 2015-->
                                                <div class="item mix Journal" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://users.cis.fiu.edu/~rfang/projects/ttv.html" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MCV.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Efficient 4D Non-Local Tensor Total-Variation for Low-Dose CT Perfusion Deconvolution</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ming Ni, Junzhou Huang, Qianmu Li, Tao Li</div>
                                                            <div class="pubcite">Medical Computer Vision: Algorithms for Big DataChapter, no.16, Lecture Notes in Computer Science</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Tensor total variation deconvolution has been recently proposed as a robust framework to accurately estimate the hemodynamic parameters in low-dose CT perfusion by fusing the local anatomicalstructure correlation and temporal blood flow continuation. However
                                                            the locality property in the current framework constrains the search for
                                                            anatomical structure similarities to the local neighborhood, missing the
                                                            global and long-range correlations in the whole anatomical structure.
                                                            This limitation has led to noticeable absence or artifact of delicate structures,
                                                            including the critical indicators for the clinical diagnosis of cerebrovascular
                                                            diseases. In this paper, we propose an extension of the TTV
                                                            framework by introducing 4D non-local tensor total variation into the deconvolution
                                                            to bridge the gap between non-adjacent regions of the same
                                                            tissue classes. The non-local regularization using tensor total variation
                                                            term is imposed on the spatio-temporal flow-scaled residue functions.
                                                            An efficient algorithm and implementation of the non-local tensor total
                                                            variation (NL-TTV) reduces the time complexity with fast similarity
                                                            computation, accelerated optimization and parallel operations. Extensive
                                                            evaluations on the clinical data with cerebrovascular diseases and normal subjects demonstrate the importance of non-local linkage and long-range connections for low-dose CT perfusion deconvolution.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7046356" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEMedical.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Robust Low-dose CT Perfusion Deconvolution via Tensor Total-Variation Regularization</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Shaoting Zhang, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">TMI, IEEE Transaction on Medical Imaging, vol.34, no.7, pp.1533-1548</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Acute brain diseases such as acute strokes and
                                                        transit ischemic attacks are the leading causes of mortality and
                                                        morbidity worldwide, responsible for 9% of total death every
                                                        year. ‘Time is brain' is a widely accepted concept in acute
                                                        cerebrovascular disease treatment. Efficient and accurate computational
                                                        framework for hemodynamic parameters estimation
                                                        can save critical time for thrombolytic therapy. Meanwhile the
                                                        high level of accumulated radiation dosage due to continuous
                                                        image acquisition in CT perfusion (CTP) raised concerns on
                                                        patient safety and public health. However, low-radiation leads to
                                                        increased noise and artifacts which require more sophisticated
                                                        and time-consuming algorithms for robust estimation. In this
                                                        paper, we focus on developing a robust and efficient framework
                                                        to accurately estimate the perfusion parameters at low radiation
                                                        dosage. Specifically, we present a tensor total-variation (TTV)
                                                        technique which fuses the spatial correlation of the vascular
                                                        structure and the temporal continuation of the blood signal flow.
                                                        An efficient algorithm is proposed to find the solution with fast
                                                        convergence and reduced computational complexity. Extensive
                                                        evaluations are carried out in terms of sensitivity to noise levels,
                                                        estimation accuracy, contrast preservation, and performed on
                                                        digital perfusion phantom estimation, as well as in-vivo clinical
                                                        subjects. Our framework reduces the necessary radiation dose
                                                        to only 8% of the original level and outperforms the state-of-art
                                                        algorithms with peak signal-to-noise ratio improved by 32%. It
                                                        reduces the oscillation in the residue functions, corrects overestimation
                                                        of cerebral blood flow (CBF) and under-estimation of
                                                        mean transit time (MTT), and maintains the distinction between
                                                        the deficit and normal regions.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S0895611115000981#" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/CMIG.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Guest Editorial: Sparsity Techniques in Medical Imaging.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Tsuhan Chen, Dimitris Metaxas, Pina Sanelli, Shaoting Zhang.</div>
                                                            <div class="pubcite">CMIG, Elsevier Journal of Computerized Medical Imaging and Graphics, vol. 46, no. 1</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>With the advent of the age for big data and complex structure,
                                                        sparsity has been an important modeling tool in compressed
                                                        sensing, machine learning, image processing, neuroscience and
                                                        statistics. In the medical imaging field, sparsity methods have been
                                                        successfully used in image reconstruction, image enhancement,
                                                        image segmentation, anomaly detection, disease classification, and
                                                        image database retrieval. Developing more powerful sparsity models
                                                        for a large range of medical imaging and medical image analysis
                                                        problems as well as efficient optimization and learning algorithm
                                                        will keep being a main research topic in this field. The goal of this
                                                        special issue is to publish original and high quality papers on innovation
                                                        research and development in medical imaging and medical
                                                        image analysis using sparsity techniques. This special issue will
                                                        help advance the scientific research within the field of sparsity
                                                        methods for medical imaging.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Journal" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S0895611115000890" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEMedical.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Tissue-Specific Sparse Deconvolution for Brain CT Perfusion. </h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>,Haodi Jiang, Junzhou Huang.</div>
                                                            <div class="pubcite"> CMIG, Elsevier Journal of Computerized Medical Imaging and Graphics, vol.46, no.1, pp. 64-72</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Enhancing perfusion maps in low-dose computed tomography perfusion (CTP)
                                                        for cerebrovascular disease diagnosis is a challenging task, especially for lowcontrast
                                                        tissue categories where infarct core and ischemic penumbra usually
                                                        occur. Sparse perfusion deconvolution has been recently proposed to effectively
                                                        improve the image quality and diagnostic accuracy of low-dose perfusion CT by
                                                        extracting the complementary information from the high-dose perfusion maps
                                                        to restore the low-dose using a joint spatio-temporal model. However the lowcontrast
                                                        tissue classes where infarct core and ischemic penumbra are likely to
                                                        occur in cerebral perfusion CT tend to be over-smoothed, leading to loss of
                                                        essential biomarkers. In this paper, we propose a tissue-specific sparse deconvolution
                                                        approach to preserve the subtle perfusion information in the low-contrast
                                                        tissue classes. We first build tissue-specific dictionaries from segmentations of
                                                        high-dose perfusion maps using online dictionary learning, and then perform
                                                        deconvolution-based hemodynamic parameters estimation for block-wise tissue
                                                        segments on the low-dose CTP data. Extensive validation on clinical datasets
                                                        of patients with cerebrovascular disease demonstrates the superior performance
                                                        of our proposed method compared to state-of-art, and potentially improve diagnostic accuracy by increasing the differentiation between normal and ischemic
                                                        tissues in the brain</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/WoundHealing.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Wound Segmentation in Near-Infrared Optical Imaging </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><strong>Ruogu Fang</strong>, Xing Pang, Arash Dadkhah, Jiali Lei, Elizabeth SOlis, Suset ROdriguez, Francisco Perez-Calvijo, Stephen Wigley, Charles Buscemi, Anuradha Godvarty.</div>
                                                            <div class="pubcite"> Innovation in Wound Healing, Hawks Cay, FL</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <!--
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="http://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="fa fa-cloud-download"></i>
                                                            </a>
                                                        </div>-->
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Fast Preconditioning for Accelerated Multi-Contrast MRI Reconstruction</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Ruoyu Li, Yeqing Li, <strong>Ruogu Fang</strong>,Shaoting Zhang, Hao Pan, Junzhou Huang</div>
                                                            <div class="pubcite"> MICCAI'15, In Proc. of the 18th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Munich, Germany</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <!--
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Although a substantial amount of research has examined the constructs of warmth and competence, far less has examined how these constructs develop and what benefits may accrue when warmth and competence are cultivated. Yet there are positive consequences, both emotional and behavioral, that are likely to occur when brands hold perceptions of both. In this paper, we shed light on when and how warmth and competence are jointly promoted in brands, and why these reputations matter.</p>
                                                    </div>-->
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Efficient 4D Non-Local Tensor Total-Variation for Low-Dose CT Perfusion Deconvolution</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"> <u><b>Ruogu Fang</b></u>, Ming Ni, Junzhou Huang, Qianmu Li, and Tao Li </div>
                                                            <div class="pubcite"> The 18th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Workshop on Medical Computer Vision, Munich, Germany</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/BMES.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Robust Low-Dose CT Perfusion Deconvolution via Non-Local Tensor Total Variation</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ming Ni, Junzhou Huang, Qianmu Li, Tao Li</div>
                                                            <div class="pubcite"> BMES, Biomedical Engineering Society Annual Meeting, Tampa, FL</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Introduction</h4>
                                                        <p>Stroke and cerebrovascular diseases are the leading cause of serious, long-term disability in the
                                                        United States. Computed tomography perfusion (CTP) is one of the most widely accepted imaging modality for
                                                        stroke care. However, the high radiation exposure of CTP has lead to increased cancer risk. Tensor total variation
                                                        (TTV)[1] has been proposed to stabilize the quantification of perfusion parameters by integrating the anatomical
                                                        structure correlation. Yet the locality limitation of the neighborhood region has led to noticeable absence or
                                                        inflation of the delicate structures which are critical indicators for the clinical diagnosis. In this work, we propose
                                                        a non-local tensor total variation (NL-TTV) deconvolution method to by incorporating the long-range dependency
                                                        and the global connections in the spatio-temporal domain</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MRM.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">4-D Spatio-Temporal MR Perfusion Deconvolution via Tensor Total Variation.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u></div>
                                                            <div class="pubcite">ISMRM'15, International Society for Magnetic Resonance in Medicine (ISMRM) Annual Meeting, Toronto, Canada. Oral presentation</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Introduction</h4>
                                                        <p>4-D dynamic susceptibility contrast (DSC) magnetic resonance imaging (MRI) is a well-established perfusion technique for non-invasive characterization of tissue
                                                        dynamics, with promising applications in assessing a wide range of diseases, as well as monitoring response of therapeutic interventions). DSC-MRI provides critical
                                                        real-time information by tracking the first-pass of an injected contrast-agent (e.g. gadolinium) with T2*-weighted MRI. The spatio-temproal data, consisting of contrast
                                                        concentration signals for each voxel of a volume, are deconvolved from the arterial input function (AIF) and then post-processed to generate perfusion parameter maps,
                                                        typically including the cerebral blood flow (CBF), cerebral blood volume (CBV), mean transit time (MTT) and time to peak (TTP). The most popular deconvolution
                                                        method is truncated singular value decomposition (TSVD)1,2 and its variants3
                                                        , which fail to exploit the spatio-temporal nature of the 4D data with both the anatomical
                                                        structure and the temporal continuation. This work adapts and demonstrates the feasibility of a 4-D tensor total variation (TTV) deconvolution approach, which has
                                                        been proposed for CT perfusion4
                                                        , to brain MR perfusion, with evaluation on synthetic data and clinical DSC-MRI data for glioblastomas, the most common type of
                                                        brain cancer. The method is guaranteed to convergence to global optimal because of the convex cost function and presents a more elegant framework of total variation
                                                        for the deconvolution, compared to recent efforts5,6 which either do not have a global optimal solution for the non-convex case or need to handcraft spatial and temporal
                                                        regularization terms.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                    <!-- <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                            <a href="http://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="fa fa-cloud-download"></i>
                                                            </a>
                                                        </div>-->
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neurocomputing.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Leveraging Coupled Multi-Index for Scalable Retrieval of Mammographic Masses. </h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor">Menglin Jiang, Shaoting Zhang, <strong>Ruogu Fang</strong>, Dimitris Metaxas.</div>
                                                            <div class="pubcite"> ISBI'15, The IEEE International Symposium on Biomedical Imaging (ISBI), NYC, USA. Oral presentation 130 / 714 = 18%</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <!--
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Although a substantial amount of research has examined the constructs of warmth and competence, far less has examined how these constructs develop and what benefits may accrue when warmth and competence are cultivated. Yet there are positive consequences, both emotional and behavioral, that are likely to occur when brands hold perceptions of both. In this paper, we shed light on when and how warmth and competence are jointly promoted in brands, and why these reputations matter.</p>
                                                    </div>-->
                                                </div>

                                                <div class="item mix Conference" data-year="2015">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Neurocomputing.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">A Spatio-Temporal Low-rank Total Variation Approach for Denoising Arterial Spin Labeling MRI Data</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>,Junzhou Huang, Wen-Ming Luh.</div>
                                                            <div class="pubcite">ISBI'15, The IEEE International Symposium on Biomedical Imaging (ISBI), NYC, USA</div>
                                                            <div class="pubdate">Publication Year: 2015</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Arterial spin labeling MRI (ASL-MRI) can provide quantitative
                                                        signals correlated to the cerebral blood flow and neural
                                                        activity. However, the low signal-to-noise ratio in ASL
                                                        requires repeated acquisitions to improve the signal reliability,
                                                        leading to prolonged scanning time. At fewer repetitions,
                                                        noise and corruptions arise due to motion and physiological
                                                        artifacts, introducing errors into the cerebral blood flow estimation.
                                                        We propose to recover the ASL-MRI data from
                                                        the noisy and corrupted observations at shorter scanning time
                                                        with a spatio-temporal low-rank total variation method. The
                                                        low-rank approximation uses the similarity of the repetitive
                                                        scans, and the total variation regularization considers the local
                                                        spatial consistency. We compare with the state-of-art robust
                                                        M-estimator for ASL cerebral blood flow map estimation.
                                                        Validation on simulated and real data demonstrate the
                                                        robustness of the proposed method at fewer scanning repetitions
                                                        and with random corruption</p>
                                                    </div>
                                                </div>





                                                <!-- 2014-->
                                                <div class="item mix Journal" data-year="2014">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S136184151300145X" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Improving Low-Dose Blood-Brain Barrier Permeability Quantification Using Sparse High-Dose Induced Prior for Patlak Model.</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Kolbeinn Karlsson, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">MedIA'14, Medical Image Analysis, Volume 18, Issue 6, Pages 866-880</div>
                                                            <div class="pubdate">Publication Year: 2014</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Blood-brain barrier permeability (BBBP) measurements extracted from the perfusion computed tomography (PCT) using the
                                                        Patlak model can be a valuable indicator to predict hemorrhagic transformation in patients with acute stroke. Unfortunately, the
                                                        standard Patlak model based PCT requires excessive radiation exposure, which raised attention on radiation safety. Minimizing
                                                        radiation dose is of high value in clinical practice but can degrade the image quality due to the introduced severe noise. The purpose
                                                        of this work is to construct high quality BBBP maps from low-dose PCT data by using the brain structural similarity between
                                                        different individuals and the relations between the high- and low-dose maps. The proposed sparse high-dose induced (shd-Patlak)
                                                        model performs by building a high-dose induced prior for the Patlak model with a set of location adaptive dictionaries, followed
                                                        by an optimized estimation of BBBP map with the prior regularized Patlak model. Evaluation with the simulated low-dose clinical
                                                        brain PCT datasets clearly demonstrate that the shd-Patlak model can achieve more significant gains than the standard Patlak model
                                                        with improved visual quality, higher fidelity to the gold standard and more accurate details for clinical analysis.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2014">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://users.cis.fiu.edu/~rfang/projects/ttv.html" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Tensor Total-Variation Regularized Deconvolution for Efficient Low-Dose CT Perfusion.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>,Pina Sanelli, Shaoting Zhang, Tsuhan Chen.</div>
                                                            <div class="pubcite">MICCAI'14, The 17th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Boston, USA</div>
                                                            <div class="pubdate">Publication Year: 2014</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Acute brain diseases such as acute stroke and transit ischemic attacks
                                                        are the leading causes of mortality and morbidity worldwide, responsible for 9%
                                                        of total death every year. ‘Time is brain' is a widely accepted concept in acute
                                                        cerebrovascular disease treatment. Efficient and accurate computational framework
                                                        for hemodynamic parameters estimation can save critical time for thrombolytic
                                                        therapy. Meanwhile the high level of accumulated radiation dosage due to
                                                        continuous image acquisition in CT perfusion (CTP) raised concerns on patient
                                                        safety and public health. However, low-radiation will lead to increased noise and
                                                        artifacts which require more sophisticated and time-consuming algorithms for
                                                        robust estimation. We propose a novel efficient framework using tensor totalvariation
                                                        (TTV) regularization to achieve both high efficiency and accuracy in
                                                        deconvolution for low-dose CTP. The method reduces the necessary radiation
                                                        dose to only 8% of the original level and outperforms the state-of-art algorithms
                                                        with estimation error reduced by 40%. It also corrects over-estimation of cerebral
                                                        blood flow (CBF) and under-estimation of mean transit time (MTT), at both normal
                                                        and reduced sampling rate. An efficient</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2014">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Anisotropic Tensor Total Variation Regularization For Low Dose Low CT Perfusion Deconvolution.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">MICCAI'14, The 17th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Workshop on Sparsity Techniques in Medical Imaging, Boston, USA</div>
                                                            <div class="pubdate">Publication Year: 2014</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Tensor total variation (TTV) regularized deconvolution has been proposed
                                                        for robust low radiation dose CT perfusion. In this paper, we extended TTV
                                                        algorithm with anisotropic regularization weighting for the temporal and spatial
                                                        dimension. We evaluated TTV algorithm on synthetic dataset for bolus delay,
                                                        uniform region variability and contrast preservation, and on clinical dataset for
                                                        reduced sampling rate with visual and quantitative comparison. The extensive
                                                        experiments demonstrated promising results of TTV compared to baseline and
                                                        state-of-art algorithms in low-dose and low sampling rate CTP deconvolution
                                                        with insensitivity to bolus delay. This work further demonstrates the effectiveness
                                                        and potential of TTV algorithm's clinical usage for cerebrovascular diseases
                                                        with significantly reduced radiation exposure and improved patient safety.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Dissertation" data-year="2014">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/Cornell.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Towards Robust Deconvolution in Medical Imaging: Informatics, Diagnosis and Treatment.</h4>
                                                            <span class="label label-success">PhD Dissertation</span>
                                                            <div class="pubauthor"><strong> Ruogu Fang</strong></div>
                                                            <div class="pubcite">School of Electrical and Computer Engineering, Cornell University</div>
                                                            <div class="pubdate">Publication Year: 2014</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Introduction</h4>
                                                        <p>Robust deconvolution, the task of estimating hemodynamic parameters from measured spatio-temporal data, is a key problem in computed tomography perfusion. Traditionally, this has been accomplished by solving the inverse problem of the temporal tracer enhancement curves at each voxel inde- pendently. Incorporating spatial contextual information, i.e. information other than the temporal enhancement of the contrast agent, has received significant attention in recent works. Intra-subject contextual information is often exploited to remove the noise and artifacts in the low-dose hemodynamic maps. In this thesis, we take a closer look at the role of inter-subject contextual information in robust deconvolution. Specifically, we explore its importance in three as- pects. First: Informatics acquisition. We show, through synthetic evaluation as well as in-vivo clinical data, that inter-subject similarity provides complimen- tary information to improve the accuracy of cerebral blood flow map estimation and increase the differentiation between normal and deficit tissue. Second: Dis- ease diagnosis. We show that apart from the global learned dictionary for hemo- dynamic maps, the tissue-specific dictionaries can be effectively leveraged for disease diagnosis tasks as well, especially for low-contrast tissue types where the deficits usually occur. Lastly: Treatment plan. We propose a generalized framework with inter-subject context through dictionary learning and sparse representation possible for any hemodynamic parameter estimation, such as blood-brain-barrier permeability. We also extend to include inter-subject context through tensor total variation. The diverse hemodynamic maps provide necessary information for treatment plan decision making. We present results of our approaches on a variety of datasets and clinical tasks, such as uniform regions estimation, contrast preservation, data acquired at low-sampling rate and low radiation dose levels.</p>
                                                    </div>
                                                </div>

                                                <!-- 2013-->
                                                <div class="item mix Journal" data-year="2013">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.sciencedirect.com/science/article/pii/S1361841513000194" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MIA.gif" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Towards Robust Deconvolution of Low-Dose Perfusion CT: Sparse Perfusion Deconvolution Using Online Dictionary Learning</h4>
                                                            <span class="label label-warning">Journal</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">MedIA'13, Medical Image Analysis, Volume 17, Issue 4, Pages 417-428(5 Year Impact Factor: 4.512)</div>
                                                            <div class="pubdate">Publication Year: 2013</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Computed tomography perfusion (CTP) is an important functional imaging modality in the evaluation of cerebrovascular diseases,
                                                        particularly in acute stroke and vasospasm. However, the post-processed parametric maps of blood flow tend to be noisy,
                                                        especially in low-dose CTP, due to the noisy contrast enhancement profile and the oscillatory nature of the results generated by
                                                        the current computational methods. In this paper, we propose a robust sparse perfusion deconvolution method (SPD) to estimate
                                                        cerebral blood flow in CTP performed at low radiation dose. We first build a dictionary from high-dose perfusion maps using online
                                                        dictionary learning and then perform deconvolution-based hemodynamic parameters estimation on the low-dose CTP data. Our
                                                        method is validated on clinical data of patients with normal and pathological CBF maps. The results show that we achieve superior
                                                        performance than existing methods, and potentially improve the differentiation between normal and ischemic tissue in the brain.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2013">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medim wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Tissue-Specific Sparse Deconvolution for Low-Dose CT Perfusion</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>>, Tsuhan Chen, Pina C. Sanelli</div>
                                                            <div class="pubcite">MICCAI'13, The 16th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Japan</div>
                                                            <div class="pubdate">Publication Year: 2013</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Sparse perfusion deconvolution has been recently proposed to effectively
                                                        improve the image quality and diagnostic accuracy of low-dose perfusion
                                                        CT by extracting the complementary information from the high-dose perfusion
                                                        maps to restore the low-dose using a joint spatio-temporal model. However the
                                                        low-contrast tissue classes where infarct core and ischemic penumbra usually occur
                                                        in cerebral perfusion CT tend to be over-smoothed, leading to loss of essential
                                                        biomarkers. In this paper, we extend this line of work by introducing tissuespecific
                                                        sparse deconvolution to preserve the subtle perfusion information in the
                                                        low-contrast tissue classes by learning tissue-specific dictionaries for each tissue
                                                        class, and restore the low-dose perfusion maps by joining the tissue segments
                                                        reconstructed from the corresponding dictionaries. Extensive validation on clinical
                                                        datasets of patients with cerebrovascular disease demonstrates the superior
                                                        performance of our proposed method with the advantage of better differentiation
                                                        between abnormal and normal tissue in these patients.</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2013">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www2.securecms.com/ICIP2013/" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/ICIP.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Kinship Classification by Modeling Facial Feature Heredity</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Andrew C. Gallagher, Tsuhan Chen, Alexander Loui</div>
                                                            <div class="pubcite">IEEE International Conference on Image Processing, Melbourne, Australia</div>
                                                            <div class="pubdate">Publication Year: 2013</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <!-- 2012-->
                                                <div class="item mix Conference" data-year="2012">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Sparsity-Based Deconvolution of Low-Dose Perfusion CT Using Learned Dictionaries.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">MICCAI'12, The 15th Annual International Conference on Medical Image Computing and Computer Assisted Intervention, Nice, France. Lecture Notes in Computer Science Volume 7510, 2012, pp 272-280.</div>
                                                            <div class="pubdate">Publication Year: 2012</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2012">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEEImaging.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Sparsity-Based Deconvolution Of Low-Dose Brain Perfusion CT In Subarachnoid Hemorrhage Patients</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Tsuhan Chen, Pina C. Sanelli.</div>
                                                            <div class="pubcite">ISBI'12, The 9th International Symposium on Biomedical Imaging, pp. 872-875, Barcelona, Spain. Oral presentation.</div>
                                                            <div class="pubdate">Publication Year: 2012</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Functional imaging serves as an important supplement to
                                                        anatomical imaging modalities such as MR and CT in
                                                        modern health care. In perfusion CT (CTP), hemodynamic
                                                        parameters are derived from the tracking of the first-pass of
                                                        the contrast bolus entering a tissue region of interest. In
                                                        practice, however, the post-processed parametric maps tend
                                                        to be noisy, especially in low-dose CTP, in part due to the
                                                        noisy contrast enhancement profile and oscillatory nature of
                                                        results generated by current computational methods. In this
                                                        paper, we propose a sparsity-based perfusion parameter
                                                        deconvolution approach that consists of a non-linear
                                                        processing based on sparsity prior in terms of residue
                                                        function dictionaries. Our simulated results from
                                                        numericaldata and experiments in aneurysmal subarachnoid
                                                        hemorrhage patients with clinical vasospasm show that the
                                                        algorithm improves the quality and reduces the noise of the
                                                        perfusion parametric maps in low-dose CTP, compared to
                                                        state-of-the-art methods</p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2012">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/SPIE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Radiation dose reduction in computed tomography perfusion using spatial-temporal Bayesian methods.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ashish Raj, Tsuhan Chen, Pina C. Sanelli</div>
                                                            <div class="pubcite">SPIE'12, In Proceedings of SPIE Medical Imaging, Volume 8313, Paper #831345</div>
                                                            <div class="pubdate">Publication Year: 2012</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>In current computed tomography (CT) examinations, the associated X-ray radiation dose is of significant concern to
                                                        patients and operators, especially CT perfusion (CTP) imaging that has higher radiation dose due to its cine scanning
                                                        technique. A simple and cost-effective means to perform the examinations is to lower the milliampere-seconds (mAs)
                                                        parameter as low as reasonably achievable in data acquisition. However, lowering the mAs parameter will unavoidably
                                                        increase data noise and degrade CT perfusion maps greatly if no adequate noise control is applied during image
                                                        reconstruction. To capture the essential dynamics of CT perfusion, a simple spatial-temporal Bayesian method that uses
                                                        a piecewise parametric model of the residual function is used, and then the model parameters are estimated from a
                                                        Bayesian formulation of prior smoothness constraints on perfusion parameters. From the fitted residual function, reliable
                                                        CTP parameter maps are obtained from low dose CT data. The merit of this scheme exists in the combination of
                                                        analytical piecewise residual function with Bayesian framework using a simpler prior spatial constrain for CT perfusion
                                                        application. On a dataset of 22 patients, this dynamic spatial-temporal Bayesian model yielded an increase in signal-tonoise-ratio
                                                        (SNR) of 78% and a decrease in mean-square-error (MSE) of 40% at low dose radiation of 43mA. </p>
                                                    </div>
                                                </div>

                                                <div class="item mix Patents" data-year="2012">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="http://www.google.com/patents/WO2012027259A2?cl=en" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                        <img width="125" src="img/pubs/Patent.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                        <h4 class="pubtitle">System and Method For Interactive Segmentation On Mobile Devices in a Cloud Computing Environment</h4>
                                                        <span class="label label-info">Patents</span>
                                                        <div class="pubauthor"><strong> Ruogu Fang</strong>,Leo Grady, Gianluca Paladini.</div>
                                                        <div class="pubcite">Siemens Corporation. U.S. Patent No: US20130272587 A1, WO2012027259 A2, WO2012027259 A3. Published on March 1, 2012.</div>
                                                        <div class="pubdate">Publication Year: 2012</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>A mobile device (160) for medical image analysis is disclosed. The mobile device (160) includes a display (162), a communication module (218), a memory (204) configured to store processor-executable instructions (224) and a processor (202) in communication with the display (162), the communication module (218) and the memory (204). The processor (202) being configured to execute the processor-executable instructions (224) to implement a compression routine to generate a compressed representation of a medical image stored in the memory (204), transmit the compressed representation to a remote device (110) via the communication module (218), receive segmented results from the remote device (110), wherein the segmented results are derived from a reconstruction of the compressed representation generated at the remote device (110), and present, via the display (162), a segmented medical image based on the received segmented results.</p>
                                                    </div>
                                                </div>

                                                <!-- 2011-->
                                                <div class="item mix Conference" data-year="2011">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Segmentation of Liver Tumor Using Efficient Global Optimal Tree Metrics Graph Cuts</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Ramin Zabih, Ashish Raj, Tsuhan Chen</div>
                                                            <div class="pubcite">MICCAI'11, Abdominal Imaging, International Conference on Medical Image Computing and Computer Assisted Intervention, pp. 51-59</div>
                                                            <div class="pubdate">Publication Year: 2011</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p> We propose a novel approach that applies global optimal tree-metrics
                                                        graph cuts algorithm on multi-phase contrast enhanced contrast enhanced MRI
                                                        for liver tumor segmentation. To address the difficulties caused by low
                                                        contrasted boundaries and high variability in liver tumor segmentation, we first
                                                        extract a set of features in multi-phase contrast enhanced MRI data and use
                                                        color-space mapping to reveal spatial-temporal information invisible in MRI
                                                        intensity images. Then we apply efficient tree-metrics graph cut algorithm on
                                                        multi-phase contrast enhanced MRI data to obtain global optimal labeling in an
                                                        unsupervised framework. Finally we use tree-pruning method to reduce the
                                                        number of available labels for liver tumor segmentation. Experiments on realworld
                                                        clinical data show encouraging results. This approach can be applied to
                                                        various medical imaging modalities and organs.  </p>
                                                    </div>
                                                </div>

                                                <!-- 2010-->
                                                <div class="item mix Conference" data-year="2010">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="fa fa-expand"></i>
                                                            </a>
                                                            <a href="https://www.newscientist.com/article/mg21228424.900-facial-recognition-software-spots-family-resemblance/#.U9VZz1ZMYhG" class="tooltips" title="External link" target="_blank">
                                                                <i class="fa fa-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Towards Computational Models of Kinship Verification.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>,  Kevin D. Tang, Noah Snavely, Tsuhan Chen.</div>
                                                            <div class="pubcite">ICIP'10, The 17th IEEE International Conference on Image Processing, Hong Kong. Oral presentation ICIP 2010 Best Paper Award</div>
                                                            <div class="pubdate">Publication Year: 2010</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>We tackle the challenge of kinship verification using novel
                                                        feature extraction and selection methods, automatically
                                                        classifying pairs of face images as “related” or “unrelated”
                                                        (in terms of kinship). First, we conducted a controlled online
                                                        search to collect frontal face images of 150 pairs of public
                                                        figures and celebrities, along with images of their parents or
                                                        children. Next, we propose and evaluate a set of low-level
                                                        image features that for use in this classification problem.
                                                        After selecting the most discriminative inherited facial
                                                        features, we demonstrate a classification accuracy of 70.67%
                                                        on a test set of image pairs using K-Nearest-Neighbors.
                                                        Finally, we present an evaluation of human performance on
                                                        this problem. </p>
                                                    </div>
                                                </div>

                                                <div class="item mix Conference" data-year="2010">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle">Tree-Metrics Graph Cuts For Brain MRI Segmentation With Tree Cutting.</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"><u><b>Ruogu Fang</b></u>, Joyce Yu-hsin Chen, Ramin Zabih, Tsuhan Chen.</div>
                                                            <div class="pubcite">WNYIPW'10, IEEE Western New York Image Processing Workshop, pp. 10-13, Rochesester, NY. USA. Oral presentation</div>
                                                            <div class="pubdate">Publication Year: 2010</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p> We tackle the problem of brain MRI image segmentation using
                                                        the tree-metric graph cuts (TM) algorithm, a novel image
                                                        segmentation algorithm, and introduce a “tree-cutting”
                                                        method to interpret the labeling returned by the TM algorithm
                                                        as tissue classification for the input brain MRI image.
                                                        The approach has three steps: 1) pre-processing, which
                                                        generates a tree of labels as input to the TM algorithm; 2) a
                                                        sweep of the TM algorithm, which returns a globally optimal
                                                        labeling with respect to the tree of labels; 3) post-processing,
                                                        which involves running the “tree-cutting” method to generate
                                                        a mapping from labels to tissue classes (GM, WM, CSF),
                                                        producing a meaningful brain MRI segmentation. The TM
                                                        algorithm produces a globally optimal labeling on tree metrics
                                                        in one sweep, unlike conventional methods such as EMS
                                                        and EM-style geo-cuts, which iterate the expectation maximization
                                                        algorithm to find hidden patterns and produce only
                                                        locally optimal labelings. When used with the “tree-cutting”
                                                        method, the TM algorithm produces brain MRI segmentations
                                                        that are as good as the Unified Segmentation algorithm used
                                                        by SPM8, using a much weaker prior. Comparison with the
                                                        current approaches shows that our method is faster and that
                                                        our overall segmentation accuracy is better. </p>
                                                    </div>
                                                </div>

                                                <!-- 2009-->
                                                <div class="item mix Conference" data-year="2009">
                                                    <div class="pubmain">
                                                        <div class="pubassets">

                                                        </div>
                                                        <div class="pubthumbnail">
                                                            <img width="125" src="img/pubs/IEEE.png" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                        </div>
                                                        <div class="pubcontent">
                                                            <h4 class="pubtitle"> Adaptive Scale Robust Feature Density Approximation For Visual Object Representation And Tracking</h4>
                                                            <span class="label label-primary">Conference</span>
                                                            <div class="pubauthor"> Chongyang Liu, <strong>Ruogu Fang</strong>, and Nelson H.C.Yung </div>
                                                            <div class="pubcite"> IEEE International Conference on Computer Vision Theory and Applications, Lisboa, Portugal</div>
                                                            <div class="pubdate">Publication Year: 2009</div>
                                                        </div>
                                                        <div class="clearfix"></div>
                                                    </div>
                                                </div>
                                            </div>
                                            <!-- Publications End -->

                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!--Teaching-->
                <div id="teaching" class="page">

                    <!--Title-->
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Teaching</h2>
                                <div class="row">
                                    <div class="col-md-12">
                                        <p></p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!--/Title-->

                    <div class="pagecontents">

                        <!--Current Teaching-->
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="title text-center">
                                        <h3>Current Teaching</h3>
                                    </div>
                                    <ul class="ul-dates">
                                        <li>
                                            <div class="dates">
                                                <span>2023</span>
                                                <span>Fall</span>
                                            </div>
                                            <div class="content">
                                                <h4> BME4931/6938 Medical Artificial Intelligence <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/10/BME4931_6938-Medical-AI-Fall-2023-Fang.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                    <ol>
                                                    <li>Understand the basic concepts and techniques of machine learning. </li>
                                                    <li>Formulate machine learning problems corresponding to different applications. </li>
                                                    <li>Understand a range of machine learning algorithms along with their strengths and weaknesses. </li>
                                                    <li>Acquire skills of using recent machine learning software for solving practical problems.
                                                    <li>Apply machine learning algorithms to solve problems of moderate complexity. </li>
                                                    <li>Apply machine learning algorithms to a real-world problem, optimize the model learned and report the expected performance that can be achieved by applying the models. </li>
                                                    </ol>
                                                    <p>Instructor Evaluation: 5.00/5.00, Course Evaluation: 4.75/5.00</p>
                                            </div>
                                        </li> 
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <!--/Current Teaching-->

                        <!--Teaching History-->
                        
                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div class="title text-center">
                                        <h3>Teaching History</h3>
                                    </div>
                                    <ul class="ul-dates-gray">
                                        <li>
                                            <ul class="ul-dates">

                                                <li>
                                                    <div class="dates">
                                                        <span>2023</span>
                                                        <span>Spring</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME6938/CIS6930 Multimodal Data Mining <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/12/BME6938__syllabus.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>Course Objectives: 1. Understand multimodal data mining in the biomedical domain; 2. Understand the concept, approaches, and limitations in analyzing different modalities of biomedical data. 3. Learn to use biomedical data programming libraries and skills to analyze multimodal biomedical data. </p>
                                                    </div>
                                                </li> 
                                                <li>
                                                    <div class="dates">
                                                        <span>2022</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/10/BME3053C_2022Fall_syllabus.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>The objectives this course are: 1) Develop a proficiency in the use of computer programming (specifically, MATLAB) to analyze biomedical measurements. 2) Develop an understanding of biomedical engineering problems that require quantitative analysis and visualization.</p>
                                                    </div>
                                                </li>
                                                 <li>
                                                    <div class="dates">
                                                        <span>2021</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/10/BME3053C_2021Fall_syllabus.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>The objectives this course are: 1) Develop a proficiency in the use of computer programming (specifically, MATLAB) to analyze biomedical measurements. 2) Develop an understanding of biomedical engineering problems that require quantitative analysis and visualization.</p>
                                                        <p>Instructor Evaluation: 4.63/5.00, Course Evaluation: 4.38/5.00 </p>
                                                    </div>
                                                </li>
                                                
                                                <li>
                                                    <div class="dates">
                                                        <span>2021</span>
                                                        <span>Spring</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME6938 Multimodal Data Mining <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/12/BME6938_Spring_2019_syllabus.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>Course Objectives: 1. Understand multimodal data mining in the biomedical domain; 2. Understand the concept, approaches, and limitations in analyzing different modalities of biomedical data. 3. Learn to use biomedical data programming libraries and skills to analyze multimodal biomedical data. </p>
                                                        <p>Instructor Evaluation: 4.92/5.00, Course Evaluation: 4.70/5.00</p>
                                                    </div>
                                                </li>
                                                
                                                <li>
                                                    <div class="dates">
                                                        <span>2020</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/10/BME3053C_Fang-1.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>The objectives this course are: 1) Develop a proficiency in the use of computer programming (specifically, MATLAB) to analyze biomedical measurements. 2) Develop an understanding of biomedical engineering problems that require quantitative analysis and visualization.</p>
                                                        <p>Instructor Evaluation: 4.83/5.00, Course Evaluation: 4.53/5.00 (Historical highest for this course)</p>
                                                    </div>
                                                </li>
                                                
                                                <li>
                                                    <div class="dates">
                                                        <span>2019</span>
                                                        <span>Spring</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME6938 Multimodal Data Mining <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/12/BME6938_Spring_2019_syllabus.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>Course Objectives: 1. Understand multimodal data mining in the biomedical domain; 2. Understand the concept, approaches, and limitations in analyzing different modalities of biomedical data. 3. Learn to use biomedical data programming libraries and skills to analyze multimodal biomedical data. </p>
                                                        <p>Instructor Evaluation: 4.87/5.00</p>
                                                    </div>
                                                </li>
                                                <li>
                                                    <div class="dates">
                                                        <span>2019</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/wp-content/uploads/2018/10/BME3053C-Syllabi-2.pdf" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>The objectives this course are: 1) Develop a proficiency in the use of computer programming (specifically, MATLAB) to analyze biomedical measurements. 2) Develop an understanding of biomedical engineering problems that require quantitative analysis and visualization.</p>
                                                    </div>
                                                </li>
                                                <li>
                                                    <div class="dates">
                                                        <span>2018</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/course/computer-applications-for-bme-bme-3053c/" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                     <!--   <p>Instructor Evaluation: 4.00/5.00</p> -->
                                                    </div>
                                                </li>
                                                <li>
                                                    <div class="dates">
                                                        <span>2017</span>
                                                        <span>Fall</span>
                                                    </div>
                                                    <div class="content">
                                                        <h4> BME3053C Computer Applications for BME <a href="https://www.bme.ufl.edu/course/computer-applications-for-bme-bme-3053c/" class="tooltips" title="syllabus" target="_blank"><i class="fa fa-cloud-download"></i></a> <a href="https://ufl.instructure.com" class="tooltips" title="canvas" target="_blank"><i class="fa fa-external-link"></i></a></h4>
                                                        <p>The objectives this course are: 1) Develop a proficiency in the use of computer programming (specifically, MATLAB) to analyze biomedical measurements. 2) Develop an understanding of biomedical engineering problems that require quantitative analysis and visualization.</p>
                                                    </div>
                                                </li>
                                            </ul>
                                            <div class="dates">
                                                <span>2017</span>
                                                <span>Spring</span>
                                            </div>
                                            <div class="content">
                                                <h4> CAP 5771 Principles of Data Mining</h4>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="dates">
                                                <span>2017</span>
                                                <span>Spring</span>
                                            </div>
                                            <div class="content">
                                                <h4> CAP 4770 Introduction to Data Mining</h4>
                                            </div>
                                        </li>

                                        <li>
                                            <div class="dates">
                                                <span>2016</span>
                                                <span>Fall</span>
                                            </div>
                                            <div class="content">
                                                <h4> CAP 4770 Introduction to Data Mining</h4>
                                            <!--    <p>Course Evaluation: 4.24/5.00, Instructor Evaluation: 4.34/5.00</p> -->
                                            </div>
                                        </li>

                                        <li>
                                            <div class="dates">
                                                <span>2016</span>
                                                <span>Spring</span>
                                            </div>
                                            <div class="content">
                                                <h4>CAP 5610 Machine Learning</h4>
                                            <!--    <p>Course Evaluation: 4.46/5.00, Instructor Evaluation: 4.39/5.00</p> -->

                                            </div>
                                        </li>

                                        <li>
                                            <div class="dates">
                                                <span>2015</span>
                                                <span>Fall</span>
                                            </div>
                                            <div class="content">
                                                <h4> CAP 4770 Introduction to Data Mining</h4>
                                                <p>Data Mining is the nontrivial extraction of implicit, previously unknown, and potentially useful information from data. It has gradually matured as a discipline merging ideas from statistics, machine learning, database and etc. This is an introductory course for junior/senior computer science undergraduate students on the topic of Data Mining. Topics include data mining applications, data preparation, data reduction and various data mining techniques (such as association, clustering, classification, anomaly detection).</p>
                                          <!--      <p>Course Evaluation: 4.53/5.00, Instructor Evaluation: 4.57/5.00</p> -->
                                            </div>
                                        </li>

                                        <li>
                                            <div class="dates">
                                                <span>2015</span>
                                                <span>Spring </span>
                                            </div>
                                            <div class="content">
                                                <h4>CAP 5610 Machine Learning</h4>
                                                <p>Machine learning is concerned with the question of how to make computers learn from experience. The ability to learn is not only central to most aspects of intelligent behavior, but machine learning techniques have become key components of many software systems. For examples, machine learning techniques are used to create spam filters, to analyze customer purchase data, to understand natural language, or to detect fraudulent credit card transactions.</p>
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Teaching-->

                <!--Software-->
                <div id="software" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Software</h2>
                                <div class="row">
                                    <div class="col-md-12">
                                        <p></p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section color-1" id="filters">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-3">
                                        <h3>Filter by type:</h3>
                                    </div>
                                    <div class="col-md-6">
                                        <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                            <option class="filter" value="all" selected>All</option>
                                            <option class="filter" value="Code">Code</option>
                                            <option class="filter" value="Data">Data</option>
                                        </select>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="section color-2" id="pub-grid">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-12">
                                        <div class="pitems">
                                            
                                            <!--
                                            <div class="item mix Code" data-year="2024">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/GatorBrain" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">BrainFounder: Towards Brain Foundation Models for Neuroimage Analysis</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>We create and provide open-source code of a model and training scheme called BrainFounder. BrainFounder focuses on the movement towards large-scale models capable of few-shot or zero-shot learning in the neuroimaginge AI space (known as Foundation Models). Our results show that BrainFounder provides a promising foundation for the future creation of such Foundation Models through its leveraging of massive unlabeled data in self-supervised learning techniques; results validated through evaluation on the Brain Tumor Segmentation (BraTS) Challenge and the ATLAS v2.0 challenge.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <p>Joseph Cox, Peng Liu, Skylar E. Stolte, Yunchao Yang, Kang Liu, Kyle B. See, Huiwen Ju, Ruogu Fang. "BrainFounder: Towards Brain Foundation Models for Neuroimage Analysis". To be published in Medical Image Analysis, Jun 2024</p>
                                                </div>
                                            </div>
                                            -->

                                            <div class="item mix Code" data-year="2024">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/LAVA" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>LAVA is an XAI framework that aims to exploit neuron-level explanation as auxiliary information during learning process to make a high-resolution AD continuum prediction.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <p>Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai. "LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images" In Nature Scientific Reports, April 2024.</p>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2024">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/RetinaPD" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">RetinaPD</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>The purpose of this project is for the binary classification of Parkinson's Disease from UK Biobank Fundus Imaging.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <p>Charlie Tran, Kai Shen, Kang Liu, Akshay Ashok, Adolfo Ramirez-Zamora Jinghua Chen, Yulin Li, Ruogu Fang. "Deep Learning Predicts Prevalent and Incident Parkinson’s Disease From UK Biobank Fundus Imaging" In Nature Scientific Reports, 2024.</p>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2023">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/DOMINOPlusPlus" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>In this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss regularization focused on OOD generalizability.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <p>Skylar E. Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam J. Woods, Kevin Brink, Matthew Hale, and Ruogu Fang. "DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability" In MICCAI, 2023</p>
                                                </div>
                                            </div>

                                             <div class="item mix Code" data-year="2022">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/DOMINO" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                        <a href="https://codeocean.com/capsule/6022409/tree/v2" class="tooltips" title="CodeOcean" target="_blank"><i class="icon-codeocean"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">DOMINO: Domain-aware Model Calibration in Medical Image Segmentation</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>DOMINO is an open-source package for domain-aware model calibration that leverages the semantic confusability and hierarchical similarity between class labels in multi-class classification/segmentation to improve model calibration while not sacrificing or even improving model accuracy.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <p>Stolte, Skylar E., Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam J. Woods, Kevin Brink, Matthew Hale, and Ruogu Fang. "DOMINO: Domain-Aware Model Calibration in Medical Image Segmentation." In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 454-463. Springer, Cham, 2022.</p>
                                                </div>
                                            </div>
                                            
                                            
                                            <div class="item mix Code" data-year="2022">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/EEGAILab" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <!--
                                                    <div class="pubthumbnail">
                                                        <img width="125" src="img/pubs/MICCAI.jpg" class="attachment-medium size-medium wp-post-image" alt="" align="left" hspace="20">
                                                    </div>
                                                    -->
                                                    <h4 class="pubtitle">EEGAILab</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Toolbox for analyzing and visualizing dipole sources from resting electroencephalography data.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Kyle B. See, Rachel Ho, Stephen Coombes, Ruogu Fang, “TL1 Team Approach to Predicting Response to Spinal Cord Stimulation for Chronic Low Back Pain”, Journal of Clinical and Translational Science, Mar 2021.</li>
                                                        <li>Kyle B. See, Rachel Louise Mahealani Judy, Stephen Coombes, Ruogu Fang, “TL1 Team Approach to Predicting Short-term and Long-term Effects of Spinal Cord Stimulation” Journal of Clinical and Translational Science, Jul 2020.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2019">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/CADA" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">CADA</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Liu, Peng, Charlie T. Tran, Bin Kong, and Ruogu Fang. "CADA: Multi-scale Collaborative Adversarial Domain Adaptation for unsupervised optic disc and cup segmentation." Neurocomputing 469 (2022): 209-220.</li>
                                                    </ul>
                                                </div>
                                            </div>
                                            
                                            
                                            <div class="item mix Code" data-year="2019">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/cswin/AWC" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Domain Shift</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Adversarial Discriminative Adaptation and Ensembling Collaborative Learning for Domain Shift in Unsupervised Optic Disc and Cup Segmentation
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Liu, Peng, Bin Kong, Zhongyu Li, Shaoting Zhang, and Ruogu Fang. "CFEA: collaborative feature ensembling adaptation for domain adaptation in unsupervised optic disc and cup segmentation." In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 521-529. Springer, Cham, 2019.</li>
                                                    </ul>
                                                </div>
                                            </div>
                                            
                                            <div class="item mix Code" data-year="2019">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/lab-smile/EvoNet" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">EvoNet</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Deep evolutionary networks with expedited genetic algorithms for medical image denoising
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Liu, Peng, Mohammad D. El Basha, Yangjunyi Li, Yao Xiao, Pina C. Sanelli, and Ruogu Fang. "Deep evolutionary networks with expedited genetic algorithms for medical image denoising." Medical image analysis 54 (2019): 306-315.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2016">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/ruogufang/pct" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                        <h4 class="pubtitle">CT Perfusion Toolbox</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Toolbox for CT perfusion image processing and computation, including image loading, preprocessing, reconstruction, quantification, and example code.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Fang, R., Chen, T. and Sanelli, P.C., 2013. Towards robust deconvolution of low-dose perfusion CT: Sparse perfusion deconvolution using online dictionary learning. Medical image analysis, 17(4), pp.417-428.</li>
                                                        <li>Fang, R., Zhang, S., Chen, T. and Sanelli, P.C., 2015. Robust low-dose CT perfusion deconvolution via tensor total-variation regularization. IEEE transactions on medical imaging, 34(7), pp.1533-1548.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2015">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/ruogufang/ttv" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Tensor Total Variation</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Toolbox for Tensor Total Variation quantfication of CT perfusion parameters in low-dose CT perfusion.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Fang, R., Zhang, S., Chen, T. and Sanelli, P.C., 2015. Robust low-dose CT perfusion deconvolution via tensor total-variation regularization. IEEE transactions on medical imaging, 34(7), pp.1533-1548.</li>
                                                        <li>Fang, R., Sanelli, P.C., Zhang, S. and Chen, T., 2014, September. Tensor total-variation regularized deconvolution for efficient low-dose CT perfusion. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 154-161). Springer, Cham.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2014">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/ruogufang/SPD-Patlak" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Sparse High-Dose Induced Patlak Model for Permeability </h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Sparse high-dose induced Patlak model for Permeability quantification in low-dose CT perfusion.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                    <h4>Citation</h4>
                                                    <ul>
                                                        <li>Fang, R., Karlsson, K., Chen, T. and Sanelli, P.C., 2014. Improving low-dose blood–brain barrier permeability quantification using sparse high-dose induced prior for Patlak model. Medical image analysis, 18(6), pp.866-880.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Code" data-year="2013">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="https://github.com/ruogufang/SPD" class="tooltips" title="Github" target="_blank"><i class="fa fa-github"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Sparse Perfusion Deconvolution Toolbox </h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Code</span>Sparse perfusion deconvolution toolbox using dictionary learning and sparse coding for low-dose CT perfusion parameters quantification.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                <h4>Citation</h4>
                                                    <ul>
                                                        <li>Fang, R., Chen, T. and Sanelli, P.C., 2012, October. Sparsity-based deconvolution of low-dose perfusion CT using learned dictionaries. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 272-280). Springer Berlin Heidelberg.</li>
                                                        <li>Fang, R., Chen, T. and Sanelli, P.C., 2013. Towards robust deconvolution of low-dose perfusion CT: Sparse perfusion deconvolution using online dictionary learning. Medical image analysis, 17(4), pp.417-428.</li>
                                                    </ul>
                                                </div>
                                            </div>

                                            <div class="item mix Data" data-year="2013">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="http://chenlab.ece.cornell.edu/projects/KinshipClassification/" class="tooltips" title="webpage" target="_blank"><i class="fa fa-external-link"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Kinship Classification Dataset</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Data</span>Family101 Dataset: first large-scale dataset of families across several generations. It contains 101 different family with distinct family names, including 206 nuclear families, 607 individuals, with 14,816 images.
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                <h4>Citation</h4>
                                                <ul>
                                                    <li>Ruogu Fang, Andrew C. Gallagher, Tsuhan Chen, Alexander Loui. Kinship Classification by Modeling Facial Feature Heredity. IEEE International Conference on Image Processing, Australia, 2013 (ICIP '13)</li>
                                                </ul>

                                                </div>
                                            </div>

                                            <div class="item mix Data" data-year="2013">
                                                <div class="pubmain">
                                                    <div class="pubassets">
                                                        <a href="#" class="pubcollapse"><i class="fa fa-expand"></i></a>
                                                        <a href="http://chenlab.ece.cornell.edu/projects/KinshipVerification/" class="tooltips" title="webpage" target="_blank"><i class="fa fa-external-link"></i></a>
                                                    </div>
                                                    <h4 class="pubtitle">Kinship Verification Dataset</h4>
                                                    <div class="pubcite">
                                                        <span class="label label-primary">Data</span>Cornell Kinship Verification Dataset (143 pairs of parents and children)
                                                    </div>
                                                </div>
                                                <div class="pubdetails">
                                                <h4>Citation</h4>
                                                    <ul>
                                                        <li>Ruogu Fang, Kevin D. Tang, Noah Snavely, Tsuhan Chen. Towards Computational Models of Kinship Verification. IEEE International Conference on Image Processing, Hong Kong, September 2010 (ICIP '10)</li>
                                                    </ul>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Software-->

                <!--Video-->
                <div id="video" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Videos</h2>
                                <div class="row">
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section fixedbg parallax contact-office">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-13 col-md-offset-1">
                        
                                            <!--YouTube Videos-->
                                            <!--To add YouTube videos take the youtube link: add /embed/ and remove watch?v=. See the example video \/ -->

                                            <h2 class="title">Leveraging artificial intelligence to improve healthcare</h2>
                                            <p>Dr. Fang with a team of students and faculty members leverage deep neural networks to predict HIV.</p>
                                            <div class="scripps_iframe_embed" style="position:relative"><div style="display:block;width:100%;height:auto;padding-bottom:56.25%;"></div><iframe id="da-iframe" allowfullscale="" style="position:absolute;top:0;left:0;width:100%;height:100%;" border="0" height="100%" frameborder="0" webkitallowfullscreen="" allowfullscreen="" mozallowfullscreen="" scrolling="no"src="https://www.youtube.com/embed/xiMhkfVsnoU" allow="autoplay; fullscreen"></iframe></div>

                                            <h2 class="title">National Academy of Science, Engineering, and Medicine Workshop</h2>
                                            <p>Dr. Fang presents a workshop presentation on the impact of AI in the medical & clinical environment.</p>
                                            <div class="scripps_iframe_embed" style="position:relative"><div style="display:block;width:100%;height:auto;padding-bottom:56.25%;"></div><iframe id="da-iframe" allowfullscale="" style="position:absolute;top:0;left:0;width:100%;height:100%;" border="0" height="100%" frameborder="0" webkitallowfullscreen="" allowfullscreen="" mozallowfullscreen="" scrolling="no"src="https://player.vimeo.com/video/929634550?h=c358241f79" allow="autoplay; fullscreen"></iframe></div>

                                            <h2 class="title">UF Engineering - Forward & Up</h2>
                                            <p>Our SMILE Lab is featured on the Forward & Up video by the College of Engineering!</p>
                                            <div class="scripps_iframe_embed" style="position:relative"><div style="display:block;width:100%;height:auto;padding-bottom:56.25%;"></div><iframe id="da-iframe" allowfullscale="" style="position:absolute;top:0;left:0;width:100%;height:100%;" border="0" height="100%" frameborder="0" webkitallowfullscreen="" allowfullscreen="" mozallowfullscreen="" scrolling="no" src="https://www.youtube.com/embed/PlJhBRqmWeI" allow="autoplay; fullscreen"></iframe></div>
                                            
                                            <div style="padding:10px;"></div> <!--Line Break-->
                                            <h2 class="title">ABC Action News - Supercomputing AI</h2>
                                            <p>Dr. Fang is interviewed by ABC Action News in a news segment on the University of Florida's supercomputer, HiPerGator.</p>
                                            <div class="scripps_iframe_embed" style="position:relative"><div style="display:block;width:100%;height:auto;padding-bottom:56.25%;"></div><iframe id="da-iframe" allowfullscale="" style="position:absolute;top:0;left:0;width:100%;height:100%;" border="0" height="100%" frameborder="0" webkitallowfullscreen="" allowfullscreen="" mozallowfullscreen="" scrolling="no" src="https://assets.scrippsdigital.com/cms/video/player.html?video=https://content.uplynk.com/4e1d6642a5aa416ca57687e6eb23459f.m3u8&mp4=https://x-default-stgec.uplynk.com/ausw/slices/4e1/45bf940c346f431c9be273b8942ab6eb/4e1d6642a5aa416ca57687e6eb23459f/4e1d6642a5aa416ca57687e6eb23459f_e.mp4&purl=/news/local-news/supercomputer-at-the-university-of-florida-is-harnessing-the-awesome-power-of-ai&ads.iu=/6088/ssp.wfts/news/local-news/supercomputer-at-the-university-of-florida-is-harnessing-the-awesome-power-of-ai&ads.proxy=1&poster=https://x-default-stgec.uplynk.com/ausw/slices/4e1/45bf940c346f431c9be273b8942ab6eb/4e1d6642a5aa416ca57687e6eb23459f/poster_f23bd34a6ce842d3ac6ca926d20eacbb.jpg&title=Supercomputer%20at%20the%20University%20of%20Florida%20is%20harnessing%20the%20awesome%20power%20of%20AI&kw=ABC%20Action%20News%2CAI%2CAlzheimers%20%2CArtificial%20Intelligence%2CDr.%20Kevin%20Wang%2CDr.%20Ruogu%20Fang%2CFlorida%2CHiPerGator%2CMichael%20Paluska%2CNVIDIA&autoplay=true&contplay=*recent&mute=0&tags=Local%20News%2CHomepage%20Showcase%2CNewsletter%20Showcase%2CNews&section=Local%20News&cust_params=temp%3D%26weather%3D&host=abcactionnews.com&s=wfts&ex=1" allow="autoplay; fullscreen"></iframe></div>                                       

                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Join-->

                <!--Media-->
                <div id="media" class="page">
                    <div class="page-container">

                        <!-- Header -->
                        <div class="pageheader">
                            <div class="headercontent">
                                <div class="section-container">
                                    <h2 class="title">Media</h2>
                                    <div class="row">
                                        <div class="col-md-12">
                                            <p></p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>            
                        <!-- /Header -->
                        
                        <!-- Content -->
                        <div class="container">
                            <div class="posts">
                                
                            <div class="post">
                                <div class="post__image post__image--ufepi"></div><!--Define image in style.css sheet-->
                                <div class="post__content">
                                    <div class="post__inside">
                                        <h3 class="post__title">July 16, 2024</h3>
                                        <p class="post__excerpt_title">
                                            Computer Vision News & Medical Imaging News. 
                                        </p>
                                        <p class="post__excerpt">
                                            Dr. Fang with a team of students and faculty members leverage deep neural networks to predict HIV.
                                        </p>
                                        <a href="https://x.com/UF_EPI/status/1813188642644635779" class="tooltips" target="_blank">
                                        <button class="btn--accent post__button">
                                            Read more
                                            <i class="fa fa-chevron-right"></i>
                                        </button>
                                        </a>
                                    </div>
                                </div>
                            </div>

                                <div class="post">
                                    <div class="post__image post__image--rsipvision"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">May 2024</h3>
                                            <p class="post__excerpt_title">
                                                Computer Vision News & Medical Imaging News. 
                                            </p>
                                            <p class="post__excerpt">
                                                Dr. Ruogu Fang receives the inaugural AI Course Award for her exceptional leadership in developing and teaching the Medical Artificial Intelligence course at UF!
                                            </p>
                                            <a href="https://www.rsipvision.com/ComputerVisionNews-2024May/51/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--nationalacademies"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">March 25-26, 2024</h3>
                                            <p class="post__excerpt_title">
                                                A Workshop on Exploring the Bidirectional Relationship Between Artificial Intelligence and Neuroscience. 
                                            </p>
                                            <p class="post__excerpt">
                                                A 1.5-day public workshop hosted by the National Academies of Sciences, Engineering, and Medicine explores the application of artificial intelligence in neuroscience research.
                                            </p>
                                            <a href="https://www.nationalacademies.org/event/41351_03-2024_exploring-the-bidirectional-relationship-between-artificial-intelligence-and-neuroscience-a-workshop?utm_source=HMD+Email+List&utm_campaign=7c0aced6ef-EMAIL_CAMPAIGN_2023_12_29_08_15_COPY_01&utm_medium=email&utm_term=0_-8b2bca7570-%5BLIST_EMAIL_ID%5D&mc_cid=7c0aced6ef" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--sciencedaily"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 20, 2023</h3>
                                            <p class="post__excerpt_title">
                                                Study reveal bias in AI tools when diagnosing women's health issue
                                            </p>
                                            <p class="post__excerpt">
                                                Machine learning algorithms designed to diagnose a common infection that affects women showed a diagnostic bias among ethnic groups, University of Florida researchers found. 
                                            </p>
                                            <a href="https://www.sciencedaily.com/releases/2023/11/231120170925.htm" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--nationalgeographic"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">April 6, 2023</h3>
                                            <p class="post__excerpt_title">
                                                Your eyes may be a window into early Alzheimer's detection
                                            </p>
                                            <p class="post__excerpt">
                                                Scientists have linked certain changes in the retina to mild cognitive impairment-which may someday help identify the early signs of dementia. 
                                            </p>
                                            <a href="https://www.nationalgeographic.com/premium/article/eyes-early-stage-alzheimers-retina" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--ufengineering"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">March 30, 2023</h3>
                                            <p class="post__excerpt_title">
                                                UF Herbet Wertheim College of Engineering - Forward & Up
                                            </p>
                                            <p class="post__excerpt">
                                                See how our college is creating societal values in the far future and dissolving walls between the university and industry research and development in the latest college video. 
                                            </p>
                                            <a href="https://www.eng.ufl.edu/newengineer/news/forward-up/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--wfts"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">February 14, 2023</h3>
                                            <p class="post__excerpt_title">
                                                Supercomputer at UF harnesses the awesome power of AI
                                            </p>
                                            <p class="post__excerpt">
                                                At the University of Florida, inside a brick building with fake windows, lives a supercomputer called HiPerGator, one of the fastest in the world to harness the power of artificial intelligence. 
                                            </p>
                                            <a href="https://www.abcactionnews.com/news/local-news/supercomputer-at-the-university-of-florida-is-harnessing-the-awesome-power-of-ai" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--cvnews"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">January 10, 2023</h3>
                                            <p class="post__excerpt_title">
                                                Computer Vision News
                                            </p>
                                            <p class="post__excerpt">
                                                The Medical Imaging section of Computer Vision News featured SMILE Lab, Dr. Fang, and Ph.D. student Skylar E. Stolte on our artificial intelligence research in brain health and aging. 
                                            </p>
                                            <a href="https://www.rsipvision.com/ComputerVisionNews-2023January/32/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="post">
                                    <div class="post__image post__image--techtuesday"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">April 21, 2022</h3>
                                            <p class="post__excerpt_title">
                                                UF Innovate - Tech Tuesday
                                            </p>
                                            <p class="post__excerpt">
                                                In today's Tech Tuesday, UF Innovate host Lauren Asmus introduces us to biomedical engineer, Dr. Ruogu Fang. Dr. Fang is an assistant professor at the University of Florida who made an important discovery when studying the brain and the eye. 
                                            </p>
                                            <a href="https://www.wcjb.com/2022/05/04/tech-tuesday-modular-ad/?utm_source=newsfore&utm_medium=email&utm_campaign=16933&pnespid=t7s2B3tWKPwe3.vE.DeoApKGo0.1CINmM7Gg3utzvBdm3JEFixSQW_4oqGfEyyA8RU2FZT94NA" class="tooltips" target="_blank">
                                            <!--<a href="https://vimeo.com/701714544" class="tooltips" target="_blank"> -->
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--hwcoeaward"></div><!--Define image in style.css sheet-->
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">March 8, 2022</h3>
                                            <p class="post__excerpt_title">
                                                Fang recieves HWCOE 2022 Faculty Award for Excellence in Innovation.
                                            </p>
                                            <p class="post__excerpt">
                                                As a key faculty member of HWCOE in the space of data science and AI, Dr. Fang’s innovative research output and impact is fundamental to the latest HWCOE initiative to embrace AI-driven innovation.
                                            </p>
                                            <a href="https://www.bme.ufl.edu/fang-receives-hwcoe-2022-faculty-award-for-excellence-in-innovation/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--ufnvidia"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">February 2, 2022</h3>
                                            <p class="post__excerpt_title">
                                                UF, NVIDIA partner to speed brain research using AI
                                            </p>
                                            <p class="post__excerpt">
                                                University of Florida researchers joined forces with scientists at NVIDIA, UF’s partner in its artificial intelligence initiative, and the OpenACC organization to significantly accelerate brain science as part of the Georgia Tech GPU Hackathon held last month.
                                            </p>
                                            <a href="https://phhp.ufl.edu/2022/02/02/uf-nvidia-partner-to-speed-brain-research-using-ai/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="post">
                                    <div class="post__image post__image--ivanhoe"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">January 10, 2022</h3>
                                            <p class="post__excerpt_title">
                                                Artificial Intelligence Prevents Dementia?
                                            </p>
                                            <p class="post__excerpt">
                                                A team at the University of Florida is using targeted transcranial direct current stimulation to save memories. “It’s a weak form of electrical stimulation applied to the scalp. And this weak electric current actually has the ability to alter how the neurons behave,” continued Woods.
                                            </p>
                                            <a href="https://www.ivanhoe.com/medical-breakthroughs/artificial-intelligence-prevents-dementia/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>
                                                     


                                <div class="post">
                                    <div class="post__image post__image--uf"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">December 6, 2021</h3>
                                            <p class="post__excerpt_title">
                                                UF study shows artificial intelligence’s potential to predict dementia
                                            </p>
                                            <p class="post__excerpt">
                                                New research published today shows that a form of artificial intelligence combined with MRI scans of the brain has the potential to predict whether people with a specific type of early memory loss will develop Alzheimer’s disease or other form of dementia.
                                            </p>
                                            <a href="https://ufhealth.org/news/2021/uf-study-shows-artificial-intelligence-s-potential-predict-dementia" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                
                                <div class="post">
                                    <div class="post__image post__image--alligator"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">July 19, 2021</h3>
                                            <p class="post__excerpt_title">
                                                UF researchers fight dementia using AI technology to develop new treatment
                                            </p>
                                            <p class="post__excerpt">
                                                If presented with current models of electrical brain stimulation a decade ago, Dr. Adam J. Woods would have thought of a science-fiction movie plot. Artificial intelligence now pulls the fantasy out of screens and into reality.
                                            </p>
                                            <a href="https://www.alligator.org/article/2021/07/ai-dementia" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--wplg"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">July 16, 2021</h3>
                                            <p class="post__excerpt_title">
                                                Staving off dementia is focus of University of Florida study
                                            </p>
                                            <p class="post__excerpt">
                                                Researchers at the University of Florida have found a therapy that holds promise for preventing dementia by combining non-invasive brain stimulation with brain games.
                                            </p>
                                            <a href="https://www.local10.com/health/2021/07/16/staving-off-dementia-is-focus-of-univ-of-florida-study/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--wcjb"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">July 14, 2021</h3>
                                            <p class="post__excerpt_title">
                                                UF researchers using artificial intelligence to develop treatment to prevent dementia
                                            </p>
                                            <p class="post__excerpt">
                                                UF researchers are developing a method they hope will prevent Alzheimer’s and Dementia. Dr. Ruogu Fang and Dr. Adam Woods are working to personalize brain stimulation treatments to make them as effective as possible.
                                            </p>
                                            <a href="https://www.wcjb.com/2021/07/14/uf-researchers-using-artificial-intelligence-develop-treatment-prevent-dementia/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--ufdementia"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">July 13, 2021</h3>
                                            <p class="post__excerpt_title">
                                                UF researchers use AI to develop precision dosing for treatment aimed at preventing dementia
                                            </p>
                                            <p class="post__excerpt">
                                                UF researchers studying the use of a noninvasive brain stimulation treatment paired with cognitive training have found the therapy holds promise as an effective, drug-free approach for warding off Alzheimer’s disease and other dementias.
                                            </p>
                                            <a href="https://ufhealth.org/news/2021/uf-researchers-use-ai-develop-precision-dosing-treatment-aimed-preventing-dementia" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="post">
                                    <div class="post__image post__image--thewashingtonpost"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">February 2021</h3>
                                            <p class="post__excerpt_title">
                                                Our eyes may provide early warning signs of Alzheimer’s and Parkinson’s
                                            </p>
                                            <p class="post__excerpt">
                                                Forget the soul — it turns out the eyes may be the best window to the brain. Changes to the retina may foreshadow Alzheimer’s and Parkinson’s diseases, and researchers say a picture of your eye could assess your future risk of neurodegenerative disease.
                                            </p>
                                            <a href="https://www.washingtonpost.com/health/retiina-changes-in-early-alzheimers/2021/02/26/24c57bfa-6bba-11eb-9ead-673168d5b874_story.html" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--eyesmart"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">December 4, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Eye Blood Vessels May Diagnose Parkinson's Disease
                                            </p>
                                            <p class="post__excerpt">
                                                A simple eye exam combined with powerful artificial intelligence (AI) machine learning technology could provide early detection of Parkinson's disease, according to research being presented at the annual meeting of the Radiological Society of North America.
                                            </p>
                                            <a href="https://eyesmart.com.au/newsarticle/6166-eye-blood-vessels-may-diagnose-parkinson's-disease" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--ufparkinson"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">December 1, 2020</h3>
                                            <p class="post__excerpt_title">
                                                UF researchers are looking into the eyes of patients to diagnose Parkinson's Disease
                                            </p>
                                            <p class="post__excerpt">
                                                With artificial intelligence (AI), researchers have moved toward diagnosing Parkinson’s disease with, essentially, an eye exam. This relatively cheap and non-invasive method could eventually lead to earlier and more accessible diagnoses.
                                            </p>
                                            <a href="https://www.eng.ufl.edu/newengineer/in-the-headlines/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--mscp"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 29, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Blood Vessels in the Eye May Diagnose Parkinson's Disease
                                            </p>
                                            <p class="post__excerpt">
                                                Using an advanced machine-learning algorithm and fundus eye images, which depict the small blood vessels and more at the back of the eye, investigators are able to classify patients with Parkinson's disease compared against a control group.
                                            </p>
                                            <a href="https://www.medscape.com/viewarticle/941700" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--bignewsnetwork"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 29, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Eye exam possible test to determine Parkinson's disease
                                            </p>
                                            <p class="post__excerpt">
                                                Scientists have determined a simple eye exam combined with powerful artificial intelligence (AI) machine learning technology that could provide early detection of Parkinson's disease.
                                            </p>
                                            <a href="https://www.bignewsnetwork.com/news/267109611/eye-exam-possible-test-to-determine-parkinson-disease" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--forbes"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 25, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Scientists Are Looking Into The Eyes Of Patients To Diagnose Parkinson’s Disease
                                            </p>
                                            <p class="post__excerpt">
                                                With artificial intelligence (AI), researchers have moved toward diagnosing Parkinson's disease with, essentially, an eye exam. This relatively cheap and non-invasive method could eventually lead to earlier and more accessible diagnoses.
                                            </p>
                                            <a href="https://www.forbes.com/sites/jackierocheleau/2020/11/25/scientists-are-looking-into-the-eyes-of-patients-to-diagnose-parkinsons-disease/?sh=41aff39d2faa" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--rsna"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 23, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Eye Exam Could Lead to Early Parkinson’s Disease Diagnosis
                                            </p>
                                            <p class="post__excerpt">
                                                A simple eye exam combined with powerful artificial intelligence (AI) machine learning technology could provide early detection of Parkinson’s disease, according to research being presented at the annual meeting of the Radiological Society of North America.
                                            </p>
                                            <a href="https://press.rsna.org/timssnet/media/pressreleases/14_pr_target.cfm?ID=2229" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--scitechdaily"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 23, 2020</h3>
                                            <p class="post__excerpt_title">
                                                Simple Eye Exam With Powerful Artificial Intelligence Could Lead to Early Parkinson’s Disease Diagnosis
                                            </p>
                                            <p class="post__excerpt">
                                                A simple eye exam combined with powerful artificial intelligence (AI) machine learning technology could provide early detection of Parkinson’s disease, according to research being presented at the annual meeting of RSNA.
                                            </p>
                                            <a href="https://scitechdaily.com/simple-eye-exam-with-powerful-artificial-intelligence-could-lead-to-early-parkinsons-disease-diagnosis/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--appliedradiology"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">November 23, 2020</h3>
                                            <p class="post__excerpt_title">
                                                RSNA 20: AI-Based Eye Exam Could Aid Early Parkinson’s Disease Diagnosis
                                            </p>
                                            <p class="post__excerpt">
                                                A simple eye exam combined with powerful artificial intelligence (AI) machine learning technology could provide early detection of Parkinson’s disease, according to research being presented at the annual meeting of the Radiological Society of North America.
                                            </p>
                                            <a href="https://www.appliedradiology.com/communities/Artificial-Intelligence/rsna-20-ai-based-eye-exam-could-aid-early-parkinson-s-disease-diagnosis" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--acm"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">May 31, 2017</h3>
                                            <p class="post__excerpt_title">
                                                Fang selected to ACM's Future of Computer Academy
                                            </p>
                                            <p class="post__excerpt">
                                                Dr. Ruogu Fang, incoming assistant professor in the J. Crayton Pruitt Family Department of Biomedical Engineering, has been selected as a member of the Association for Computing Machinery’s (ACM) inaugural Future Computing Academy (FCA).
                                            </p>
                                            <a href="https://www.bme.ufl.edu/fang-selected-to-acms-future-of-computer-academy/" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--dotmed"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">May 31, 2016</h3>
                                            <p class="post__excerpt_title">
                                                Researcher says head CT radiation dose can be reduced by 90 percent
                                            </p>
                                            <p class="post__excerpt">
                                                Working with radiologists at Weill Cornell Medicine, Dr. Ruogu Fang, Ph.D., has applied machine learning and mathematical algorithms to manipulate low-dose CT perfusion images on stroke patients.
                                            </p>
                                            <a href="https://www.dotmed.com/news/story/31164" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--FIU-news"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">May 25, 2016</h3>
                                            <p class="post__excerpt_title">
                                                Professor uses computer science to reduce patients' exposure to radiation from CT scans
                                            </p>
                                            <p class="post__excerpt">
                                                When a doctor orders a CT perfusion scan, most people don’t give it a second thought as it’s necessary to evaluate serious medical conditions such as stroke.
                                            </p>
                                            <a href="https://newsarchives.fiu.edu/2016/05/professor-uses-computer-science-to-reduce-patients-exposure-to-radiation-from-ct-scans" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                                <div class="post">
                                    <div class="post__image post__image--newscientist"></div>
                                    <div class="post__content">
                                        <div class="post__inside">
                                            <h3 class="post__title">December 7, 2011</h3>
                                            <p class="post__excerpt_title">
                                                Facial recognition software spots family resemblance
                                            </p>
                                            <p class="post__excerpt">
                                                FACIAL recognition software that’s as good as people at spotting family resemblances could help to reunite lost family members – or help the likes of Facebook work out which of your friends are blood relatives.
                                            </p>
                                            <a href="https://www.newscientist.com/article/mg21228424-900-facial-recognition-software-spots-family-resemblance/#.Um2V95RhscZ" class="tooltips" target="_blank">
                                            <button class="btn--accent post__button">
                                                Read more
                                                <i class="fa fa-chevron-right"></i>
                                            </button>
                                            </a>
                                        </div>
                                    </div>
                                </div>

                            </div>
                        </div>
                        <!-- /Content-->
                        
                    </div>
                </div>                    
                <!--/Media-->

                <!--#######-->
                <!--Gallery-->
                <!--#######-->
                <div id="gallery" class="page">
                    <div class="pagecontents">
                        <div class="section color-3" id="gallery-header">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-3">
                                        <h2>Gallery</h2>
                                    </div>
                                    <div class="col-md-9">
                                        <p></p>
                                    </div>
                                </div>
                            </div> 
                        </div>

                        <div class="section color-3" id="gallery-large">
                            <div class="section-container">
                                <ul id="grid" class="grid">

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2024-04-22_SkylarStolte_GatorAttributeCreativity.JPG">
                                            <a href="img/gallery/2024-04-22_SkylarStolte_GatorAttributeCreativity.JPG" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE PhD student Skylar Stolte won the HWCOE GatorAttributes Award in Creativity (04/22/2024)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2024-04-17_AI Course Award.jpg">
                                            <a href="img/gallery/2024-04-17_AI Course Award.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Dr. Fang receives the Inaugural AI Course by AI2 Center/CTE/CITT at UF (04/17/2024)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-10-11_WILL Prize_MICCAI 2023.jpg">
                                            <a href="img/gallery/2023-10-11_WILL Prize_MICCAI 2023.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Skylar Stolte won the 2nd Prize in 2023 WiM Inspirational Leadership Legacy (WILL) (10/11/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-04-25_SeniorDesignShowcase_2.jpg">
                                            <a href="img/gallery/2023-04-25_SeniorDesignShowcase_2.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>2023 Senior Design Showcase: AI-based speech-to-text on mobile phone for electrolarynx (04/25/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-04-25_SeniorDesignShowcase_1.jpg">
                                            <a href="img/gallery/2023-04-25_SeniorDesignShowcase_1.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>2023 Senior Design Showcase: Intraoperative Arthroscopy Stability Device (04/25/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-04-19_AI4Health.jpg">
                                            <a href="img/gallery/2023-04-19_AI4Health.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Joseph Cox instructing the AI bootcamp at AI4Health! (04/19/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-03-23_NeevaSeethi_PresidentialAward.jpg">
                                            <a href="img/gallery/2023-03-23_NeevaSeethi_PresidentialAward.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Neeva Sethi receives Presidential Service Award! (03/23/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2023-01-13_Lab Group Photo First Meeting Spring 2023.png">
                                            <a href="img/gallery/2023-01-13_Lab Group Photo First Meeting Spring 2023.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>2023 Lab Group Photo First Meeting Spring (01/13/2023)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-12-09_BME Holiday Party_1.png">
                                            <a href="img/gallery/2022-12-09_BME Holiday Party_1.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>2022 BME Holiday Party Photo (12/09/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-12-06_BME3053C Class Finale.jpg">
                                            <a href="img/gallery/2022-12-06_BME3053C Class Finale.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>2022 BME3053C Group Photo (12/06/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-11-19_Thankgiving2022_3.png">
                                            <a href="img/gallery/2022-11-19_Thankgiving2022_3.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab's Thankgiving Potluck (11/19/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-11-19_Thankgiving2022_2.png">
                                            <a href="img/gallery/2022-11-19_Thankgiving2022_2.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab's Thankgiving Potluck (11/19/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-10-26_Halloween2022_5.png">
                                            <a href="img/gallery/2022-10-26_Halloween2022_5.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Group picture from the BME Halloween Event (10/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-10-26_Halloween2022_4.png">
                                            <a href="img/gallery/2022-10-26_Halloween2022_4.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Halloween 2022 lab decorations (10/26/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-10-26_Halloween2022_3.png">
                                            <a href="img/gallery/2022-10-26_Halloween2022_3.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Finished Mario Kart cars! (10/26/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_1.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_1.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Farewell lunch for Peng @ Chopstix Cafe (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_2.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_2.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Lab retreat lunch to welcome new members @ Chopstix Cafe (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_3.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_3.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab members @ Lab Retreat Lunch (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_4.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_4.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab members @ Lab Retreat Lunch (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_5.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_5.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab's Group Photo @ Lab Retreat Lunch 2022 (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-27_Fall2022LabRetreatLunch_6.png">
                                            <a href="img/gallery/2022-08-27_Fall2022LabRetreatLunch_6.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab's Group Photo @ Lab Retreat Lunch 2022 (08/27/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-22_FirstGroupMeetingFall2022_1.jpg">
                                            <a href="img/gallery/2022-08-22_FirstGroupMeetingFall2022_1.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab's Group Photo @ First Group Meeting Fall 2022 (08/22/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-22_FirstGroupMeetingFall2022_2.jpg">
                                            <a href="img/gallery/2022-08-22_FirstGroupMeetingFall2022_2.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab celebrating achievements and the start of the Fall 2022 semester! (08/22/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-22_FirstGroupMeetingFall2022_3.jpg">
                                            <a href="img/gallery/2022-08-22_FirstGroupMeetingFall2022_3.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab Group Photo Fall 2022 (08/22/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-08-22_FirstGroupMeetingFall2022_4.jpg">
                                            <a href="img/gallery/2022-08-22_FirstGroupMeetingFall2022_4.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Popping champagne to kick off the Fall 2022 semester! (08/22/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-04-22_hwcoe_award.jpg">
                                            <a href="img/gallery/2022-04-22_hwcoe_award.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Dr. Fang receives UF HWCOE Faculty Award for Excellence in Innovation (04/22/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-04-14_Garrett_Award_UFBME_Undergrad_Research.png">
                                            <a href="img/gallery/2022-04-14_Garrett_Award_UFBME_Undergrad_Research.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Garrett receives the Outstanding Research Award at UF BME Undergraduate Research Day (04/14/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-04-14_Garrett_Poster_UFBME_Undergrad_Research.png">
                                            <a href="img/gallery/2022-04-14_Garrett_Poster_UFBME_Undergrad_Research.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Garrett @ UF BME Undergraduate Research Day (04/14/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-04-07_UF_Undergraduate_Research_Symposium.png">
                                            <a href="img/gallery/2022-04-07_UF_Undergraduate_Research_Symposium.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>UF Undergraduate Research Symposium (04/12/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-04-03_Group_La-Chua-Trail.png">
                                            <a href="img/gallery/2022-04-03_Group_La-Chua-Trail.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>La Chua Trail Hiking (04/03/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2022-02-19_EscapeRoom.png">
                                            <a href="img/gallery/2022-02-19_EscapeRoom.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Escape Room Misson Completed! (02/2022)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-12-21_PhDGraduation.jpg">
                                            <a href="img/gallery/2021-12-21_PhDGraduation.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Drs. Xiao and Liu PhD Commencement (12/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-12-12_EndofYearLunch@YummyHouse.jpg">
                                            <a href="img/gallery/2021-12-12_EndofYearLunch@YummyHouse.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>End of Year Lunch @ Yummy House (12/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-11-14_Rock climbing_DrFang.png">
                                            <a href="img/gallery/2021-11-14_Rock climbing_DrFang.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Rock Climbing @ Lake Wauburg South Shore (11/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-11-14_GarrettKyleBirthday.jpg">
                                            <a href="img/gallery/2021-11-14_GarrettKyleBirthday.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Happy Birthday to Kyle and Garrett! (11/14/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-11-14_BBQ@Lake Wauburg.jpg">
                                            <a href="img/gallery/2021-11-14_BBQ@Lake Wauburg.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Lab BBQ @ Lake Wauburg (11/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-11-14_BBQ.jpg">
                                            <a href="img/gallery/2021-11-14_BBQ.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Lab BBQ @ Lake Wauburg (11/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-10-28_Halloween.png">
                                            <a href="img/gallery/2021-10-28_Halloween.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>BME Department Halloween Party (10/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-10-08_UFBME@BMES.jpg">
                                            <a href="img/gallery/2021-10-08_UFBME@BMES.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>UF BME@BMES 2021 (10/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-10-08_SMILE@BMES.jpg">
                                            <a href="img/gallery/2021-10-08_SMILE@BMES.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab @ BMES 2021 (10/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2021-09-19_GrapePicking@LotusFarm.jpg">
                                            <a href="img/gallery/2021-09-19_GrapePicking@LotusFarm.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Grape Picking @ Lotus Farm (09/2021)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2020-05-21_KyleSeeDCECelebrate.png">
                                            <a href="img/gallery/2020-05-21_KyleSeeDCECelebrate.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Kyle See passed Ph.D. Doctoral Comprehensive Exam! (05/2020)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2019-02-26_OutreachCadeMuseum.jpg">
                                            <a href="img/gallery/2019-02-26_OutreachCadeMuseum.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab Outreach @ Case Museum on AI for Diabetic Retinopathy Diagnosis (02/2019)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2019-02-01_SMILELab.jpg">
                                            <a href="img/gallery/2019-02-01_SMILELab.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab @ 2019 (02/2019)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2019-02-01_Group_smile.jpg">
                                            <a href="img/gallery/2019-02-01_Group_smile.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>The Smiling SMILE Lab @ 2019 (02/2019)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2018-12-04_BME3053CPoster.jpg">
                                            <a href="img/gallery/2018-12-04_BME3053CPoster.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>BME3053C Poster Day (12/2018)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2018-12-04_BME3053C_Poster_FirstPlace.jpg">
                                            <a href="img/gallery/2018-12-04_BME3053C_Poster_FirstPlace.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>BME3053C Poster Day Winner (12/2018)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2017-06_PicnicFIU.png">
                                            <a href="img/gallery/2017-06_PicnicFIU.png" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Lab BBQ @ Miami Beach (06/2017)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2017-04_Robin Sidhu Memorial Young Scientist Award@Society of Brain Mapping and Therapeutics.jpg">
                                            <a href="img/gallery/2017-04_Robin Sidhu Memorial Young Scientist Award@Society of Brain Mapping and Therapeutics.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Robin Sidhu Memorial Young Scientist Award@Society of Brain Mapping and Therapeutics (04/2017)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2017-04_award@SBMT.jpg">
                                            <a href="img/gallery/2017-04_award@SBMT.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Awards at Society of Brain Mapping and Therapeutics Annual Meeting (04/2017)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2016-04_spring-mlcourse.jpg">
                                            <a href="img/gallery/2016-04_spring-mlcourse.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>Machine Learning Course Group Photo (04/2016)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/2016-02-08_FIU_Group.jpg">
                                            <a href="img/gallery/2016-02-08_FIU_Group.jpg" class="popup-with-move-anim">
                                            <div class="over">
                                                <div class="comein">
                                                    <h3>SMILE Lab @ 2016 (02/2016)</h3>
                                                    <div class="comein-bg"></div>
                                                </div>
                                            </div>
                                            </a>
                                        </div>
                                    </li>

                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Gallery-->

                <!--Join-->
                <div id="join" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">JOIN US to SMILE!</h2>
                                <div class="row">
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section fixedbg parallax contact-office">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-13 col-md-offset-1">
                                        <h2 class="title">For Prospective Students</h2>
                                            <h3>Postdoc</h3>
                                            <p>We are hiring a Postdoc Researcher. Proficiency with Python and deep learning is required. Experience with Pytorch/Tensorflow, FSL/FreeSurfer/SPM are preferred. Please check out the job <a href="https://explore.jobs.ufl.edu/en-us/job/519971/postdoctoral-associate">HERE</a>.</p>
                                            <p>Please send me an email at <i>ruogu.fang@bme.ufl.edu</i> with the following:</p>
                                            <ul>
                                                <li>Subject line: <b>"Postdoc Applicant: YOUR_NAME - YOUR_UNIVERSITY"</b></li>
                                                <li>CV</li>
                                                <li>Transcript</li>
                                                <li>Cover letter</li>
                                                <li>Contact information of <i>three</i> references</li>
                                            </ul>
                                            <br>

                                            <h3>Ph.D. Applicants:</h3>
                                            <p>For Ph.D. applicants interested in working in my lab, you can apply for the Ph.D. program in Biomedical Engineering, Electrical and Computer Engineering, Computer Science, or other related programs at UF. </p>
                                            <p>Please send me an email at <i>ruogu.fang@bme.ufl.edu</i> with the following <b style="color:red">before you apply</b>:</p>
                                            <ul>
                                                <li>Subject line: <b>"PhD Applicant: YOUR_NAME - YOUR_UNIVERSITY"</b></li>
                                                <li>CV</li>
                                                <li>Transcript</li>
                                                <li>Overview of research experiences</li>
                                            </ul>
                                            <br>

                                            <h3>Current or Incoming Master Students:</h3>
                                            <p>If you are already a master student or have received admission to BME/ECE/CISE or related programs at the University of Florida, first complete the application form below. </p>
                                            <h4><b>Please complete the <a href="https://forms.gle/cPheVDB1Esj5Hdt68">application form</a></b></h4>
                                            <p>Please send me an email at <i>ruogu.fang@bme.ufl.edu</i> with the intention for voluntary research along with the following:</p>
                                            <ul>
                                                <li>Subject line: <b>"MS Applicant: YOUR_NAME - YOUR_UNIVERSITY"</b></li>
                                                <li>CV</li>
                                                <li>Transcript</li>
                                            </ul>
                                            <br>
                                            
                                            <h3>Undergraduate Students:</h3>
                                            <p>We take undergraduates from all years and prefer students who have a good math and coding background, or at least the strong motivation and interest to build a solid math and coding background.</p>
                                            
                                            <h4><b>Please complete the <a href="https://forms.gle/cPheVDB1Esj5Hdt68">application form</a></b></h4>
                                            <p>This form is always open, but the form <b>will only be reviewed during the recruitment period</b>. The official recruitment period begins at the end of <i>Fall</i> and <i>Spring</i> semester. More details are listed below.</p>
                                            <ul>
                                                <li>The recruitment consists of 1 review process and 1 (or additional) interview process.</li>
                                                <li>The <b>Fall</b> recruitment review begins <b>June 15th</b> (application should be submitted no later than June 14 23:59pm).</li>
                                                <li>The <b>Spring</b> recruitment review begins <b>December 15th</b> (application should be submitted no later than December 14 23:59pm).</li>
                                                <li style="color:red"><i>There are no exceptions for the late submission of the application.</i></li>
                                            </ul>
                                            <!--
                                            <p>Please send an email to amylazarte@ufl.edu and me with the title <b>"Undergraduate Applicant: YOUR NAME - YOUR YEAR IN THE PROGRAM (e.g., sophomore, junior)"</b> including your CV, transcript, and a brief research statement of why you want to join SMILE lab as an undergraduate researcher, what related research projects you have been involved, and why you think you will be a good undergraduate researcher in our lab.</p>
                                            -->

                                            <p><b>Prerequisite</b>: Complete <a href="https://www.coursera.org/learn/machine-learning">Coursera Machine Learning course</a> by Andrew Ng before you can officially join the lab. (Free) </p>
                                            <p><b>Co-requisite</b>: Students who have joined our lab (including PhD, MS, and UG) are strongly encouraged to complete the following courses online during their time in the lab:
                                            <ul>
                                                <li>Coursera <a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization's 4 courses</a></li>
                                                <li>Stanford CS231n [<a href="http://cs231n.stanford.edu/syllabus.html">Course website</a>] [<a href="https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk">Videos</a>]</li>
                                            </ul>
                                            <br>
                                        
                                            <h3>NSF Research Experience for Undergraduate (REU)</h3>
                                                <ul>
                                                    <li>The Research Experiences for Undergraduates (REU) site at University of Florida (UF) provides research experience to undergraduate students a six-month/1-year program. </li>
                                                    <li>Students will work on cutting-edge research in the area of AI for brain health and brain-inspired AI under the supervision of Dr. Fang and her graduate students.</li>
                                                    <li>Improve oral and written comprehension and communication of technical knowledge.</li>
                                                    <li>Spark an interest in continuing STEM research in graduate schools.</li>
                                                </ul>
                                                <h4>Requirements</h4>
                                                <ul>
                                                    <li>Applicant must be a U.S. citizen or permanent resident of the United States.</li>
                                                    <li>Applicant must be and remain an undergraduate student in good standing.</li>
                                                </ul>
                                                <p>All students that meet these requirements are welcome to apply! We are particularly interested in broadening participation of underrepresented groups in STEM, and women and minorities are especially encouraged to apply. We also aim to provide research experiences for students who have limited exposure and opportunities to participate in research. </p>
                                                <h4>How to apply</h4>
                                                <ul>
                                                    <li>Send an email to Dr. Fang entitled "REU Application_YourName" with your (i) a CV; (ii) information describing your research skills and experience; (iii) your goals and research interests for your REU research; (iv) contact details for two references. Applicants are considered on a rolling basis until filled. The deadline for 2022 application is April 1, 2022.</li>
                                                    <li>We consider applications on a rolling basis until all positions are filled.</li>
                                                </ul>
                                                <br>
                                        <h3>We look forward to your smile at SMILE Lab to make your day!</h3>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <!--/Join-->

                <!--Contact-->
                <div id="contact" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Contact & Meet Me</h2>
                                <div class="row">
                                    <div class="col-md-8">
                                        <p>I would be happy to talk to you if you need my assistance in your research, have intention for collaboration, or need technology translation for your company. Also, welcome to join my SMILE research group. Email is the best way to get in touch with me. Please feel free to contact me!</p>
                                    </div>
                                    <div class="col-md-4">
                                        <ul class="list-unstyled">
                                            <li>
                                                <strong><i class="fa fa-phone"></i>&nbsp;&nbsp;</strong>
                                                <span>office: (352) 294-1375</span>
                                            </li>
                                            <li>
                                                <strong><i class="fa fa-envelope"></i>&nbsp;&nbsp;</strong>
                                                <span>ruogu.fang@bme.ufl.edu</span>
                                            </li>
                                            <li>
                                                <!-- <span><a href="http://smile.cs.fiu.edu" target="_blank">SMILE Research group</a></span> -->
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section fixedbg parallax contact-office">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-7 col-md-offset-1">
                                        <h2 class="title">At My Office</h2>
                                        <p>J287 Biomedical Science Building<br>University of Florida<br>1275 Center Dr.<br>Gainesville, FL, 32611.</p>
                                        <p></p>
                                    </div>
                                    <div class="col-md-3 text-center hidden-xs hidden-sm">
                                        <i class="fa fa-coffee icon-huge"></i>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <!--
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-4 text-center hidden-xs hidden-sm">
                                        <i class="fa fa-stethoscope icon-huge"></i>
                                    </div>
                                    <div class="col-md-8">
                                        <h2 class="title">At My Work</h2>
                                        <p>You can find me at my Work located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                        <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="section fixedbg parallax contact-lab">
                            <div class="section-container">
                                <div class="row">
                                   <div class="col-md-7 col-md-offset-1">
                                        <h2 class="title">At My Lab</h2>
                                        <p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                        <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                                    </div>
                                    <div class="col-md-3 text-center hidden-xs hidden-sm">
                                        <i class="fa fa-superscript icon-huge"></i>
                                    </div>
                                </div>
                            </div>
                        </div>-->
                    </div>
                </div>
                <div id="overlay"></div>
            </div>
        </div>
    </body>
</html>
